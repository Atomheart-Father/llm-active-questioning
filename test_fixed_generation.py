#!/usr/bin/env python3
"""æµ‹è¯•ä¿®å¤åçš„æ•°æ®ç”ŸæˆåŠŸèƒ½"""

import os
import sys
import json
from pathlib import Path

# è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿå¯†é’¥ï¼‰
os.environ["GEMINI_API_KEY"] = "test_key_0"
os.environ["GEMINI_API_KEY2"] = "test_key_1"
os.environ["GEMINI_API_KEY3"] = "test_key_2"
os.environ["DEEPSEEK_API_KEY"] = "test_deepseek"
os.environ["DEEPSEEK_API_KEY2"] = "test_deepseek_2"
os.environ["FAILOVER_ENABLE"] = "true"
os.environ["ALLOW_RSD_FALLBACK"] = "false"

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_generation_quality():
    """æµ‹è¯•ç”Ÿæˆè´¨é‡"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•ä¿®å¤åçš„æ•°æ®ç”Ÿæˆ...")

    try:
        from tools.data_generator import DataGenerator, GenerationConfig

        # åˆ›å»ºé…ç½®
        config = GenerationConfig(
            batch_date="2025-09-03",
            alc_count=5,
            ar_count=3,
            rsd_count=2,
            temperature=0.7
        )

        # åˆ›å»ºç”Ÿæˆå™¨
        generator = DataGenerator(config)

        print("âœ… ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")

        # æµ‹è¯•promptç”Ÿæˆ
        alc_prompt = generator._get_alc_prompt()
        print(f"ğŸ¯ ALC Promptæ ·ä¾‹:\n{alc_prompt[:200]}...")

        # æ£€æŸ¥å¤šæ ·æ€§æ± 
        print("ğŸ¨ å¤šæ ·æ€§æ± æ£€æŸ¥:")
        personas = alc_prompt.count("ä¸€ä¸ª")  # æ£€æŸ¥æ˜¯å¦åŒ…å«äººè®¾
        print(f"  - äººè®¾æ± : {'âœ…' if personas > 0 else 'âŒ'}")

        # æµ‹è¯•è´¨é‡æ£€æŸ¥æ–¹æ³•
        test_sample = {
            "id": "TEST-001",
            "turns": [
                {"role": "user", "text": "æµ‹è¯•é—®é¢˜"},
                {"role": "model_target", "text": "<ASK>è¯·æä¾›æ›´å¤šä¿¡æ¯</ASK>"}
            ],
            "labels": {
                "ask_required": True,
                "ambiguity_types": ["test"],
                "good_question_set": ["test"]
            },
            "reasoning": {
                "actions": [
                    {"t": "AWARE_GAP", "vars": ["test"]},
                    {"t": "ASK", "q": "test"},
                    {"t": "STOP_ASK"}
                ]
            }
        }

        quality_result = generator._quality_check(test_sample, "ALC")
        print(f"ğŸšï¸ è´¨é‡æ£€æŸ¥æµ‹è¯•: {'âœ… é€šè¿‡' if quality_result['passed'] else 'âŒ å¤±è´¥'}")
        if not quality_result['passed']:
            print(f"  åŸå› : {quality_result['reasons']}")

        # æµ‹è¯•å¥å­æ”¹å†™
        original = "è¯·å‘Šè¯‰æˆ‘ä½ çš„æƒ³æ³•"
        rewritten = generator._rewrite_sentence(original)
        print(f"ğŸ“ å¥å­æ”¹å†™æµ‹è¯•: '{original}' â†’ '{rewritten}'")

        # æµ‹è¯•model_targetå†…å®¹ä¿®å¤
        test_turns = [
            {"role": "user", "text": "æµ‹è¯•"},
            {"role": "model_target", "text": "å¬èµ·æ¥å¾ˆæ£’ï¼ä¸ºäº†æ›´å¥½åœ°å¸®æ‚¨è§„åˆ’ï¼Œ<ASK>è¯·å‘Šè¯‰æˆ‘å…·ä½“æ—¶é—´</ASK>"}
        ]
        fixed_turns = generator._fix_model_target_content(test_turns)
        print(f"ğŸ”§ model_targetä¿®å¤æµ‹è¯•: {fixed_turns[1]['text']}")

        print("âœ… æ‰€æœ‰åŸºç¡€æµ‹è¯•é€šè¿‡ï¼")

        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_generation_quality()
    sys.exit(0 if success else 1)
