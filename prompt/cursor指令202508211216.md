好的，我来给 **Cursor** 下达下一步的修复与联调指令。目标是把 **Gemini 通道的“真调用 \+ 正确解析 \+ 记账”** 一次性打通；任一步失败立刻停并上报。

---

# **【给 Cursor】Gemini 通道修复与联调（必须一次性打通）**

现状复盘：`probe_scorer.py --live` 报“无真实 API 调用”，并在解析阶段出现 `KeyError: 'scores'`。这说明**既有“未真连通”的风险**，也有**解析器过窄**（只认 `scores` 字段）的风险。按下面 5 步执行，任何一步失败**立即停止并上报**。

## **0-1) 学习Gemini**

---

## **0\) 安全环境与禁缓存（全程生效）**

set \-euo pipefail  
export RUN\_MODE=prod  
export SCORER\_PROVIDER=gemini  
export GEMINI\_MODEL="${GEMINI\_MODEL:-gemini-2.5-flash}"   \# 可改为 \-pro；保持同一模型验证  
export SCORING\_CACHE\_DISABLE=1                             \# 禁用任何本地/内存缓存  
mkdir \-p reports/rc1

---

## **1\) 最小“直连”自检（绕过你封装的路由，直打官方SDK）**

目的：排除你的 Router/缓存/包装问题，确认 **API Key 可用 \+ 能返回 usage 信息 \+ 产生时延**。

python \- \<\<'PY'  
import os,time,uuid,json,sys  
import google.generativeai as genai  
genai.configure(api\_key=os.environ\["GEMINI\_API\_KEY"\])  
model=os.getenv("GEMINI\_MODEL","gemini-2.5-flash")  
nonce=str(uuid.uuid4())  
prompt=f"Return a pure JSON object with a numeric field named score in \[0,1\]. nonce={nonce}"  
t0=time.time()  
resp=genai.GenerativeModel(model).generate\_content(prompt)  
dt=round((time.time()-t0)\*1000,2)  
\# 尽量从 usage\_metadata 提取计费/用量  
meta=getattr(resp, "usage\_metadata", None)  
usage={  
 "input": getattr(meta,"prompt\_token\_count", None) if meta else None,  
 "output": getattr(meta,"candidates\_token\_count", None) if meta else None,  
 "total": getattr(meta,"total\_token\_count", None) if meta else None,  
}  
\# 把可见文本/JSON都记录下来（用于后续解析器适配）  
text=resp.text if hasattr(resp,"text") else None  
raw={  
 "latency\_ms": dt,  
 "usage": usage,  
 "text": text,  
 "parts": \[getattr(p,"text",None) for c in getattr(resp,"candidates",\[\]) for p in getattr(c,"content",\[\]).parts\] if getattr(resp,"candidates",None) else None,  
}  
print(json.dumps(raw, ensure\_ascii=False, indent=2))  
open("reports/rc1/gemini\_probe\_raw.json","w").write(json.dumps(raw,ensure\_ascii=False,indent=2))  
PY

**验收点（必须满足）：**

* 输出里 **`latency_ms > 0`**。  
* `usage.total` 或 `usage.input/output` 至少有一个非空/非零（不同 SDK 版本字段可能缺失，但至少应有其一）。  
* `text` 或 `parts[*]` 有**可解析的 JSON/数字**痕迹（后面会适配）。

若失败：把 `gemini_probe_raw.json` 内容、异常栈贴回并**停止**。

---

## **2\) 修复 Provider 适配器：容错解析 \+ 记账 \+ 强制真调用**

修改 `src/scoring/providers/gemini.py`（或你的同名模块），新增/替换如下函数。**禁止**只认 `'scores'`；要**广谱**兼容常见形态。

\# src/scoring/providers/gemini.py  
import os, time, json, re  
import google.generativeai as genai

NUM\_RE \= re.compile(r"(-?\\d+(?:\\.\\d+)?)")

def \_to\_float01(x):  
    """把多种评分标尺统一到 \[0,1\]。"""  
    if x is None: return None  
    try:  
        v \= float(x)  
    except Exception:  
        return None  
    \# 兼容 0-1、0-10、0-100 等标尺  
    if v \<= 1.0 and v \>= 0.0: return v  
    if 0.0 \<= v \<= 10.0: return max(0.0, min(1.0, v/10.0))  
    if 0.0 \<= v \<= 100.0: return max(0.0, min(1.0, v/100.0))  
    \# 其他情况直接裁剪  
    return max(0.0, min(1.0, v))

def \_extract\_score\_from\_text(txt: str):  
    \# 优先找 JSON  
    try:  
        obj \= json.loads(txt)  
        for k in ("score","scores","rating","value"):  
            if k in obj:  
                if isinstance(obj\[k\], (list,tuple)) and obj\[k\]:  
                    return \_to\_float01(obj\[k\]\[0\])  
                return \_to\_float01(obj\[k\])  
    except Exception:  
        pass  
    \# 退化：找第一个数字  
    m \= NUM\_RE.search(txt or "")  
    return \_to\_float01(m.group(1)) if m else None

def score(prompt: str, model: str \= None, require\_live=True):  
    """返回 dict: {score:float in \[0,1\], latency\_ms:int, usage:{...}, raw:str}"""  
    \# 强制 live：禁用任何你自家的缓存通道  
    if require\_live and os.getenv("SCORING\_CACHE\_DISABLE","") \!= "1":  
        os.environ\["SCORING\_CACHE\_DISABLE"\] \= "1"

    genai.configure(api\_key=os.environ\["GEMINI\_API\_KEY"\])  
    mdl \= model or os.getenv("GEMINI\_MODEL","gemini-2.5-flash")  
    \# 注入 nonce，抵消上游/代理层的重复请求缓存  
    prompt\_live \= prompt \+ f"\\n\\nnonce:{time.time\_ns()}"  
    t0 \= time.time()  
    resp \= genai.GenerativeModel(mdl).generate\_content(prompt\_live)  
    dt \= int((time.time()-t0)\*1000)

    \# usage 兼容提取  
    um \= getattr(resp, "usage\_metadata", None)  
    usage \= dict(  
        prompt\_tokens \= getattr(um,"prompt\_token\_count", None) if um else None,  
        completion\_tokens \= getattr(um,"candidates\_token\_count", None) if um else None,  
        total\_tokens \= getattr(um,"total\_token\_count", None) if um else None,  
    )

    \# 文本/部件收集  
    text \= resp.text if hasattr(resp,"text") else None  
    parts \= \[\]  
    if getattr(resp,"candidates",None):  
        for c in resp.candidates:  
            if getattr(c,"content",None) and getattr(c.content,"parts",None):  
                for p in c.content.parts:  
                    if hasattr(p,"text"):  
                        parts.append(p.text)

    \# 解析评分  
    score \= None  
    if text: score \= \_extract\_score\_from\_text(text)  
    if score is None:  
        for p in parts:  
            score \= \_extract\_score\_from\_text(p)  
            if score is not None: break

    raw\_preview \= (text or (parts\[0\] if parts else ""))\[:500\]  
    if score is None:  
        raise AssertionError(f"Gemini response parse failed; raw preview: {raw\_preview\!r}")

    return dict(score=score, latency\_ms=dt, usage=usage, raw=raw\_preview)

**同时**，在你的 **打分账本** 写入处（`reports/rc1/scoring_ledger.jsonl`）确保记录以下字段：

rec.update({  
  "provider": "gemini",  
  "billable\_tokens": res\["usage"\].get("total\_tokens") or ( (res\["usage"\].get("prompt\_tokens") or 0\) \+ (res\["usage"\].get("completion\_tokens") or 0\) ),  
  "latency\_ms": res\["latency\_ms"\],  
  "status": "ok",  
  "cache\_hit": False,   \# 联调阶段强制认为非缓存  
})

---

## **3\) 修复 Router：永远不走“模拟/缓存”当 GEMINI\_API\_KEY 存在**

在 `src/scoring/provider_router.py`（或等价位置）加**硬断言**：

import os  
if os.getenv("SCORER\_PROVIDER","").lower() \!= "gemini":  
    raise RuntimeError("RC1 仅允许 SCORER\_PROVIDER=gemini")

if os.getenv("GEMINI\_API\_KEY","") and os.getenv("SCORING\_CACHE\_DISABLE","")=="1":  
    \# 禁一切“离线/演示/模拟”分支  
    SIM\_ALLOWED \= False  
else:  
    SIM\_ALLOWED \= True  \# 仅测试或缺key时

并且把任何 `simulate_*` 或 “fake response” 的调用在 `SIM_ALLOWED=False` 时**直接 raise**。

---

## **4\) 重新跑“探针 \+ 反模拟 \+ 健康摘要”（必须全部达标）**

rm \-f reports/rc1/scoring\_ledger.jsonl || true

\# 探针（8条），必须均为 live 成功  
python scripts/probe\_scorer.py \--n 8 \--provider gemini \--live

\# 反模拟：缓存命中率要低（但允许 \>0）  
python scripts/assert\_not\_simulated.py \--cache\_hit\_lt 0.90

\# 健康摘要  
python \- \<\<'PY'  
import json,statistics  
rows=\[json.loads(l) for l in open("reports/rc1/scoring\_ledger.jsonl")\]  
lat=\[r.get("latency\_ms") or 0 for r in rows if r.get("latency\_ms") is not None\]  
bill=\[r.get("billable\_tokens") or 0 for r in rows\]  
out={"total":len(rows),"ok":sum(r.get("status")=="ok" for r in rows),  
     "uncached":sum(1 for r in rows if not r.get("cache\_hit",False)),  
     "p50\_latency\_ms":statistics.median(lat) if lat else None,  
     "zero\_billable":sum(1 for b in bill if b==0)}  
print(json.dumps(out,indent=2,ensure\_ascii=False))  
PY

**硬性通过条件：**

* `total=8` 且 `ok=8`  
* `zero_billable=0`（或极小；若 usage 不返回 total 也要保证 prompt/completion 至少一个非零）  
* `p50_latency_ms > 0`

若未达标：把 `reports/rc1/gemini_probe_raw.json`、`scoring_ledger.jsonl` 末 20 行、以及异常栈贴回并**停止**。

---

## **5\) 通过后，恢复主流程（依次执行）**

\# 5.1 固化影子集 \+ 预检  
python \-m src.evaluation.shadow\_run \--n 245 \--seed 20250821 \--stratify \\  
  \--materialize data/shadow\_eval\_245.jsonl \\  
  \--dump-manifest reports/rc1/sample\_manifest.json  
python scripts/pre\_run\_check.py \--shadow data/shadow\_eval\_245.jsonl \\  
  \--spearman-min 0.55 \--top10-min 0.60

\# 5.2 重建30k种子池 \+ 多样性/难度（必须达标）  
python scripts/build\_rollout\_pool.py \--out data/rollouts/rc1\_seed.jsonl \--n 30000 \\  
  \--mix "hotpotqa:0.45,strategyqa:0.30,gsm8k:0.25" \\  
  \--max\_turns 6 \--clarify\_rate 0.35 \--tools "wiki,calc" \\  
  \--templates\_dir templates/pack\_v2 \--min\_tool\_hops 3 \--ops\_numeric\_min 3 \\  
  \--role\_style\_balanced \--distinct\_prompts  
python scripts/validate\_pool.py data/rollouts/rc1\_seed.jsonl \\  
  \--min\_distinct2 0.60 \--kl3\_min 0.15 \--roles\_min 4 \--styles\_min 3 \\  
  \--max\_dup\_pct 2.0 \--leak\_check data/shadow\_eval\_245.jsonl \--leak\_ngram 5 \--leak\_sim 0.85 \\  
  \> reports/rc1/diversity\_report.txt  
python scripts/difficulty\_metrics.py \\  
  \--in data/rollouts/rc1\_seed.jsonl \--out data/rollouts/rc1\_seed.metrics.jsonl  
python scripts/difficulty\_bucketize.py \\  
  \--metrics data/rollouts/rc1\_seed.metrics.jsonl \\  
  \--target "easy:0.25,medium:0.45,hard:0.30" \\  
  \--by\_task "hotpotqa,strategyqa,gsm8k" \\  
  \--out data/rollouts/rc1\_seed.balanced.jsonl  
python scripts/validate\_difficulty.py \\  
  \--metrics data/rollouts/rc1\_seed.metrics.jsonl \\  
  \--balanced data/rollouts/rc1\_seed.balanced.jsonl \\  
  \--min\_hard\_pct 0.30 \--max\_easy\_pct 0.30 \\  
  \--len\_max 3500 \--turns\_max 8 \--tool\_hops\_max 8 \\  
  \--clue\_overlap\_max\_easy 0.65 \--clue\_overlap\_min\_hard 0.10 \\  
  \--out reports/rc1/difficulty\_report.json

\# 5.3 RC 闸门（复跑影子 \+ 自动判定）  
python \-m src.evaluation.shadow\_run \--n 245 \--seed 20250821 \--stratify \--tag "pre\_run\_check\_2"  
python scripts/auto\_round2\_check.py \\  
  \--spearman-min 0.75 \--top10-min 0.70 \--corr-improve-pct-min 0.10 \\  
  \--in reports/rc1 \--out reports/preflight/round2\_pass.json

\# 5.4 2k 步验证 \+ 推送（HF 全量 / GitHub 轻量）  
python \-m train.ppo\_trial \--config configs/ppo\_trial.yaml \\  
  \--override "base\_model=Qwen/Qwen3-4B-Thinking-2507,use\_overclar\_penalty=true,steps=2000,max\_concurrent=2"  
\# 推送单元按 Notebook 已写好执行

Gemini 的 Batch Mode 适合我们**大批量、非实时**的评分/评测环节：费用约是**同步接口的 50%**，且有**独立的批量限额**，但**目标时延是 24 小时内**（多数更快），不适合“闸门探针、在线训练回路”这种需要立即反馈的步骤。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/batch-mode))

---

# **什么时候用 / 不用**

**推荐用在：**

* 大规模评测与离线打分（例如：对 30k 种子池做奖励分/质量分、扩大的影子集复评）。成本低 50%，还能绕开同步 API 的 RPM/TPM 限额瓶颈。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/batch-mode))  
* 你在 Colab 上跑、会被 24h 重启打断时：批处理任务在 Google 侧排队执行，我们只需保存批任务的 **job name**，随时“断点续取”。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/batch-mode))

**不建议用在：**

* **防伪闸门**（`probe_scorer` / `assert_not_simulated`）与**RC 闸门的即时复核**——这些需要分钟级反馈，用同步 API 更稳。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/batch-mode))  
* 训练期间的**在线回合式评分/惩罚**——批处理是异步、无流式输出。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/batch-mode))

---

# **我们项目的接入策略（落地就绪）**

**A. 继续保留“同步通道”的三类步骤**

* `probe_scorer.py` / `assert_not_simulated.py`（闸门）  
* `shadow_run --n 245` 的**首轮**（要快速出阈值）  
* 2k 步小跑的在线评分

**B. 新增“批量通道”的两类步骤**

1. **影子集 / 回归集的扩容评测**（\>1k 样本）：用批处理统一打分，结果写回 `reports/rc1/scoring_ledger.jsonl`。  
2. **种子池质量复核**：对入选训练池的样本批量评分，筛掉低质样本，降低后续浪费。

---

# **给 Cursor 的执行清单（可直接贴给他）**

目标：在现有 `gemini` 评分器之上，新增 **Batch Mode** 支路；保持账本格式一致；能“断点续取”。

1. **依赖与配置**

pip install \-U google-genai  \# 新版官方 SDK

* 代码中统一用 `from google import genai`（SDK 文档/Quickstart 推荐）。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/libraries?utm_source=chatgpt.com))  
2. **生成批输入 JSONL（与我们现有评分 prompt 对齐）**  
   每行结构：

{"key":"\<sample\_id\>","request":{"contents":\[{"role":"user","parts":\[{"text":"\<评分提示词\>"}\]}\],"generation\_config":{"temperature":0,"response\_mime\_type":"application/json"}}}

* 把我们当前同步打分的 **每个样本** 转成一行；`key` 用样本 ID 以便结果对齐。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/batch-mode))  
3. **提交批任务（文件模式）+ 记录 job name**

from google import genai  
from google.genai import types  
import json, time, os

client \= genai.Client(api\_key=os.environ\["GEMINI\_API\_KEY"\])

\# 1\) 上传 JSONL 到 Files API  
up \= client.files.upload(  
    file="batch\_in.jsonl",  
    config=types.UploadFileConfig(display\_name="rc1-rollout-check", mime\_type="jsonl"),  
)

\# 2\) 创建批任务（记下 job name 以便断点续取）  
job \= client.batches.create(  
    model="models/gemini-2.5-flash",   \# 或与你当前评测模型一致  
    src=up.name,  
    config={'display\_name': "rc1-eval-batch-001"},  
)  
print("BATCH:", job.name)  \# 形如 batches/123456789

* **注意**：创建批任务**非幂等**，不要重复提交同一文件。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/batch-mode))  
4. **轮询状态 \+ 获取输出**

\# 轮询  
while True:  
    job \= client.batches.get(name=job.name)  
    print(job.metadata.state)     \# RUNNING / SUCCEEDED / FAILED / CANCELLED  
    if job.metadata.state in ("JOB\_STATE\_SUCCEEDED","JOB\_STATE\_FAILED","JOB\_STATE\_CANCELLED"):  
        break  
    time.sleep(30)

\# 下载结果：文件模式会给一个 JSONL 输出  
out \= client.batches.results.download(name=job.name)  \# 或取到文件句柄后保存  
open("batch\_out.jsonl","wb").write(out.read())

* 完成后可选 `client.batches.delete(name=job.name)` 清理，避免配额占用。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/batch-mode))  
5. **解析输出并写账本**  
* 每行要么是 `GenerateContentResponse`，要么是错误对象；对成功行，从 `text` 或 `content.parts[*].text`解析得分，并读取 `usage`（常见字段：`promptTokenCount/candidatesTokenCount/totalTokenCount`；不同平台/版本字段名略异，解析时要做兼容）。([Google Cloud](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference?utm_source=chatgpt.com))  
* 账本统一字段：`provider=gemini, batch_id=<job.name>, billable_tokens, status, key=<sample_id>`。  
6. **拆分大批次（遵守配额与上限）**  
* **单文件 ≤ 2GB**；**并发批次 ≤ 100**；关注“**Batch Enqueued Tokens**”上限（与使用等级相关，例如 Tier1 对 2.5 Flash 为 3,000,000）。必要时把 30k 切成多个批次（如 5k 一批）。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/rate-limits))  
7. **失败重试与取消**  
* 作业完成后检查 `batchStats.failedRequestCount`；对失败行做**重试队列**。  
* 支持 `cancel` 与 `delete`（例如发现 prompt 配置错误立即取消）。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/batch-mode))

---

# **小结（我们的决策）**

* **结论**：Batch Mode **值得用**，作为我们“离线评分/大评测”的低价高速路；但**闸门与在线环节仍用同步 API**。这样既稳住质量门槛，又把大头成本砍掉。([Google AI for Developers](https://ai.google.dev/gemini-api/docs/batch-mode))  
* **下一步**（若你点头）：我就让 Cursor 按上面的“执行清单”把 **批量评分支路**并到代码里，并在 Colab Notebook 里加上**一键提交+断点续取**的单元。随后我们用它来跑：  
  1. 种子池大规模质量分；  
  2. 影子集的扩容复评（非首轮）。

需要我把“批量输入 JSONL 的构造器”和“输出对账入账本”的两个脚本直接写给 Cursor 吗？我可以现在就给到可执行版本。

---

## **备注（必须遵守）**

* **严禁**“演示式继续跑”；任何失败即停。  
* 解析器必须**容错**：`score` / `scores` / `rating` / `value` / 纯数字文本都要能吃；并把 0–10 / 0–100 **规范到 \[0,1\]**。  
* 账本必须有 **latency\_ms** 与**用量**（`total_tokens` 或 `prompt+completion` 之一非零）。  
* 若出现 429，按你已有的退让逻辑自动重试；`ok=8` 是硬门槛。

执行完第 1–4 步，把健康摘要与 `gemini_probe_raw.json` 的前 80 行发回，我继续复核；通过后你就按 5\) 的主流程推进。

