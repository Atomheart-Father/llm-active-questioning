好的，以下是可以直接转发给 **cursor** 的本地工单式「开发者 Prompt」。按这份做就行；所有命令都能直接复制执行。目标是：在 **本地 MPS（Apple/Metal）** 上把**训练流水线**完整搭起来（含断点、日志、评测脚手架、可热插拔的强化策略与训练引擎），为后续接入云端数据与真实奖励打好地基。

---

# **CURSOR\_PROMPT\_LOCAL.md**

**主题：在本地搭建“模块化高级训练系统”（MPS 优先），支持快速更换策略与引擎**

你现在的唯一 KPI：把一个可复现、可恢复、可审计的**训练流水线**跑通（含最小训练回路）。策略、数据来源、奖励模型后续会增加与替换，所以框架必须**模块化**、**插拔式**。  
✅ 出错立刻停止并上报，不得隐藏；✅ 任何阶段产出要有日志与指纹（sha256）；✅ 只能在本地运行（MPS/CPU），勿上云。

---

## **0\) 环境与设备规范（立即执行）**

\# 在仓库根目录  
python3 \-m venv .venv  
source .venv/bin/activate  
python \-m pip install \-U pip wheel

\# 基础依赖（若 requirements.txt 已有，以文件为准）  
pip install "torch\>=2.3" "transformers\>=4.43" "accelerate\>=0.30" "trl\>=0.9" \\  
            "peft\>=0.11" "datasets\>=2.19" "evaluate\>=0.4" \\  
            "tqdm" "numpy" "scikit-learn" "pyyaml" "jsonlines" "psutil"

\# 设备自检（MPS 优先）  
python \- \<\<'PY'  
import torch, platform  
dev \= "mps" if torch.backends.mps.is\_available() else "cpu"  
print("DEVICE:", dev, "PLAT:", platform.platform())  
PY

**要求**

* 写一个 `src/runtime/device.py`，导出 `get_device()` 与 `to_device(t)`，自动优先用 MPS，退回 CPU；统一 dtype（bf16 优先，MPS 不支持则自动 fp32）。  
* 在训练循环中只通过 `to_device()` 放张量，不允许 scattered `.to(...)`。

---

## **1\) 目录骨架（必须落地）**

mkdir \-p src/{config,core,agents,strategies,engines,callbacks,utils} \\  
         src/data/{readers,collate} src/eval tests ops logs reports checkpoints

**模块职责**

* `src/config/`: 解析与校验 YAML（见 §2）。  
* `src/core/`: 统一的 `TrainerAPI`、`Episode`, `Rollout`, `Checkpoint` 数据结构。  
* `src/strategies/`: 强化策略接口 `Strategy`（如 PPO、DPO 将来可并存）。  
* `src/engines/`: 训练引擎适配层（纯 PyTorch / TRL / Accelerate），实现 `Engine` 抽象。  
* `src/agents/`: 模型封装（加载 base model、tokenizer，forward 输出 logit/value）。  
* `src/callbacks/`: 日志、评估、checkpoint、早停、梯度裁剪、学习率调度等回调。  
* `src/data/`: `JSONLReader`, `Collator`，统一返回 `Batch`（input\_ids、labels、meta）。  
* `src/eval/`: 轻量评测脚手架与影子运行占位（接口即可）。  
* `tests/`: 单测与最小集成测试。  
* `ops/`: 一键脚本（预检、启动、恢复、打包上报）。

---

## **2\) 配置系统（YAML \+ 严格校验）**

创建 `configs/train_local.yaml`（示例）：

run:  
  seed: 20250823  
  output\_dir: "checkpoints/local"  
  save\_steps: 500  
  eval\_steps: 1000  
  max\_steps: 2000        \# 本地小步  
  mixed\_precision: "bf16"  \# MPS 不支持则自动 fp32  
  gradient\_accumulation: 2  
  device\_pref: \["mps","cpu"\]  
  log\_file: "logs/train.log"

data:  
  train\_path: "data/train\_min.jsonl"  
  eval\_path:  "data/eval\_min.jsonl"  
  max\_length: 1024  
  batch\_size: 1

model:  
  base: "Qwen/Qwen2.5-3B-Instruct"   \# 示例，可调整为本地可加载模型  
  lora:  
    enable: true  
    r: 8  
    alpha: 16  
    dropout: 0.05

engine:  
  name: "trl\_ppo"     \# 可选将来: "pure\_pt\_sft", "trl\_dpo" 等  
  target\_kl: 0.03  
  lr: 1.0e-5  
  clip\_coef: 0.2

strategy:  
  name: "ppo"  
  \# 预留策略超参，随时可替换策略实现

callbacks:  
  \- "logging"  
  \- "checkpoint"  
  \- "eval\_shadow"

**要求**

* 写 `src/config/loader.py`：加载后进行**强校验**（必填项/类型/范围），失败即退出码 2。  
* 把最终“有效配置”落盘 `reports/config_effective.yaml`（便于复现）。

---

## **3\) 接口设计（必须按以下命名/签名）**

\# src/core/api.py  
from typing import Protocol, Dict, Any

class Engine(Protocol):  
    def setup(self, cfg: Dict\[str, Any\]) \-\> None: ...  
    def train\_step(self, batch: Dict\[str, Any\]) \-\> Dict\[str, float\]: ...  
    def eval\_step(self, batch: Dict\[str, Any\]) \-\> Dict\[str, float\]: ...  
    def state\_dict(self) \-\> Dict\[str, Any\]: ...  
    def load\_state\_dict(self, state: Dict\[str, Any\]) \-\> None: ...

class Strategy(Protocol):  
    def attach\_engine(self, engine: Engine) \-\> None: ...  
    def on\_batch(self, batch: Dict\[str, Any\]) \-\> Dict\[str, float\]: ...

* `Engine` 封装**引擎差异**（纯 PT / TRL / Accelerate）。  
* `Strategy` 封装**策略差异**（PPO/DPO/…）。  
* 顶层 `Trainer` 调用顺序：`engine.setup()` → 训练循环 `{ batch → strategy.on_batch → engine.train_step }`。  
* 写一个 `src/engines/trl_ppo.py` 和 `src/strategies/ppo.py` 的最小可跑版本（可参考 TRL 典型用法），只要能走完整回路并输出 loss/kl/ratio 等统计即可。

---

## **4\) 数据读取与最小数据集（占位即可）**

* `src/data/readers/jsonl_reader.py`：读取 `{"input": "...", "output": "...", "meta": {...}}` 结构，返回样本字典。  
* `src/data/collate/default.py`：tokenize \+ pad，返回 `Batch`。  
* 提供最小训练/评测集：`data/train_min.jsonl`（≥100 条）、`data/eval_min.jsonl`（≥30 条）。  
* 写 `ops/make_min_data.py` 脚本：若文件缺失，自动生成**占位数据**（确保流水线能跑）。

⚠️ 你只需要保证**格式与流程**正确，内容本身不做要求。

---

## **5\) Checkpoint 与断点续训（必须有）**

* 每 `save_steps` 保存：`checkpoints/local/step_XXXXX/{adapter.bin|model.safetensors,opt.pt,sched.pt,scaler.pt,rng.pkl}`

训练启动 CLI 支持：  
python \-m src.core.launch \--config configs/train\_local.yaml  
python \-m src.core.launch \--config configs/train\_local.yaml \--resume checkpoints/local/step\_05000

*   
* `src/core/checkpoint.py`：统一 `save_ckpt(state, path)` / `load_ckpt(path) -> state`；含 **sha256** 记录到 `reports/ckpt_manifest.jsonl`。

---

## **6\) 日志与上报（必须有）**

* 所有 stdout 持久化到 `logs/train.log`；同时逐步写入 `reports/metrics.jsonl`（step、loss、kl、ratio、lr、mem、time）。  
* 发生异常：  
  1. 立即 `print("FATAL: <msg>")`；  
  2. 写 `reports/ERROR_<ts>.json`（包含 trace、最近 200 行日志）并 **`exit 1`**；  
  3. 不得吞错。  
* 提供 `ops/failpack.sh`：将 `logs/`、`reports/`、`configs/` 打包为 `reports/FAIL_<ts>.tgz`。

---

## **7\) 一键脚本与 Makefile（必须可用）**

**一键脚本**：`ops/run_local.sh`

\#\!/usr/bin/env bash  
set \-euo pipefail  
source .venv/bin/activate  
python \-m src.config.verify \--config configs/train\_local.yaml  
python \-m ops.make\_min\_data || true  
python \-m src.core.launch \--config configs/train\_local.yaml 2\>&1 | tee \-a logs/train.log

**Makefile**：

.PHONY: preflight run resume test failpack

preflight:  
\\tpython \-m src.config.verify \--config configs/train\_local.yaml

run:  
\\tpython \-m ops.make\_min\_data || true  
\\tpython \-m src.core.launch \--config configs/train\_local.yaml | tee \-a logs/train.log

resume:  
\\tpython \-m src.core.launch \--config configs/train\_local.yaml \--resume checkpoints/local/latest | tee \-a logs/train.log

test:  
\\tpytest \-q

failpack:  
\\ttar \-czf reports/FAIL\_$(shell date \+%Y%m%d\_%H%M%S).tgz logs reports configs || true

---

## **8\) 单元测试（最少 4 条，pytest 必过）**

* `tests/test_config.py`：无效 YAML/缺键应退出码 2。  
* `tests/test_device.py`：MPS 可用时返回 “mps”，否则 “cpu”。  
* `tests/test_ckpt.py`：保存→加载后参数一致。  
* `tests/test_train_smoke.py`：加载 10 条数据、跑 20 step，`metrics.jsonl` 有递增 step 与 loss 记录。

---

## **9\) 预检闸门（本地必须 PASS 才算完工）**

运行：

make preflight && make run

**验收标准**

* 在 MPS/CPU 上**完整跑完** `max_steps`（2000 步可调小），`logs/train.log` 无未处理异常；  
* `checkpoints/local/step_*` 连续产出 ≥ 3 个，`checkpoints/local/latest` 指向最新；  
* `reports/metrics.jsonl` 至少包含字段：`step,loss,kl,ratio,lr,mem_used_mb,sec_per_step`；  
* `reports/config_effective.yaml` 与 `reports/ckpt_manifest.jsonl` 存在；  
* 运行 `python -m src.core.launch --config configs/train_local.yaml --resume checkpoints/local/latest` 能继续训练，`step` 单调递增。

---

## **10\) 提交要求（禁止篡改历史）**

* 提交前运行：`pytest -q` 全部通过；  
* Commit 模板：

git add \-A  
git commit \-m "feat(training): modular TrainerAPI \+ TRL-PPO engine \+ resume/checkpoint  
\- device: MPS/CPU auto  
\- config: strict yaml validation; effective dump  
\- data: jsonl reader \+ minimal dataset generator  
\- logs/metrics: jsonl \+ tee  
\- ckpt: step\_x manifest+sha256  
\- make: preflight/run/resume/test/failpack"

* 上报文件：`logs/train.log`、`reports/metrics.jsonl`（末 50 行）、`reports/config_effective.yaml`、`reports/ckpt_manifest.jsonl`、`tree -L 3` 截图。

---

## **11\) 失败处理（必须上报）**

任何失败，执行：

make failpack

将生成的 `reports/FAIL_*.tgz` 发送给负责人复盘。

---

### **备注给你（Cursor）**

* 先把**框架跑通**是最高优先级；策略、数据源、奖励模型都将通过本框架**热插拔**替换。  
* 所有实现以**稳定性与可审计**为第一原则：配置强校验、日志完整、断点可恢复。  
* 请勿进行任何“只在你机器上能跑”的写法；确保默认配置即能在 **MPS/CPU** 小步跑通。

交付时间：完成以上 §0–§9 的骨架与最小可跑回路后，提交日志与报告，我会下发下一轮迭代（接入评测脚手架与策略变体切换）。

---

好提醒！我刚刚复核了我们给 cursor 的本地配置，确实有一处与实际底模不一致。我已把**所有涉及基础模型的地方**统一为：

**`Qwen/Qwen3-4B-Thinking-2507`**

下面给你一份一次性“修订补丁”，你把它发给 cursor 覆盖即可（包含 YAML 配置、环境变量、LoRA 目标层与 MPS 细节）。

---

# **更新包：把底模统一为 Qwen/Qwen3-4B-Thinking-2507**

## **1\) 覆盖配置：`configs/train_local.yaml`**

把之前示例改成下面这一版（已按 MPS 友好参数调整）：

run:

  seed: 20250823

  output\_dir: "checkpoints/local"

  save\_steps: 500

  eval\_steps: 1000

  max\_steps: 2000

  mixed\_precision: "fp16"         \# MPS 更稳妥用 fp16

  gradient\_accumulation: 2

  device\_pref: \["mps","cpu"\]

  log\_file: "logs/train.log"

data:

  train\_path: "data/train\_min.jsonl"

  eval\_path:  "data/eval\_min.jsonl"

  max\_length: 1024

  batch\_size: 1

  padding\_side: "right"

model:

  base: "Qwen/Qwen3-4B-Thinking-2507"

  trust\_remote\_code: true          \# Qwen 系列通常需要

  use\_flash\_attention\_2: false     \# MPS/CPU 关闭 FA2

  use\_cache: false                 \# 训练时禁用 cache

  gradient\_checkpointing: true

  lora:

    enable: true

    r: 8

    alpha: 16

    dropout: 0.05

    target\_modules: \["q\_proj","k\_proj","v\_proj","o\_proj","gate\_proj","up\_proj","down\_proj"\]

engine:

  name: "trl\_ppo"

  target\_kl: 0.03

  lr: 1.0e-5

  clip\_coef: 0.2

  max\_grad\_norm: 1.0

strategy:

  name: "ppo"

callbacks:

  \- "logging"

  \- "checkpoint"

  \- "eval\_shadow"

### **为什么这样改**

* **fp16**：MPS 对 bf16 支持不一致，fp16 更稳。  
* **trust\_remote\_code: true**：Qwen-Thinking 分支常用到自定义模块。  
* **use\_cache: false / gradient\_checkpointing: true**：节省显存、便于继续训练。  
* **LoRA target\_modules**：覆盖注意力与 MLP 三路的常见线性层，后续可按显存删减。

---

## **2\) 环境变量与脚本里的模型名（统一替换）**

如果你之前给了环境变量或脚本默认值，统一替换为下面这一句：

\# 例如 ops/run\_local.sh / 任何一键脚本开头

export BASE\_MODEL="Qwen/Qwen3-4B-Thinking-2507"

一键替换命令（在仓库根目录执行）：

grep \-RIl "Qwen/Qwen2.5-3B-Instruct" | xargs sed \-i '' 's\#Qwen/Qwen2.5-3B-Instruct\#Qwen/Qwen3-4B-Thinking-2507\#g'

---

## **3\) 代理层/装载层小修（给 cursor 放到相应文件）**

* **Tokenizer padding**：若无 pad token，设为 eos，避免 batch pad 报错。  
* **MPS 自动选择与 dtype**：优先 `mps`，否则 `cpu`；dtype 设为 `torch.float16`。

\# src/agents/loader\_qwen.py 里的要点（示意）

from transformers import AutoModelForCausalLM, AutoTokenizer

import torch, os

def load\_qwen(base):

    tok \= AutoTokenizer.from\_pretrained(base, trust\_remote\_code=True)

    if tok.pad\_token\_id is None:

        tok.pad\_token \= tok.eos\_token

    dtype \= torch.float16

    dev \= "mps" if torch.backends.mps.is\_available() else "cpu"

    model \= AutoModelForCausalLM.from\_pretrained(

        base,

        trust\_remote\_code=True,

        torch\_dtype=dtype,

        device\_map=None  \# MPS/CPU 手动 .to()

    )

    model.to(dev)

    model.config.use\_cache \= False

    return model, tok, torch.device(dev)

TRL PPO 侧请继续用 `AutoModelForCausalLMWithValueHead` 包一层；`use_cache=False`、`gradient_checkpointing=True` 要在包装前设置好。

---

## **4\) 预检自测（cursor 立即执行）**

\# 重新创建环境并自检

python3 \-m venv .venv && source .venv/bin/activate

pip install \-U pip wheel

pip install "torch\>=2.3" "transformers\>=4.43" "accelerate\>=0.30" "trl\>=0.9" \\

            "peft\>=0.11" "datasets\>=2.19" "evaluate\>=0.4" tqdm pyyaml jsonlines

python \- \<\<'PY'

import torch, platform

print("DEVICE:", "mps" if torch.backends.mps.is\_available() else "cpu", platform.platform())

PY

\# 用新的 YAML 跑最小回路

make preflight && make run

出现以下即视为通过：

* `logs/train.log` 正常追加，无未处理异常；  
* `reports/metrics.jsonl` 有 step/loss/kl/ratio 等键；  
* `checkpoints/local/step_*` 周期落盘，`latest` 指向最新；  
* `python -m src.core.launch --config configs/train_local.yaml --resume checkpoints/local/latest`能继续训练。

---

