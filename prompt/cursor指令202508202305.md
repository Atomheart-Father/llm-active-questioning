没问题，我来当“总工”，给 cursor 一份**一键可执行的全量核查工单**。目标：**先固化 seed pool，再做两轮预检（Round 1→补缺→Round 2），全部 PASS 才能启动 RC1 真实训练**。

---

# **给 cursor 的工单：RC1 训练前“二轮预检 \+ 种子池固化”🚦**

约定：本工单所有命令在仓库根目录执行；任何 FAIL 必须先修复再进下一步。最终需产出 `reports/preflight/round2_pass.json` 才能开跑。

## **0\) 生产模式硬约束（立即执行）**

\# 强制生产模式（禁用一切模拟）  
export RUN\_MODE=prod  
export BASE\_MODEL="Qwen/Qwen3-4B-Thinking-2507"  
export SCORER\_PROVIDER=deepseek\_r1  
export SCORER\_API\_KEY=\<填入真实Key\>

\# 目录就绪  
mkdir \-p reports/preflight reports/rc1 data/rollouts checkpoints/rc1/best

---

## **1\) 固化影子评测集 & 种子池（seed pool）**

\# 1.1 物化影子集（与Phase 2口径一致），并输出manifest与sha256  
python \-m src.evaluation.shadow\_run \--n 245 \--seed 20250820 \--stratify \\  
  \--materialize data/shadow\_eval\_245.jsonl \--dump-manifest reports/rc1/sample\_manifest.json  
sha256sum data/shadow\_eval\_245.jsonl \> reports/rc1/shadow\_eval\_245.sha256

\# 1.2 生成30k种子池（可改n=20000\~40000）  
python scripts/build\_rollout\_pool.py \\  
  \--out data/rollouts/rc1\_seed.jsonl \\  
  \--n 30000 \\  
  \--mix "hotpotqa:0.45,strategyqa:0.30,gsm8k:0.25" \\  
  \--max\_turns 6 \--clarify\_rate 0.30 \\  
  \--tools "wiki,calc" \\  
  \--templates\_dir templates/pack\_v2

\# 1.3 种子池质量体检（必须全部PASS）  
python scripts/validate\_pool.py data/rollouts/rc1\_seed.jsonl \\  
  \--min\_distinct2 0.60 \--kl3\_min 0.15 \--roles\_min 4 \--styles\_min 3 \\  
  \--max\_dup\_pct 2.0 \--max\_len 4096 \--min\_len 64 \\  
  \--leak\_check data/shadow\_eval\_245.jsonl \--leak\_ngram 5 \--leak\_sim 0.85 \\  
  \--by\_task "hotpotqa,strategyqa,gsm8k"  
sha256sum data/rollouts/rc1\_seed.jsonl \> reports/rc1/rc1\_seed.sha256

**判定标准（全部必须满足）**

* `distinct-2 ≥ 0.60`；`3-gram KL ≥ 0.15`；角色≥4、语体≥3；  
* 去重后重复率 ≤2%；长度在 `[64,4096]`；  
* **无泄漏**：与影子集 `n≥5` n-gram 高相似样本相似度 ≤0.85（应为0样本/0%）；  
* 任务配比≈设定（允差±3pp）。

---

## **2\) 奖励系统与权重校准就绪检查**

\# 2.1 权重文件与报告  
test \-f configs/weights.json || (echo "缺少权重文件" && exit 2\)  
python \- \<\<'PY'  
import json,sys,hashlib,os,datetime  
w=json.load(open("configs/weights.json"))  
wsum=sum(w\["weights"\].values())  
assert abs(wsum-1.0)\<1e-6, "权重未归一化"  
assert max(w\["weights"\].values())\<=0.5+1e-9, "存在单维\>0.5"  
for k,v in w\["weights"\].items(): assert v\>=0, f"权重负值:{k}"  
print("WEIGHTS\_OK",hashlib.sha256(open("configs/weights.json","rb").read()).hexdigest())  
PY

\# 2.2 过度澄清惩罚启用与单测  
grep \-q "use\_overclar\_penalty: true" configs/ppo\_scale.yaml || (echo "未启用过度澄清惩罚" && exit 2\)  
pytest \-q tests/test\_overclar\_penalty.py

**判定标准**

* `configs/weights.json` 存在、**非负且归一**、`max(w_i) ≤ 0.5`；  
* `use_overclar_penalty: true`，相关单测通过。

---

## **3\) 打分器连通性 & 反模拟闸门**

\# 3.1 真打分探针（必须有真实账单调用与延迟统计）  
python scripts/probe\_scorer.py \--n 8 \--provider $SCORER\_PROVIDER \--live

\# 3.2 防伪检查（必须PASS；命中率阈值首轮更严：\<90%）  
python scripts/assert\_not\_simulated.py \--cache\_hit\_lt 0.90

**判定标准**

* 最近100条评分 `billable_count ≥ 1`；`latency_ms > 0`；缓存命中率 \< 90%；  
* `RUN_MODE=prod`、`simulate=false`；**严禁 fallback 到 mock**。

---

## **4\) 强化学习策略与配置一致性**

python \- \<\<'PY'  
import yaml,sys  
cfg=yaml.safe\_load(open("configs/ppo\_scale.yaml"))  
assert cfg.get("simulate",False)==False, "simulate 应为 false"  
assert cfg.get("live\_mode",True)==True, "live\_mode 应为 true"  
assert cfg.get("datasets")=={'hotpotqa':0.45,'strategyqa':0.30,'gsm8k':0.25}, "数据配比不一致"  
assert cfg.get("steps",0)\>=50000, "steps\<50k"  
kl=cfg.get("target\_kl",0.03); assert 0.02\<=kl\<=0.05, "target\_kl 异常"  
seeds=cfg.get("seeds",\[20250820,20250821,20250822\]); assert len(seeds)\>=3, "seeds\<3"  
ft=cfg.get("finetune",{}); assert ft.get("method")=="qlora", "建议使用QLoRA"  
print("PPO\_CFG\_OK")  
PY

**判定标准**

* 模式：`simulate=false`、`live_mode=true`；  
* 数据配比与步数达标；KL 目标合理；三 seed；QLoRA 已启用。

---

## **5\) 资源与产物存储预检**

python \- \<\<'PY'  
import shutil,os,sys  
free\_gb=shutil.disk\_usage(".").free/2\*\*30  
assert free\_gb\>50, f"磁盘不足：{free\_gb:.1f}GB"  
print("DISK\_OK",f"{free\_gb:.1f}GB")  
PY

\# 可选：显存/Metal 预检（按你们环境实现）  
\# 例如nvidia-smi | grep 'MiB'...

**判定标准**

* 磁盘可用 \> 50GB（含日志/检查点/量化产物冗余）。

---

## **6\) Round 1 预检聚合并出报告**

python \- \<\<'PY'  
import json,os,glob,hashlib,datetime  
report={"round":"round1","ts":datetime.datetime.utcnow().isoformat()+"Z"}  
def sha(p):   
  try: return hashlib.sha256(open(p,"rb").read()).hexdigest()  
  except: return None  
report\["files"\]={  
  "shadow\_eval":"data/shadow\_eval\_245.jsonl",  
  "shadow\_eval\_sha":sha("data/shadow\_eval\_245.jsonl"),  
  "seed\_pool":"data/rollouts/rc1\_seed.jsonl",  
  "seed\_pool\_sha":sha("data/rollouts/rc1\_seed.jsonl"),  
  "weights":"configs/weights.json",  
  "weights\_sha":sha("configs/weights.json"),  
  "ppo\_cfg":"configs/ppo\_scale.yaml",  
}  
open("reports/preflight/round1.json","w").write(json.dumps(report,indent=2))  
print("PRE-R1-REPORT: reports/preflight/round1.json")  
PY

**若任何前面步骤 FAIL/未达标**：就地修复（补样本、调权重、修配置/Key、扩磁盘…），再重新跑对应步骤，直至 Round 1 全 PASS。

---

## **7\) Round 2 复核（更接近实战口径）**

* 重新跑第 **1–5 步**，只改两点：

防伪脚本缓和缓存阈值到 `<95%`：  
python scripts/assert\_not\_simulated.py \--cache\_hit\_lt 0.95

1. 

追加一次**影子运行干预检查**（以种子池的新权重/惩罚口径）：  
python \-m src.evaluation.shadow\_run \--n 245 \--seed 20250820 \--stratify \--tag "pre\_run\_check"

2.   
* 聚合出 **Round 2** 报告：

python \- \<\<'PY'  
import json,datetime  
r={"round":"round2","ts":datetime.datetime.utcnow().isoformat()+"Z","pass":True}  
open("reports/preflight/round2\_pass.json","w").write(json.dumps(r,indent=2))  
print("PRE-R2-REPORT: reports/preflight/round2\_pass.json")  
PY

---

## **8\) 只有当 `reports/preflight/round2_pass.json` 存在时才能启动训练**

**启动命令（此时才允许执行）：**

test \-f reports/preflight/round2\_pass.json || (echo "预检未通过：禁止开跑" && exit 2\)

\# 在 ppo\_scale.yaml 中加入：  
\# seed\_pool: "data/rollouts/rc1\_seed.jsonl"  
\# priority\_sampling: {enable: true, low\_perf\_cap: 0.30, seed\_ratio: 0.5}

python \-m train.ppo\_runner \--config configs/ppo\_scale.yaml

---

好主意！我在原“二轮预检 \+ 种子池固化”流程的基础上，\*\*补充“数据难度核查与难度采样”\*\*整套规范（含脚本、指标、阈值、分布目标与训练接入）。你直接把这段和上一个工单合并给 cursor 执行即可。

---

# **🔧 新增章节：数据难度核查与难度采样（面向推理强化）**

目标：确保用于 RC1 的训练/评测数据在**长度、对话轮次、逻辑复杂度、工具调用链条、数值运算难度**等维度达到既定分布；并把“难度”接入到 **采样/奖励/评测** 全链路。

## **新增文件**

scripts/difficulty\_metrics.py       \# 逐样本难度指标抽取  
scripts/difficulty\_bucketize.py     \# 难度分桶与目标分布校验、重采样  
scripts/validate\_difficulty.py      \# 难度体检（阈值/分布/越界检查）  
reports/rc1/difficulty\_report.json  \# 聚合报告（直方图/分位数/按任务拆分）

## **一、难度指标定义（逐样本产生 JSON 结构）**

对每条样本（问题/上下文/对话轨迹）输出：

{  
  "id": "uuid",  
  "task": "hotpotqa|strategyqa|gsm8k",  
  "len\_tokens": 512,                 // prompt+上下文的总token数（估算器即可）  
  "turns": 4,                        // 对话轮次数（问答或澄清轮次）  
  "tool\_hops": 3,                    // 工具调用次数（含失败重试）  
  "entities": 6,                     // 去重后的实体数（NER或简易专名/大写词/中文名词正则）  
  "ops\_numeric": 3,                  // 推断的算术操作数（+,-,×,÷,比较、日期差等）  
  "connector\_density": 6.2,          // 每100词中的逻辑连接词密度（and/because/if/then/因此/从而/同时…）  
  "coref\_pronouns": 5,               // 指代词数（it/they/this/that/其/他/她/它 等）  
  "clue\_overlap": 0.18,              // 线索重叠率：问句 vs 支撑文本 n-gram Jaccard  
  "ambiguity\_flags": \["under-specified","multi-entity"\],  
  "needs\_clarification": true  
}

**计算要点（实现简化即可）**

* `len_tokens`：用 BPE 估算器（或近似：字/词数×系数）。  
* `turns`：对话轮次数，澄清问答也计入。  
* `tool_hops`：从日志/轨迹统计 `wiki/calc/检索` 等工具调用次数。  
* `entities`：用简易规则：英文大写开头的专名+数字+中文专名正则（`[A-Z][a-z]+`、`[一-龥]{2,4}`）去重计数。  
* `ops_numeric`：从文本提取表达式，统计 `+ - * / % > < =`、日期/时间差关键词。  
* `connector_density`：连接词表（中英）/100 词密度。  
* `clue_overlap`：问句与上下文的 **3-gram Jaccard**；**越低表示越难**。  
* `ambiguity_flags`：包含多实体、指代不清、时间范围未定等的规则命中。

运行：

python scripts/difficulty\_metrics.py \\  
  \--in data/rollouts/rc1\_seed.jsonl \\  
  \--out data/rollouts/rc1\_seed.metrics.jsonl

## **二、难度分桶与分布目标**

按下表将样本分到 **Easy / Medium / Hard**（只需命中多数条件即可；实现按“得分”聚合也行）：

| 维度 | Easy | Medium | Hard |
| ----- | ----- | ----- | ----- |
| `len_tokens` | \< 200 | 200–600 | \> 600 |
| `turns` | ≤ 2 | 3–4 | ≥ 5 |
| `tool_hops` | 0–1 | 2–3 | ≥ 4 |
| `ops_numeric` | 0–1 | 2–3 | ≥ 4 |
| `entities` | ≤ 3 | 4–6 | ≥ 7 |
| `connector_density` (每100词) | \< 3 | 3–6 | \> 6 |
| `clue_overlap` | \> 0.40 | 0.20–0.40 | \< 0.20 |
| `needs_clarification` | false | mixed | true 且 turns≥4 |

**全库目标分布（按任务分别控制）**

* **Hard：30–40%**  
* **Medium：40–50%**  
* **Easy：20–30%**

执行分桶与重采样，产出对齐目标分布的 **最终训练池**：

python scripts/difficulty\_bucketize.py \\  
  \--metrics data/rollouts/rc1\_seed.metrics.jsonl \\  
  \--target "easy:0.25,medium:0.45,hard:0.30" \\  
  \--by\_task "hotpotqa,strategyqa,gsm8k" \\  
  \--out data/rollouts/rc1\_seed.balanced.jsonl

## **三、难度体检与准入阈值（新增预检 Step）**

新增 **Step 1.4 & 1.5**（插入到“种子池固化”后）：

\# 1.4 难度体检（直方图/分位数/越界）  
python scripts/validate\_difficulty.py \\  
  \--metrics data/rollouts/rc1\_seed.metrics.jsonl \\  
  \--balanced data/rollouts/rc1\_seed.balanced.jsonl \\  
  \--min\_hard\_pct 0.30 \--max\_easy\_pct 0.30 \\  
  \--len\_max 3500 \--turns\_max 8 \--tool\_hops\_max 8 \\  
  \--clue\_overlap\_max\_easy 0.65 \--clue\_overlap\_min\_hard 0.10 \\  
  \--out reports/rc1/difficulty\_report.json

\# 1.5 记录指纹（面向可复现）  
sha256sum data/rollouts/rc1\_seed.metrics.jsonl \> reports/rc1/rc1\_seed.metrics.sha256  
sha256sum data/rollouts/rc1\_seed.balanced.jsonl \> reports/rc1/rc1\_seed.balanced.sha256

**必须全部满足**

* 平衡后 **Hard ≥30%**、**Easy ≤30%**（按任务单独核对亦达标）。  
* 长度/轮次/工具链均未超过上限（避免越界至上下文/执行极限）。  
* `clue_overlap`：hard 的**中位数 ≤ 0.20**；easy 的**中位数 ≥ 0.40**。  
* 输出 `difficulty_report.json` 含：直方图、分位数（p10/50/90）、任务拆分与分桶计数。

## **四、把“难度”接入训练与评测**

### **4.1 训练采样（难度感知）**

在 `configs/ppo_scale.yaml` 增加：

seed\_pool: "data/rollouts/rc1\_seed.balanced.jsonl"  
priority\_sampling:  
  enable: true  
  by\_difficulty: {easy: 0.2, medium: 0.4, hard: 0.4}    \# 训练采样权重  
  low\_perf\_cap: 0.30  
  seed\_ratio\_schedule:  
    \- {step: 0,   ratio: 0.50}  
    \- {step: 20000, ratio: 0.35}  
    \- {step: 40000, ratio: 0.20}

### **4.2 奖励微调（可选，但建议）**

在 `advanced_reward_system.py` 聚合前加入难度加权（避免“刷易题”）：

reward \= base\_reward \* (1 \+ beta \* (I\[hard\] \- I\[easy\]))  
\# 建议 beta \= 0.05\~0.10；确保不过拟合到“苦难奖励”

### **4.3 评测拆分（影子运行 & RC1 报告）**

* `shadow_run` 与 PPO 报告中**新增“按难度拆分”**：  
  * `success_easy/medium/hard`、`delta_pp`、`overclar_rate_*`、`avg_turns_*`。  
* **RC1 门槛追加一条**：Hard 桶的成功率提升 **≥ \+5pp**（HotpotQA/StrategyQA 合并口径）。

## **五、失败快速定位（若难度不达标）**

* **Hard 不足**：提高 `--target hard`；或放宽 hard 的判定（例如 `tool_hops≥3` 即计 hard）。  
* **长度越界多**：上调 `max_len` 检查或裁剪长上下文；同时验证底模 max\_seq\_len。  
* **clue\_overlap 偏高**：加强 paraphrase/多来源检索生成，降低问句与支持文本重叠。  
* **ops\_numeric 过低**：引入更多需要多步计算的模板（日期差、比例变化、级联运算）。  
* **turns 偏低**：提升 `clarify_rate` 或在模板里强制 1–2 次“必要澄清”。

---

# **🧭 集成到“二轮预检”中的位置**

* 放在 **步骤 1\) 种子池固化** 之后，作为 **Step 1.4/1.5**；  
* **Round 1** 和 **Round 2** 两轮预检里都要检查 `reports/rc1/difficulty_report.json` 是否达标；  
* 若不达标：**补数据 → 重跑 metrics/bucketize/validate → 再核查**；两轮全部 PASS 后才允许启动训练。

---

这样一来，数据不只是“量够、多样性达标”，还在**推理难度维度**上有明确的 **阈值、分布与准入控制**，且直接影响**采样、奖励与评测**。你把这部分拼进上一条工单发给 cursor，他就能按表操作。

# **PM（你）的“看灯口径”**

本次“二轮预检”视作**启动前试车**：

* **数据**：`rc1_seed.jsonl`（30k±，多样性/泄漏/配比 PASS）+ 影子集落盘并有 SHA。  
* **奖励**：`weights.json` 合法、惩罚启用、单测通过。  
* **评分**：真 API 连通，缓存阈值控制（R1\<90%，R2\<95%），无 fallback。  
* **策略**：PPO 配置与 QLoRA 就绪，KL 目标合理，三 seed。  
* **资源**：磁盘充足，目录/日志位齐全。  
* **证据**： `reports/preflight/round1.json` 与 `round2_pass.json` 均在。

你把这份工单发给 cursor 执行，两轮全部 PASS 后，我再给“开跑后监控与中途闸门”的轻量 Runbook（以及失败快速定位表）。

