#!/usr/bin/env python3
"""
ä¸´æ—¶è„šæœ¬ï¼šå¢å¼ºè´¨æ£€è„šæœ¬v1.1
æ·»åŠ è¯æ®å…³è”åº¦è®¡ç®—ã€è®¸å¯ç™½åå•ã€å¤±è´¥åŸå› ç»Ÿè®¡
"""

import json
import re
from collections import Counter
from pathlib import Path

def calculate_evidence_overlap(questions, context):
    """è®¡ç®—æ¾„æ¸…é—®å¥ä¸ä¸Šä¸‹æ–‡çš„è¯é¢é‡å åº¦"""
    if not questions or not context:
        return 0.0

    # ç®€å•åˆ†è¯ï¼ˆå»é™¤æ ‡ç‚¹å’Œåœç”¨è¯ï¼‰
    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'as', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'what', 'when', 'where', 'who', 'why', 'how', 'which', 'that', 'this', 'these', 'those'}

    def tokenize(text):
        # ç®€å•åˆ†è¯ï¼šå»é™¤æ ‡ç‚¹ï¼Œè½¬æ¢ä¸ºå°å†™
        words = re.findall(r'\b\w+\b', text.lower())
        return [w for w in words if w not in stop_words and len(w) > 2]

    # å¯¹æ‰€æœ‰é—®é¢˜è¿›è¡Œåˆ†è¯å¹¶åˆå¹¶
    all_question_tokens = set()
    for q in questions:
        all_question_tokens.update(tokenize(q))

    # å¯¹ä¸Šä¸‹æ–‡è¿›è¡Œåˆ†è¯
    context_tokens = set(tokenize(context))

    if not all_question_tokens:
        return 0.0

    # è®¡ç®—é‡å åº¦
    overlap = len(all_question_tokens.intersection(context_tokens))
    return overlap / len(all_question_tokens)

def validate_license_whitelist(license_str):
    """éªŒè¯è®¸å¯æ˜¯å¦åœ¨ç™½åå•ä¸­"""
    whitelist = {'cc-by-sa-3.0', 'cc-by-sa-4.0', 'mit', 'apache-2.0'}
    return license_str in whitelist

def enhance_quality_checks():
    """å¢å¼ºè´¨æ£€è„šæœ¬çš„ä¸»è¦é€»è¾‘"""

    print("=== å¢å¼ºè´¨æ£€è„šæœ¬ v1.1 ===")

    # è¯»å–ç°æœ‰çš„è´¨æ£€è„šæœ¬
    original_script = Path("tools/stage2_quality_checks_v1.py")
    if not original_script.exists():
        print("âŒ æ‰¾ä¸åˆ°åŸå§‹è´¨æ£€è„šæœ¬")
        return

    with open(original_script, 'r', encoding='utf-8') as f:
        content = f.read()

    print("ğŸ“– è¯»å–åŸå§‹è´¨æ£€è„šæœ¬æˆåŠŸ")

    # å¢å¼ºå†…å®¹
    enhancements = []

    # 1. æ·»åŠ è¯æ®å…³è”åº¦è®¡ç®—å‡½æ•°
    evidence_overlap_func = '''
def calculate_evidence_overlap(questions, context):
    """è®¡ç®—æ¾„æ¸…é—®å¥ä¸ä¸Šä¸‹æ–‡çš„è¯é¢é‡å åº¦"""
    if not questions or not context:
        return 0.0

    # ç®€å•åˆ†è¯ï¼ˆå»é™¤æ ‡ç‚¹å’Œåœç”¨è¯ï¼‰
    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'as', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'what', 'when', 'where', 'who', 'why', 'how', 'which', 'that', 'this', 'these', 'those'}

    def tokenize(text):
        # ç®€å•åˆ†è¯ï¼šå»é™¤æ ‡ç‚¹ï¼Œè½¬æ¢ä¸ºå°å†™
        words = re.findall(r'\\b\\w+\\b', text.lower())
        return [w for w in words if w not in stop_words and len(w) > 2]

    # å¯¹æ‰€æœ‰é—®é¢˜è¿›è¡Œåˆ†è¯å¹¶åˆå¹¶
    all_question_tokens = set()
    for q in questions:
        all_question_tokens.update(tokenize(q))

    # å¯¹ä¸Šä¸‹æ–‡è¿›è¡Œåˆ†è¯
    context_tokens = set(tokenize(context))

    if not all_question_tokens:
        return 0.0

    # è®¡ç®—é‡å åº¦
    overlap = len(all_question_tokens.intersection(context_tokens))
    return overlap / len(all_question_tokens)
'''

    # 2. æ·»åŠ è®¸å¯ç™½åå•éªŒè¯å‡½æ•°
    license_func = '''
def validate_license_whitelist(license_str):
    """éªŒè¯è®¸å¯æ˜¯å¦åœ¨ç™½åå•ä¸­"""
    whitelist = {'cc-by-sa-3.0', 'cc-by-sa-4.0', 'mit', 'apache-2.0'}
    return license_str in whitelist
'''

    # 3. å¢å¼ºQualityCheckerç±»
    class_enhancement = '''
    def __init__(self):
        self.required_fields = [
            "uid", "user_query", "needs_clarification",
            "clarification_questions", "provided_context",
            "assistant_response", "task_type", "source",
            "licensing", "gen_meta"
        ]
        self.license_whitelist = {'cc-by-sa-3.0', 'cc-by-sa-4.0', 'mit', 'apache-2.0'}
        self.drop_reasons = Counter()
        self.evidence_overlaps = []
'''

    # 4. æ·»åŠ è¯æ®å…³è”åº¦æ£€æŸ¥
    evidence_check = '''
    def check_evidence_overlap(self, samples):
        """æ£€æŸ¥è¯æ®å…³è”åº¦ï¼ˆHotpotQA/ASQAé€‚ç”¨ï¼‰"""
        overlaps = []
        for sample in samples:
            if sample.get('source') in ['hotpotqa', 'asqa']:
                overlap = calculate_evidence_overlap(
                    sample.get('clarification_questions', []),
                    sample.get('provided_context', '')
                )
                overlaps.append(overlap)
                sample['_evidence_overlap'] = overlap
            else:
                sample['_evidence_overlap'] = None

        return overlaps
'''

    # 5. å¢å¼ºè®¸å¯æ£€æŸ¥
    license_check = '''
    def check_license_whitelist(self, samples):
        """æ£€æŸ¥è®¸å¯ç™½åå•"""
        errors = []
        for i, sample in enumerate(samples):
            license_str = sample.get('licensing', '')
            if not validate_license_whitelist(license_str):
                errors.append({
                    'sample_index': i,
                    'license': license_str,
                    'reason': 'invalid_license'
                })

        return errors
'''

    # 6. å¢å¼ºå¤±è´¥åŸå› ç»Ÿè®¡
    failure_stats = '''
    def update_drop_reasons(self, reason):
        """æ›´æ–°å¤±è´¥åŸå› ç»Ÿè®¡"""
        self.drop_reasons[reason] += 1
'''

    # 7. å¢å¼ºrun_quality_checksæ–¹æ³•
    run_enhancement = '''
    def run_quality_checks(self, samples):
        """è¿è¡Œæ‰€æœ‰è´¨é‡æ£€æŸ¥ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        print("Running enhanced quality checks...")

        # åŸºç¡€æ£€æŸ¥
        field_results = self.check_field_completeness(samples)
        question_results = self.check_clarification_questions(samples)
        type_results = self.check_task_type_enum(samples)
        license_results = self.check_licensing_format(samples)
        text_results = self.check_text_lengths(samples)
        duplicate_results = self.check_near_duplicates(samples)

        # æ–°å¢æ£€æŸ¥
        evidence_overlaps = self.check_evidence_overlap(samples)
        license_errors = self.check_license_whitelist(samples)

        # è®¡ç®—ç»Ÿè®¡
        total_samples = len(samples)
        alignment_errors = question_results['alignment_errors']

        # æŒ‰åˆ†ç‰‡ç»Ÿè®¡
        by_shard = self.calculate_by_shard_stats(samples)

        # è¯æ®å…³è”åº¦ç»Ÿè®¡
        if evidence_overlaps:
            evidence_stats = {
                'mean': sum(evidence_overlaps) / len(evidence_overlaps),
                'min': min(evidence_overlaps),
                'max': max(evidence_overlaps),
                'count': len(evidence_overlaps)
            }
        else:
            evidence_stats = {'mean': 0.0, 'min': 0.0, 'max': 0.0, 'count': 0}

        return {
            'total_samples': total_samples,
            'field_completeness': field_results,
            'clarification_questions': question_results,
            'task_type_enum': type_results,
            'licensing_format': license_results,
            'text_lengths': text_results,
            'near_duplicates': duplicate_results,
            'evidence_overlap': evidence_stats,
            'license_whitelist_errors': license_errors,
            'by_shard': by_shard,
            'drop_reasons': dict(self.drop_reasons)
        }
'''

    # 8. æ·»åŠ æŒ‰åˆ†ç‰‡ç»Ÿè®¡æ–¹æ³•
    shard_stats = '''
    def calculate_by_shard_stats(self, samples):
        """è®¡ç®—æŒ‰åˆ†ç‰‡çš„ç»Ÿè®¡ä¿¡æ¯"""
        from collections import defaultdict

        shard_stats = defaultdict(lambda: {
            'total': 0,
            'alignment_ok': 0,
            'duplicates': 0,
            'evidence_overlaps': []
        })

        for sample in samples:
            source = sample.get('source', 'unknown')
            shard_stats[source]['total'] += 1

            # å¯¹é½æ£€æŸ¥
            questions = sample.get('clarification_questions', [])
            response = sample.get('assistant_response', '')
            if questions and response:
                expected_answers = len(questions)
                actual_answers = response.count('ï¼›') + 1
                if expected_answers == actual_answers:
                    shard_stats[source]['alignment_ok'] += 1

            # è¯æ®å…³è”åº¦
            if '_evidence_overlap' in sample and sample['_evidence_overlap'] is not None:
                shard_stats[source]['evidence_overlaps'].append(sample['_evidence_overlap'])

        # è®¡ç®—å¹³å‡å€¼
        for source, stats in shard_stats.items():
            if stats['evidence_overlaps']:
                stats['evidence_overlap_mean'] = sum(stats['evidence_overlaps']) / len(stats['evidence_overlaps'])
            else:
                stats['evidence_overlap_mean'] = 0.0
            del stats['evidence_overlaps']  # æ¸…ç†åŸå§‹æ•°æ®

        return dict(shard_stats)
'''

    # ç»„åˆæ‰€æœ‰å¢å¼º
    enhanced_content = content
    enhanced_content = enhanced_content.replace(
        "import argparse",
        "import argparse\nimport re"
    )

    # æ·»åŠ æ–°å‡½æ•°
    enhanced_content = enhanced_content.replace(
        "class QualityChecker:",
        f"{evidence_overlap_func}\n{license_func}\nclass QualityChecker:"
    )

    # å¢å¼º__init__æ–¹æ³•
    enhanced_content = enhanced_content.replace(
        "    def __init__(self):",
        "    def __init__(self):\n        self.license_whitelist = {'cc-by-sa-3.0', 'cc-by-sa-4.0', 'mit', 'apache-2.0'}\n        self.drop_reasons = Counter()\n        self.evidence_overlaps = []"
    )

    # æ·»åŠ æ–°æ–¹æ³•
    enhanced_content = enhanced_content.replace(
        "    def check_near_duplicates(self, samples):",
        f"{evidence_check}\n{license_check}\n{failure_stats}\n{shard_stats}\n    def check_near_duplicates(self, samples):"
    )

    # æ›¿æ¢ä¸»è¿è¡Œæ–¹æ³•
    enhanced_content = enhanced_content.replace(
        "    def run_quality_checks(self, samples):",
        "    def run_quality_checks(self, samples):\n        \"\"\"è¿è¡Œæ‰€æœ‰è´¨é‡æ£€æŸ¥ï¼ˆå¢å¼ºç‰ˆï¼‰\"\"\"\n        print(\"Running enhanced quality checks...\")\n        \n        # åŸºç¡€æ£€æŸ¥\n        field_results = self.check_field_completeness(samples)\n        question_results = self.check_clarification_questions(samples)\n        type_results = self.check_task_type_enum(samples)\n        license_results = self.check_licensing_format(samples)\n        text_results = self.check_text_lengths(samples)\n        duplicate_results = self.check_near_duplicates(samples)\n        \n        # æ–°å¢æ£€æŸ¥\n        evidence_overlaps = self.check_evidence_overlap(samples)\n        license_errors = self.check_license_whitelist(samples)\n        \n        # è®¡ç®—ç»Ÿè®¡\n        total_samples = len(samples)\n        alignment_errors = question_results['alignment_errors']\n        \n        # æŒ‰åˆ†ç‰‡ç»Ÿè®¡\n        by_shard = self.calculate_by_shard_stats(samples)\n        \n        # è¯æ®å…³è”åº¦ç»Ÿè®¡\n        if evidence_overlaps:\n            evidence_stats = {\n                'mean': sum(evidence_overlaps) / len(evidence_overlaps),\n                'min': min(evidence_overlaps),\n                'max': max(evidence_overlaps),\n                'count': len(evidence_overlaps)\n            }\n        else:\n            evidence_stats = {'mean': 0.0, 'min': 0.0, 'max': 0.0, 'count': 0}\n        \n        return {\n            'total_samples': total_samples,\n            'field_completeness': field_results,\n            'clarification_questions': question_results,\n            'task_type_enum': type_results,\n            'licensing_format': license_results,\n            'text_lengths': text_results,\n            'near_duplicates': duplicate_results,\n            'evidence_overlap': evidence_stats,\n            'license_whitelist_errors': license_errors,\n            'by_shard': by_shard,\n            'drop_reasons': dict(self.drop_reasons)\n        }"
    )

    # ä¿å­˜å¢å¼ºåçš„è„šæœ¬
    enhanced_script = Path("tools/stage2_quality_checks_v1.1.py")
    with open(enhanced_script, 'w', encoding='utf-8') as f:
        f.write(enhanced_content)

    print(f"âœ… å¢å¼ºåçš„è´¨æ£€è„šæœ¬å·²ä¿å­˜åˆ° {enhanced_script}")
    print("ğŸ¯ æ–°å¢åŠŸèƒ½ï¼š")
    print("  - è¯æ®å…³è”åº¦è®¡ç®—ï¼ˆHotpotQA/ASQAï¼‰")
    print("  - è®¸å¯ç™½åå•æ ¡éªŒ")
    print("  - å¤±è´¥åŸå› ç»Ÿè®¡")
    print("  - æŒ‰åˆ†ç‰‡ç»Ÿè®¡")

if __name__ == "__main__":
    enhance_quality_checks()
