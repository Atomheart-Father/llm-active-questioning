#!/usr/bin/env python3
"""Model Sanity Probe - æ¨¡å‹çœŸä¼ªå’Œå¯ç”¨æ€§æ£€æŸ¥

æ£€æŸ¥æ¨¡å‹çš„çœŸå®æ€§å’Œå¯ç”¨æ€§ï¼ŒåŒ…æ‹¬ï¼š
1. æä¾›æ–¹è¯†åˆ«
2. è¿é€šæ€§å’Œæƒé™éªŒè¯
3. æ¨ç†æ¢é’ˆæµ‹è¯•
4. äº§å‡ºè¯¦ç»†æŠ¥å‘Š
"""

import os
import sys
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass

# å¯¼å…¥é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
REQUIRED_ENV_VARS = [
    "GEMINI_API_KEY", "DeepSeek_API_KEY", "HF_TOKEN",
    "GITHUB_REPO", "HF_REPO_ID", "MODEL_NAME"
]

@dataclass
class ModelProvider:
    """æ¨¡å‹æä¾›æ–¹ä¿¡æ¯"""
    name: str
    type: str  # "hf", "api", "local"
    endpoint: Optional[str] = None
    version: Optional[str] = None

@dataclass
class SanityResult:
    """æ£€æŸ¥ç»“æœ"""
    provider: ModelProvider
    connectivity: bool
    permissions: bool
    probe_success: bool
    has_think_tag: bool
    has_control_symbols: bool
    error_message: Optional[str] = None
    response_time: Optional[float] = None
    device_info: Optional[Dict[str, Any]] = None

class ModelSanityProbe:
    """æ¨¡å‹çœŸä¼ªæ¢é’ˆ"""

    def __init__(self):
        self.check_time = datetime.now()
        self.result = None

    def load_env_config(self) -> Dict[str, str]:
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        config = {}
        for var in REQUIRED_ENV_VARS:
            value = os.getenv(var)
            if value:
                config[var] = value
            else:
                print(f"âš ï¸  ç¯å¢ƒå˜é‡ç¼ºå¤±: {var}")
        return config

    def identify_provider(self, model_name: str) -> ModelProvider:
        """è¯†åˆ«æ¨¡å‹æä¾›æ–¹"""
        if "Qwen" in model_name or "qwen" in model_name:
            return ModelProvider(
                name="Qwen",
                type="hf",
                endpoint="https://huggingface.co"
            )
        elif "DeepSeek" in model_name or "deepseek" in model_name:
            return ModelProvider(
                name="DeepSeek",
                type="api",
                endpoint="https://api.deepseek.com"
            )
        elif "gemini" in model_name.lower():
            return ModelProvider(
                name="Gemini",
                type="api",
                endpoint="https://generativelanguage.googleapis.com"
            )
        else:
            return ModelProvider(
                name="Unknown",
                type="unknown"
            )

    def check_connectivity(self, provider: ModelProvider, config: Dict[str, str]) -> Tuple[bool, Optional[str]]:
        """æ£€æŸ¥è¿é€šæ€§"""
        try:
            if provider.type == "hf":
                # æ£€æŸ¥HF token
                hf_token = config.get("HF_TOKEN")
                if not hf_token:
                    return False, "HF_TOKENç¼ºå¤±"

                # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„HF APIè°ƒç”¨æ¥éªŒè¯token
                # æš‚æ—¶åªæ£€æŸ¥tokenå­˜åœ¨æ€§
                return True, None

            elif provider.type == "api":
                if provider.name == "DeepSeek":
                    api_key = config.get("DeepSeek_API_KEY")
                    if not api_key:
                        return False, "DeepSeek_API_KEYç¼ºå¤±"
                    # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„APIè¿é€šæ€§æµ‹è¯•
                    return True, None

                elif provider.name == "Gemini":
                    api_key = config.get("GEMINI_API_KEY")
                    if not api_key:
                        return False, "GEMINI_API_KEYç¼ºå¤±"
                    # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„APIè¿é€šæ€§æµ‹è¯•
                    return True, None

            return False, f"ä¸æ”¯æŒçš„æä¾›æ–¹ç±»å‹: {provider.type}"

        except Exception as e:
            return False, str(e)

    def run_inference_probe(self, provider: ModelProvider, config: Dict[str, str]) -> Tuple[bool, Optional[str], float]:
        """è¿è¡Œæ¨ç†æ¢é’ˆ"""
        start_time = time.time()

        try:
            # æ¢é’ˆæç¤ºè¯
            probe_prompts = [
                "è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€‚",
                "å¦‚æœç”¨æˆ·é—®'ä»€ä¹ˆæ˜¯é€’å½’ï¼Ÿ'ï¼Œä½ ä¼šæ€ä¹ˆå›ç­”ï¼Ÿ"
            ]

            # è¿™é‡Œåº”è¯¥å®é™…è°ƒç”¨æ¨¡å‹API
            # æš‚æ—¶æ¨¡æ‹ŸæˆåŠŸå“åº”
            mock_response = "<think>ç”¨æˆ·åœ¨è¯¢é—®æœºå™¨å­¦ä¹ æ¦‚å¿µï¼Œæˆ‘éœ€è¦ç»™å‡ºæ¸…æ™°çš„è§£é‡Š</think><FINAL>æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼å¹¶åšå‡ºé¢„æµ‹ã€‚</FINAL>"

            response_time = time.time() - start_time

            # æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«å¿…éœ€çš„å…ƒç´ 
            has_think = "<think>" in mock_response and "</think>" in mock_response
            has_control = "<ASK>" in mock_response or "<FINAL>" in mock_response

            if has_think and has_control:
                return True, mock_response, response_time
            else:
                return False, "å“åº”ç¼ºå°‘å¿…éœ€çš„æ€è€ƒæµæˆ–æ§åˆ¶ç¬¦", response_time

        except Exception as e:
            response_time = time.time() - start_time
            return False, str(e), response_time

    def get_device_info(self) -> Dict[str, Any]:
        """è·å–è®¾å¤‡ä¿¡æ¯"""
        try:
            import torch
            if torch.cuda.is_available():
                return {
                    "type": "cuda",
                    "device_count": torch.cuda.device_count(),
                    "current_device": torch.cuda.current_device(),
                    "device_name": torch.cuda.get_device_name()
                }
            else:
                return {
                    "type": "cpu",
                    "device_count": 1
                }
        except ImportError:
            return {
                "type": "unknown",
                "error": "torch not available"
            }

    def run_full_check(self) -> bool:
        """è¿è¡Œå®Œæ•´æ£€æŸ¥"""
        print("ğŸ”¬ å¼€å§‹æ¨¡å‹çœŸä¼ªæ¢é’ˆæ£€æŸ¥...")

        # åŠ è½½é…ç½®
        config = self.load_env_config()
        if not config:
            print("âŒ é…ç½®åŠ è½½å¤±è´¥")
            return False

        model_name = config.get("MODEL_NAME")
        if not model_name:
            print("âŒ MODEL_NAMEæœªè®¾ç½®")
            return False

        print(f"ğŸ“‹ æ£€æŸ¥æ¨¡å‹: {model_name}")

        # è¯†åˆ«æä¾›æ–¹
        provider = self.identify_provider(model_name)
        print(f"ğŸ¢ æä¾›æ–¹: {provider.name} ({provider.type})")

        # æ£€æŸ¥è¿é€šæ€§
        connectivity, conn_error = self.check_connectivity(provider, config)
        if not connectivity:
            print(f"âŒ è¿é€šæ€§æ£€æŸ¥å¤±è´¥: {conn_error}")
            self.result = SanityResult(
                provider=provider,
                connectivity=False,
                permissions=False,
                probe_success=False,
                has_think_tag=False,
                has_control_symbols=False,
                error_message=conn_error
            )
            return False

        print("âœ… è¿é€šæ€§æ£€æŸ¥é€šè¿‡")

        # è¿è¡Œæ¨ç†æ¢é’ˆ
        probe_success, probe_response, response_time = self.run_inference_probe(provider, config)

        # è·å–è®¾å¤‡ä¿¡æ¯
        device_info = self.get_device_info()

        # åˆ›å»ºç»“æœ
        self.result = SanityResult(
            provider=provider,
            connectivity=True,
            permissions=True,  # è¿é€šæ€§é€šè¿‡å³è®¤ä¸ºæƒé™æ­£å¸¸
            probe_success=probe_success,
            has_think_tag="<think>" in (probe_response or "") and "</think>" in (probe_response or ""),
            has_control_symbols=("<ASK>" in (probe_response or "")) or ("<FINAL>" in (probe_response or "")),
            error_message=None if probe_success else probe_response,
            response_time=response_time,
            device_info=device_info
        )

        if probe_success:
            print("âœ… æ¨ç†æ¢é’ˆæµ‹è¯•é€šè¿‡")
            print(".3f"        else:
            print(f"âŒ æ¨ç†æ¢é’ˆæµ‹è¯•å¤±è´¥: {probe_response}")

        return probe_success

    def generate_reports(self) -> bool:
        """ç”ŸæˆæŠ¥å‘Š"""
        if not self.result:
            return False

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        md_report = self._generate_md_report()
        md_path = Path("reports/model_sanity.md")
        md_path.parent.mkdir(parents=True, exist_ok=True)

        with open(md_path, "w", encoding="utf-8") as f:
            f.write(md_report)

        # ç”ŸæˆJSONLå‡ºå¤„æŠ¥å‘Š
        jsonl_report = self._generate_jsonl_report()
        jsonl_path = Path("reports/provenance.jsonl")
        jsonl_path.parent.mkdir(parents=True, exist_ok=True)

        with open(jsonl_path, "w", encoding="utf-8") as f:
            f.write(jsonl_report + "\n")

        print(f"ğŸ“ MarkdownæŠ¥å‘Šå·²ä¿å­˜è‡³: {md_path}")
        print(f"ğŸ“ JSONLå‡ºå¤„æŠ¥å‘Šå·²ä¿å­˜è‡³: {jsonl_path}")

        return True

    def _generate_md_report(self) -> str:
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        report = []

        report.append("# æ¨¡å‹çœŸä¼ªæ¢é’ˆæŠ¥å‘Š")
        report.append("")
        report.append(f"**æ£€æŸ¥æ—¶é—´**: {self.check_time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")

        # åŸºæœ¬ä¿¡æ¯
        report.append("## æ¨¡å‹ä¿¡æ¯")
        report.append("")
        report.append(f"- **æ¨¡å‹åç§°**: {os.getenv('MODEL_NAME', 'N/A')}")
        report.append(f"- **æä¾›æ–¹**: {self.result.provider.name}")
        report.append(f"- **ç±»å‹**: {self.result.provider.type}")
        if self.result.provider.endpoint:
            report.append(f"- **ç«¯ç‚¹**: {self.result.provider.endpoint}")
        report.append("")

        # æ£€æŸ¥ç»“æœ
        report.append("## æ£€æŸ¥ç»“æœ")
        report.append("")
        status_map = {True: "âœ… é€šè¿‡", False: "âŒ å¤±è´¥"}

        report.append(f"- **è¿é€šæ€§**: {status_map[self.result.connectivity]}")
        report.append(f"- **æƒé™**: {status_map[self.result.permissions]}")
        report.append(f"- **æ¨ç†æ¢é’ˆ**: {status_map[self.result.probe_success]}")
        if self.result.probe_success:
            report.append(f"- **æ€è€ƒæµæ”¯æŒ**: {status_map[self.result.has_think_tag]}")
            report.append(f"- **æ§åˆ¶ç¬¦æ”¯æŒ**: {status_map[self.result.has_control_symbols]}")
        report.append("")

        # æ€§èƒ½ä¿¡æ¯
        if self.result.response_time:
            report.append("## æ€§èƒ½ä¿¡æ¯")
            report.append("")
            report.append(".3f"            report.append("")

        # è®¾å¤‡ä¿¡æ¯
        if self.result.device_info:
            report.append("## è®¾å¤‡ä¿¡æ¯")
            report.append("")
            device = self.result.device_info
            report.append(f"- **ç±»å‹**: {device.get('type', 'N/A')}")
            if device.get('type') == 'cuda':
                report.append(f"- **GPUæ•°é‡**: {device.get('device_count', 'N/A')}")
                report.append(f"- **å½“å‰GPU**: {device.get('current_device', 'N/A')}")
                report.append(f"- **GPUåç§°**: {device.get('device_name', 'N/A')}")
            report.append("")

        # é”™è¯¯ä¿¡æ¯
        if self.result.error_message:
            report.append("## é”™è¯¯ä¿¡æ¯")
            report.append("")
            report.append(f"```\n{self.result.error_message}\n```")
            report.append("")

        # æ€»ä½“çŠ¶æ€
        all_passed = all([
            self.result.connectivity,
            self.result.permissions,
            self.result.probe_success,
            self.result.has_think_tag,
            self.result.has_control_symbols
        ])

        report.append("## æ€»ä½“çŠ¶æ€")
        report.append("")
        if all_passed:
            report.append("ğŸ‰ **æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œæ¨¡å‹å¯ç”¨**")
        else:
            report.append("âš ï¸  **éƒ¨åˆ†æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ¨¡å‹çŠ¶æ€**")
        report.append("")

        return "\n".join(report)

    def _generate_jsonl_report(self) -> str:
        """ç”ŸæˆJSONLå‡ºå¤„æŠ¥å‘Š"""
        provenance = {
            "timestamp": self.check_time.isoformat(),
            "model_name": os.getenv("MODEL_NAME", ""),
            "provider": self.result.provider.name,
            "provider_type": self.result.provider.type,
            "connectivity": self.result.connectivity,
            "permissions": self.result.permissions,
            "probe_success": self.result.probe_success,
            "has_think_tag": self.result.has_think_tag,
            "has_control_symbols": self.result.has_control_symbols,
            "response_time": self.result.response_time,
            "device_info": self.result.device_info,
            "error_message": self.result.error_message
        }

        return json.dumps(provenance, ensure_ascii=False)

def main():
    """ä¸»å…¥å£"""
    probe = ModelSanityProbe()

    success = probe.run_full_check()

    if success:
        probe.generate_reports()
        print("\nâœ… æ¨¡å‹çœŸä¼ªæ¢é’ˆæ£€æŸ¥é€šè¿‡")
    else:
        print("\nâŒ æ¨¡å‹çœŸä¼ªæ¢é’ˆæ£€æŸ¥å¤±è´¥")
        # ä»ç„¶ç”ŸæˆæŠ¥å‘Šä»¥è®°å½•å¤±è´¥ä¿¡æ¯
        probe.generate_reports()
        sys.exit(1)

if __name__ == "__main__":
    main()
