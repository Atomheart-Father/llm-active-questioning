#!/usr/bin/env python3
"""
ä¸´æ—¶è„šæœ¬ï¼šæ›´æ–°ç´¯ç§¯metricsï¼Œæ­£å¼çº³å…¥shard-005
"""

import json
from pathlib import Path

def update_cumulative_metrics_v2():
    """æ›´æ–°ç´¯ç§¯metricsæ–‡ä»¶ï¼ŒåŠ å…¥shard-005"""

    # è¯»å–å½“å‰ç´¯ç§¯metrics
    cumulative_file = "data/processed/active_qa_v1/metrics.json"
    with open(cumulative_file, 'r', encoding='utf-8') as f:
        cumulative = json.load(f)

    # è¯»å–shard-005çš„metrics
    shard_file = "data/processed/active_qa_v1/metrics_shard_005.json"
    with open(shard_file, 'r', encoding='utf-8') as f:
        shard_metrics = json.load(f)

    print("=== æ›´æ–°ç´¯ç§¯Metrics v2 (åŠ å…¥shard-005) ===")
    print(f"å½“å‰ç´¯ç§¯æ ·æœ¬: {cumulative['total_samples']}")
    print(f"shard-005æ ·æœ¬: {shard_metrics['total_samples']}")
    print(f"shard-005å¯¹é½é”™è¯¯: {shard_metrics['clarification_questions']['alignment_errors']}")
    print(f"shard-005è¯æ®å…³è”åº¦: {shard_metrics['evidence_overlap']['mean']:.3f}")

    # æ›´æ–°æ€»æ ·æœ¬æ•°
    old_total = cumulative['total_samples']
    new_total = old_total + shard_metrics['total_samples']

    # æ›´æ–°å¯¹é½ç»Ÿè®¡
    old_errors = cumulative['alignment_stats']['alignment_error_count']
    new_errors = old_errors + shard_metrics['clarification_questions']['alignment_errors']

    # æ›´æ–°å‡†ç¡®ç‡
    new_ok_count = new_total - new_errors
    new_accuracy = (new_ok_count / new_total) * 100

    print(f"\\næ›´æ–°è¯¦æƒ…:")
    print(f"  æ€»æ ·æœ¬: {old_total} -> {new_total}")
    print(f"  å¯¹é½é”™è¯¯: {old_errors} -> {new_errors}")
    print(f"  å¯¹é½å‡†ç¡®ç‡: {cumulative['alignment_stats']['alignment_ok_percentage']:.2f}% -> {new_accuracy:.2f}%")

    # æ›´æ–°cumulativeæ•°æ®
    cumulative['timestamp'] = "2025-09-02T22:00:00.000000"  # æ›´æ–°æ—¶é—´æˆ³
    cumulative['total_samples'] = new_total
    cumulative['alignment_stats']['alignment_ok_count'] = new_ok_count
    cumulative['alignment_stats']['alignment_error_count'] = new_errors
    cumulative['alignment_stats']['alignment_ok_percentage'] = new_accuracy
    cumulative['shards']['shard-005'] = shard_metrics['total_samples']

    # æ›´æ–°è¯æ®å…³è”åº¦ç»Ÿè®¡
    if 'evidence_overlap' not in cumulative:
        cumulative['evidence_overlap'] = {
            'mean': shard_metrics['evidence_overlap']['mean'],
            'count': shard_metrics['evidence_overlap']['count']
        }
        new_mean = shard_metrics['evidence_overlap']['mean']
        new_count = shard_metrics['evidence_overlap']['count']
    else:
        # è®¡ç®—æ–°çš„å¹³å‡å€¼
        old_count = cumulative['evidence_overlap']['count']
        old_mean = cumulative['evidence_overlap']['mean']
        new_count = old_count + shard_metrics['evidence_overlap']['count']
        new_mean = (old_mean * old_count + shard_metrics['evidence_overlap']['mean'] * shard_metrics['evidence_overlap']['count']) / new_count

        cumulative['evidence_overlap']['mean'] = new_mean
        cumulative['evidence_overlap']['count'] = new_count

    print(f"  è¯æ®å…³è”åº¦å‡å€¼: {new_mean:.3f} (åŸºäº{new_count}ä¸ªæ ·æœ¬)")

    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    with open(cumulative_file, 'w', encoding='utf-8') as f:
        json.dump(cumulative, f, indent=2, ensure_ascii=False)

    print(f"\\nâœ… ç´¯ç§¯metricså·²æ›´æ–°å¹¶ä¿å­˜åˆ° {cumulative_file}")
    print("ğŸ¯ #S2-04f ä»»åŠ¡å®Œæˆï¼šshard-005å·²æ­£å¼çº³å…¥æœ‰æ•ˆé›†")

if __name__ == "__main__":
    update_cumulative_metrics_v2()
