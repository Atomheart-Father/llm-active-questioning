#!/usr/bin/env python3
"""Dataset Gate - æ•°æ®å°±ç»ªåº¦æ£€æŸ¥

éªŒè¯æ•°æ®é›†æ˜¯å¦æ»¡è¶³è®­ç»ƒè¦æ±‚ï¼š
1. ç»“æ„åˆæ³•æ€§æ£€æŸ¥
2. CoTæ³„æ¼æ£€æŸ¥
3. è§„æ¨¡é˜ˆå€¼æ£€æŸ¥
4. ç”Ÿæˆæ•°æ®æ¦‚è§ˆæŠ¥å‘Š
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime

# å¯¼å…¥ç°æœ‰çš„å·¥å…·
try:
    sys.path.append(str(Path(__file__).parent.parent))
    from src.data.loader import DataLoader, Sample
    from tools.scan_for_cot_leakage import CoTLeakageScanner
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

class DatasetGate:
    """æ•°æ®é›†å®ˆå«"""

    def __init__(self, min_samples: int = 8):
        self.min_samples = min_samples
        self.check_time = datetime.now()
        self.stats = {}
        self.errors = []

    def check_seed_data(self) -> bool:
        """æ£€æŸ¥ç§å­æ•°æ®"""
        print("ğŸ” å¼€å§‹æ•°æ®é›†å°±ç»ªåº¦æ£€æŸ¥...")

        seed_dirs = [
            "data/seed/ALC",
            "data/seed/AR"
        ]

        total_samples = 0
        all_valid = True

        for seed_dir in seed_dirs:
            dir_path = Path(seed_dir)
            if not dir_path.exists():
                self.errors.append(f"ç§å­æ•°æ®ç›®å½•ä¸å­˜åœ¨: {seed_dir}")
                all_valid = False
                continue

            jsonl_files = list(dir_path.glob("*.jsonl"))
            if not jsonl_files:
                self.errors.append(f"ç§å­æ•°æ®ç›®å½•ä¸ºç©º: {seed_dir}")
                all_valid = False
                continue

            for jsonl_file in jsonl_files:
                print(f"ğŸ“„ æ£€æŸ¥æ–‡ä»¶: {jsonl_file}")

                # ç»“æ„åˆæ³•æ€§æ£€æŸ¥
                if not self._check_structure_validity(str(jsonl_file)):
                    all_valid = False

                # CoTæ³„æ¼æ£€æŸ¥
                if not self._check_cot_leakage(str(jsonl_file)):
                    all_valid = False

                # ç»Ÿè®¡æ ·æœ¬æ•°
                sample_count = self._count_samples(str(jsonl_file))
                total_samples += sample_count
                self.stats[f"{seed_dir}/{jsonl_file.name}"] = sample_count

        # è§„æ¨¡é˜ˆå€¼æ£€æŸ¥
        if total_samples < self.min_samples:
            self.errors.append(f"æ ·æœ¬æ€»æ•°ä¸è¶³: {total_samples} < {self.min_samples}")
            all_valid = False

        self.stats["total_samples"] = total_samples

        if all_valid:
            print(f"âœ… æ•°æ®é›†æ£€æŸ¥é€šè¿‡ (å…± {total_samples} ä¸ªæ ·æœ¬)")
        else:
            print(f"âŒ æ•°æ®é›†æ£€æŸ¥å¤±è´¥")
            for error in self.errors:
                print(f"   - {error}")

        return all_valid

    def _check_structure_validity(self, file_path: str) -> bool:
        """æ£€æŸ¥æ•°æ®ç»“æ„åˆæ³•æ€§"""
        try:
            loader = DataLoader(strict_mode=False)
            samples = list(loader.load_jsonl(file_path))
            validation_report = loader.get_validation_report()

            if validation_report["error_count"] > 0:
                self.errors.append(f"ç»“æ„é”™è¯¯ ({file_path}): {validation_report['error_count']} ä¸ªé”™è¯¯")
                return False

            return True

        except Exception as e:
            self.errors.append(f"ç»“æ„æ£€æŸ¥å¤±è´¥ ({file_path}): {e}")
            return False

    def _check_cot_leakage(self, file_path: str) -> bool:
        """æ£€æŸ¥CoTæ³„æ¼"""
        try:
            scanner = CoTLeakageScanner()
            leakages = scanner.scan_file(file_path)

            if leakages:
                self.errors.append(f"CoTæ³„æ¼æ£€æµ‹ ({file_path}): {len(leakages)} ä¸ªæ³„æ¼")
                return False

            return True

        except Exception as e:
            self.errors.append(f"CoTæ³„æ¼æ£€æŸ¥å¤±è´¥ ({file_path}): {e}")
            return False

    def _count_samples(self, file_path: str) -> int:
        """ç»Ÿè®¡æ ·æœ¬æ•°é‡"""
        try:
            count = 0
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        count += 1
            return count
        except Exception:
            return 0

    def collect_detailed_stats(self) -> bool:
        """æ”¶é›†è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ“Š æ”¶é›†æ•°æ®ç»Ÿè®¡ä¿¡æ¯...")

        try:
            # ä½¿ç”¨ç°æœ‰çš„éªŒè¯å·¥å…·æ”¶é›†ç»Ÿè®¡
            from tools.validate_dataset import collect_statistics

            all_samples = []

            # åŠ è½½æ‰€æœ‰ç§å­æ•°æ®
            seed_files = [
                "data/seed/ALC/seed.jsonl",
                "data/seed/AR/seed.jsonl"
            ]

            for file_path in seed_files:
                if Path(file_path).exists():
                    loader = DataLoader(strict_mode=False)
                    samples = list(loader.load_jsonl(file_path))
                    all_samples.extend(samples)

            if all_samples:
                detailed_stats = collect_statistics(all_samples)
                self.stats.update(detailed_stats)

            return True

        except Exception as e:
            print(f"âš ï¸  ç»Ÿè®¡æ”¶é›†å¤±è´¥: {e}")
            return False

    def generate_report(self) -> str:
        """ç”Ÿæˆæ•°æ®æ£€æŸ¥æŠ¥å‘Š"""
        report = []

        report.append("# æ•°æ®é›†å°±ç»ªåº¦æ£€æŸ¥æŠ¥å‘Š")
        report.append("")
        report.append(f"**æ£€æŸ¥æ—¶é—´**: {self.check_time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**æœ€å°æ ·æœ¬é˜ˆå€¼**: {self.min_samples}")
        report.append("")

        # åŸºæœ¬ç»Ÿè®¡
        total_samples = self.stats.get("total_samples", 0)
        report.append("## åŸºæœ¬ç»Ÿè®¡")
        report.append("")
        report.append(f"- **æ€»æ ·æœ¬æ•°**: {total_samples}")
        report.append(f"- **é˜ˆå€¼è¦æ±‚**: â‰¥{self.min_samples}")
        report.append(f"- **çŠ¶æ€**: {'âœ… é€šè¿‡' if total_samples >= self.min_samples else 'âŒ æœªè¾¾æ ‡'}")
        report.append("")

        # æ–‡ä»¶ç»Ÿè®¡
        if any(k for k in self.stats.keys() if k.endswith('.jsonl')):
            report.append("## æ–‡ä»¶ç»Ÿè®¡")
            report.append("")
            report.append("| æ–‡ä»¶ | æ ·æœ¬æ•° |")
            report.append("|------|--------|")

            for file_path, count in self.stats.items():
                if file_path.endswith('.jsonl'):
                    report.append(f"| {file_path} | {count} |")
            report.append("")

        # è¯¦ç»†ç»Ÿè®¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if "domain_distribution" in self.stats:
            report.append("## é¢†åŸŸåˆ†å¸ƒ")
            report.append("")
            for domain, count in sorted(self.stats["domain_distribution"].items()):
                percentage = (count / total_samples) * 100 if total_samples > 0 else 0
                report.append(".1f")
            report.append("")

        if "ask_required_distribution" in self.stats:
            report.append("## æ¾„æ¸…éœ€æ±‚åˆ†å¸ƒ")
            report.append("")
            for ask_required, count in sorted(self.stats["ask_required_distribution"].items()):
                percentage = (count / total_samples) * 100 if total_samples > 0 else 0
                status = "éœ€è¦æ¾„æ¸…" if ask_required else "ç›´æ¥å›ç­”"
                report.append(".1f")
            report.append("")

        if "turns_length_stats" in self.stats:
            report.append("## å¯¹è¯ç»Ÿè®¡")
            report.append("")
            turns_stats = self.stats["turns_length_stats"]
            report.append(f"- **å¹³å‡è½®æ¬¡**: {turns_stats['avg']:.1f}")
            report.append(f"- **æœ€å°è½®æ¬¡**: {turns_stats['min']}")
            report.append(f"- **æœ€å¤§è½®æ¬¡**: {turns_stats['max']}")
            report.append("")

        # é”™è¯¯ä¿¡æ¯
        if self.errors:
            report.append("## æ£€æŸ¥é—®é¢˜")
            report.append("")
            for error in self.errors:
                report.append(f"- âŒ {error}")
            report.append("")

        # æ€»ä½“çŠ¶æ€
        has_errors = len(self.errors) > 0
        meets_threshold = total_samples >= self.min_samples

        report.append("## æ€»ä½“çŠ¶æ€")
        report.append("")
        if not has_errors and meets_threshold:
            report.append("ğŸ‰ **æ•°æ®é›†æ£€æŸ¥å…¨éƒ¨é€šè¿‡ï¼Œå¯ä»¥è¿›å…¥è®­ç»ƒé˜¶æ®µ**")
        else:
            report.append("âš ï¸  **æ•°æ®é›†æ£€æŸ¥å‘ç°é—®é¢˜ï¼Œéœ€è¦ä¿®å¤åé‡æ–°æ£€æŸ¥**")
        report.append("")

        return "\n".join(report)

    def run_check(self) -> bool:
        """è¿è¡Œå®Œæ•´æ£€æŸ¥"""
        # æ£€æŸ¥ç§å­æ•°æ®
        data_valid = self.check_seed_data()

        # æ”¶é›†è¯¦ç»†ç»Ÿè®¡
        self.collect_detailed_stats()

        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report()
        report_path = Path("reports/data_overview.md")
        report_path.parent.mkdir(parents=True, exist_ok=True)

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)

        print(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")

        return data_valid

def main():
    """ä¸»å…¥å£"""
    # ä»ç¯å¢ƒå˜é‡è·å–æœ€å°æ ·æœ¬é˜ˆå€¼ï¼Œé»˜è®¤8ä¸ª
    min_samples = int(os.getenv("DATASET_MIN_SAMPLES", "8"))

    gate = DatasetGate(min_samples=min_samples)
    success = gate.run_check()

    if not success:
        print("\nâŒ æ•°æ®é›†æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤é—®é¢˜åé‡æ–°æ£€æŸ¥")
        sys.exit(1)
    else:
        print("\nâœ… æ•°æ®é›†æ£€æŸ¥é€šè¿‡")

if __name__ == "__main__":
    main()
