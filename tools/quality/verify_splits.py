#!/usr/bin/env python3
"""
æ•°æ®åˆ‡åˆ†æ ¡éªŒè„šæœ¬
éªŒè¯train/dev/testæ•°æ®é›†çš„æ— äº¤å‰æ³„æ¼

åŠŸèƒ½ï¼š
1. æ£€æŸ¥ä¸‰ä¸ªæ•°æ®é›†ä¹‹é—´æ˜¯å¦æœ‰UIDé‡å¤
2. éªŒè¯åˆ‡åˆ†æ¯”ä¾‹æ˜¯å¦ç¬¦åˆé¢„æœŸ (80/10/10)
3. æ£€æŸ¥æ¯ä¸ªæ•°æ®é›†çš„æ ·æœ¬å®Œæ•´æ€§
4. è¾“å‡ºå†²çªæŠ¥å‘Šå’Œç»Ÿè®¡æ‘˜è¦

è¾“å‡ºï¼š
- æ§åˆ¶å°æŠ¥å‘Šï¼šæ ¡éªŒç»“æœ
- conflicts.jsonï¼šå‘ç°çš„é‡å¤UIDè¯¦æƒ…
- split_stats.jsonï¼šåˆ‡åˆ†ç»Ÿè®¡ä¿¡æ¯
"""

import json
import os
from collections import defaultdict
from pathlib import Path


def load_uids_from_jsonl(filepath):
    """ä»JSONLæ–‡ä»¶ä¸­æå–æ‰€æœ‰UID"""
    uids = []
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if line:
                    try:
                        sample = json.loads(line)
                        uid = sample.get('uid')
                        if uid:
                            uids.append(uid)
                        else:
                            print(f"è­¦å‘Š: {filepath}:{line_num} ç¼ºå°‘UID")
                    except json.JSONDecodeError as e:
                        print(f"é”™è¯¯: {filepath}:{line_num} JSONè§£æå¤±è´¥: {e}")
    except FileNotFoundError:
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {filepath}")
        return []
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–æ–‡ä»¶ {filepath} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return []

    return uids


def find_uid_conflicts(train_uids, dev_uids, test_uids):
    """æŸ¥æ‰¾ä¸‰ä¸ªæ•°æ®é›†ä¹‹é—´çš„UIDå†²çª"""
    conflicts = {
        'train_dev': [],
        'train_test': [],
        'dev_test': [],
        'all_sets': []
    }

    # åˆ›å»ºUIDåˆ°æ•°æ®é›†çš„æ˜ å°„
    uid_to_datasets = defaultdict(list)

    for uid in train_uids:
        uid_to_datasets[uid].append('train')
    for uid in dev_uids:
        uid_to_datasets[uid].append('dev')
    for uid in test_uids:
        uid_to_datasets[uid].append('test')

    # æŸ¥æ‰¾å†²çª
    for uid, datasets in uid_to_datasets.items():
        if len(datasets) > 1:
            # è®°å½•å…·ä½“å†²çª
            if 'train' in datasets and 'dev' in datasets:
                conflicts['train_dev'].append(uid)
            if 'train' in datasets and 'test' in datasets:
                conflicts['train_test'].append(uid)
            if 'dev' in datasets and 'test' in datasets:
                conflicts['dev_test'].append(uid)
            if len(datasets) == 3:
                conflicts['all_sets'].append(uid)

    return conflicts, uid_to_datasets


def calculate_split_stats(train_uids, dev_uids, test_uids):
    """è®¡ç®—åˆ‡åˆ†ç»Ÿè®¡ä¿¡æ¯"""
    total_samples = len(train_uids) + len(dev_uids) + len(test_uids)

    stats = {
        'total_samples': total_samples,
        'train': {
            'count': len(train_uids),
            'percentage': len(train_uids) / total_samples * 100 if total_samples > 0 else 0
        },
        'dev': {
            'count': len(dev_uids),
            'percentage': len(dev_uids) / total_samples * 100 if total_samples > 0 else 0
        },
        'test': {
            'count': len(test_uids),
            'percentage': len(test_uids) / total_samples * 100 if total_samples > 0 else 0
        },
        'expected_distribution': {
            'train': 80.0,
            'dev': 10.0,
            'test': 10.0
        }
    }

    # è®¡ç®—åå·®
    stats['deviations'] = {
        'train': stats['train']['percentage'] - stats['expected_distribution']['train'],
        'dev': stats['dev']['percentage'] - stats['expected_distribution']['dev'],
        'test': stats['test']['percentage'] - stats['expected_distribution']['test']
    }

    return stats


def validate_split_quality(stats):
    """éªŒè¯åˆ‡åˆ†è´¨é‡"""
    issues = []

    # æ£€æŸ¥æ¯”ä¾‹åå·® (å…è®¸1%çš„è¯¯å·®)
    tolerance = 1.0
    for split_name in ['train', 'dev', 'test']:
        deviation = abs(stats['deviations'][split_name])
        if deviation > tolerance:
            issues.append({
                'type': 'ratio_deviation',
                'split': split_name,
                'expected': stats['expected_distribution'][split_name],
                'actual': stats[split_name]['percentage'],
                'deviation': deviation,
                'status': 'warning' if deviation <= 5.0 else 'error'
            })

    # æ£€æŸ¥æ ·æœ¬æ•°é‡åˆç†æ€§
    if stats['total_samples'] == 0:
        issues.append({
            'type': 'no_samples',
            'message': 'æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ ·æœ¬',
            'status': 'error'
        })

    for split_name in ['train', 'dev', 'test']:
        if stats[split_name]['count'] == 0:
            issues.append({
                'type': 'empty_split',
                'split': split_name,
                'message': f'{split_name}æ•°æ®é›†ä¸ºç©º',
                'status': 'error'
            })

    return issues


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Stage 2 æ•°æ®åˆ‡åˆ†æ ¡éªŒ - å¼€å§‹æ‰§è¡Œ")
    print("=" * 60)

    # æ•°æ®æ–‡ä»¶è·¯å¾„
    data_dir = Path("data/processed/active_qa_v1")
    train_file = data_dir / "train.jsonl"
    dev_file = data_dir / "dev.jsonl"
    test_file = data_dir / "test.jsonl"

    # åŠ è½½UID
    print("ğŸ“– åŠ è½½è®­ç»ƒé›†UID...")
    train_uids = load_uids_from_jsonl(train_file)

    print("ğŸ“– åŠ è½½éªŒè¯é›†UID...")
    dev_uids = load_uids_from_jsonl(dev_file)

    print("ğŸ“– åŠ è½½æµ‹è¯•é›†UID...")
    test_uids = load_uids_from_jsonl(test_file)

    # æŸ¥æ‰¾å†²çª
    print("ğŸ” æŸ¥æ‰¾UIDå†²çª...")
    conflicts, uid_to_datasets = find_uid_conflicts(train_uids, dev_uids, test_uids)

    # è®¡ç®—ç»Ÿè®¡
    print("ğŸ“Š è®¡ç®—åˆ‡åˆ†ç»Ÿè®¡...")
    stats = calculate_split_stats(train_uids, dev_uids, test_uids)

    # éªŒè¯è´¨é‡
    print("âœ… éªŒè¯åˆ‡åˆ†è´¨é‡...")
    quality_issues = validate_split_quality(stats)

    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ ¡éªŒç»“æœæŠ¥å‘Š:")

    print("\nğŸ”¢ æ•°æ®é›†è§„æ¨¡:")
    print(f"  è®­ç»ƒé›†: {stats['train']['count']} æ ·æœ¬ ({stats['train']['percentage']:.1f}%)")
    print(f"  éªŒè¯é›†: {stats['dev']['count']} æ ·æœ¬ ({stats['dev']['percentage']:.1f}%)")
    print(f"  æµ‹è¯•é›†: {stats['test']['count']} æ ·æœ¬ ({stats['test']['percentage']:.1f}%)")
    print(f"  æ€»è®¡: {stats['total_samples']} æ ·æœ¬")

    print("\nğŸ“Š æœŸæœ›åˆ†å¸ƒ:")
    print("  è®­ç»ƒé›†: 80.0%")
    print("  éªŒè¯é›†: 10.0%")
    print("  æµ‹è¯•é›†: 10.0%")

    print("\nâš–ï¸ åˆ†å¸ƒåå·®:")
    for split_name in ['train', 'dev', 'test']:
        deviation = stats['deviations'][split_name]
        status = "âœ…" if abs(deviation) <= 1.0 else "âš ï¸" if abs(deviation) <= 5.0 else "âŒ"
        print(f"  {split_name}: {deviation:+.1f}% {status}")
    # å†²çªæ£€æŸ¥
    total_conflicts = sum(len(conflicts[key]) for key in conflicts if key != 'all_sets')

    print("\nğŸ” UIDå†²çªæ£€æŸ¥:")
    print(f"  è®­ç»ƒé›†-éªŒè¯é›†é‡å : {len(conflicts['train_dev'])}")
    print(f"  è®­ç»ƒé›†-æµ‹è¯•é›†é‡å : {len(conflicts['train_test'])}")
    print(f"  éªŒè¯é›†-æµ‹è¯•é›†é‡å : {len(conflicts['dev_test'])}")
    print(f"  ä¸‰é›†éƒ½é‡å : {len(conflicts['all_sets'])}")
    print(f"  æ€»å†²çªæ•°: {total_conflicts}")

    # è´¨é‡é—®é¢˜
    if quality_issues:
        print("\nâš ï¸ è´¨é‡é—®é¢˜:")
        for issue in quality_issues:
            status_icon = "âŒ" if issue['status'] == 'error' else "âš ï¸"
            print(f"  {status_icon} {issue.get('message', issue['type'])}")
    else:
        print("\nâœ… æ— è´¨é‡é—®é¢˜")

    # ä¿å­˜å†²çªè¯¦æƒ…
    conflicts_output = {
        'summary': {
            'total_conflicts': total_conflicts,
            'train_dev_conflicts': len(conflicts['train_dev']),
            'train_test_conflicts': len(conflicts['train_test']),
            'dev_test_conflicts': len(conflicts['dev_test']),
            'all_sets_conflicts': len(conflicts['all_sets'])
        },
        'details': conflicts,
        'stats': stats,
        'quality_issues': quality_issues
    }

    conflicts_file = data_dir / "split_conflicts.json"
    with open(conflicts_file, 'w', encoding='utf-8') as f:
        json.dump(conflicts_output, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ’¾ ä¿å­˜å†²çªæŠ¥å‘Šåˆ°: {conflicts_file}")

    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_file = data_dir / "split_stats.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    print(f"ğŸ’¾ ä¿å­˜ç»Ÿè®¡ä¿¡æ¯åˆ°: {stats_file}")

    # é€€å‡ºçŠ¶æ€
    has_errors = any(issue['status'] == 'error' for issue in quality_issues) or total_conflicts > 0

    print("\n" + "=" * 60)
    if has_errors:
        print("âŒ æ ¡éªŒå¤±è´¥ï¼å‘ç°æ•°æ®æ³„æ¼æˆ–è´¨é‡é—®é¢˜ã€‚")
        print("è¯·æ£€æŸ¥ä¸Šè¿°é—®é¢˜å¹¶ä¿®å¤åé‡æ–°è¿è¡Œã€‚")
        exit(1)
    else:
        print("âœ… æ ¡éªŒé€šè¿‡ï¼æ•°æ®é›†åˆ‡åˆ†è´¨é‡è‰¯å¥½ï¼Œæ— æ³„æ¼é£é™©ã€‚")
        exit(0)


if __name__ == "__main__":
    main()
