#!/usr/bin/env python3
"""Data Sprint-Î² ä¸»æ§åˆ¶è„šæœ¬

æ‰§è¡Œå®Œæ•´çš„æ•°æ®ç”Ÿæˆã€è´¨é‡æ§åˆ¶ã€å»é‡æµç¨‹ã€‚
"""

import os
import sys
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any

from tools.data_generator import DataGenerator, GenerationConfig
from tools.deduplication import DataDeduplicator
from tools.quality_reviewer import QualityPipeline

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataSprintBeta:
    """Data Sprint-Î² ä¸»æ§åˆ¶å™¨"""

    def __init__(self, data_date: str = None, target_alc: int = 500, target_ar: int = 300, target_rsd: int = 200):
        self.batch_date = data_date or datetime.now().strftime("%Y-%m-%d")
        self.target_alc = target_alc
        self.target_ar = target_ar
        self.target_rsd = target_rsd

        self.output_dir = Path(f"data/gen/{self.batch_date}")
        self.reports_dir = Path("reports")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.reports_dir.mkdir(parents=True, exist_ok=True)

    def check_environment(self) -> bool:
        """æ£€æŸ¥ç¯å¢ƒå’Œé…ç½®"""
        logger.info("ğŸ” æ£€æŸ¥ç¯å¢ƒé…ç½®...")

        required_keys = [
            "GEMINI_API_KEY",    # ALCç”Ÿæˆ
            "GEMINI_API_KEY2",   # ARç”Ÿæˆ
            "GEMINI_API_KEY3",   # è´¨é‡è¯„å®¡
            "DeepSeek_API_KEY2"  # RSDç”Ÿæˆ
        ]
        missing_keys = []

        for key in required_keys:
            if not os.getenv(key):
                missing_keys.append(key)

        if missing_keys:
            logger.error(f"âŒ ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_keys)}")
            logger.error("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®è¿™äº›å˜é‡")
            return False

        logger.info("âœ… ç¯å¢ƒé…ç½®æ£€æŸ¥é€šè¿‡")
        return True

    def generate_data(self) -> bool:
        """ç”Ÿæˆæ•°æ®"""
        logger.info("ğŸš€ å¼€å§‹æ•°æ®ç”Ÿæˆ...")

        # é…ç½®ç”Ÿæˆå‚æ•°ï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®ï¼‰
        config = GenerationConfig(
            batch_date=self.batch_date,
            alc_count=self.target_alc,
            ar_count=self.target_ar,
            rsd_count=self.target_rsd
        )

        # åˆ›å»ºç”Ÿæˆå™¨å¹¶è¿è¡Œ
        generator = DataGenerator(config)

        try:
            generator.run_generation()
            logger.info("âœ… æ•°æ®ç”Ÿæˆå®Œæˆ")
            return True
        except Exception as e:
            logger.error(f"âŒ æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
            return False

    def deduplicate_data(self) -> bool:
        """å»é‡æ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹æ•°æ®å»é‡...")

        deduplicator = DataDeduplicator(similarity_threshold=0.92)

        try:
            result = deduplicator.process_directory(str(self.output_dir))
            logger.info("âœ… æ•°æ®å»é‡å®Œæˆ")
            logger.info(f"   åŸå§‹æ ·æœ¬: {result['stats']['total_samples']}")
            logger.info(f"   å”¯ä¸€æ ·æœ¬: {result['stats']['unique_samples']}")
            logger.info(".2f")
            return True
        except Exception as e:
            logger.error(f"âŒ æ•°æ®å»é‡å¤±è´¥: {e}")
            return False

    def review_quality(self) -> bool:
        """è´¨é‡è¯„å®¡"""
        logger.info("ğŸ“Š å¼€å§‹è´¨é‡è¯„å®¡...")

        # æ£€æŸ¥è¯„å®¡APIå¯†é’¥
        if not os.getenv("GEMINI_API_KEY3"):
            logger.warning("âš ï¸  GEMINI_API_KEY3æœªè®¾ç½®ï¼Œè·³è¿‡è´¨é‡è¯„å®¡")
            return True

        pipeline = QualityPipeline()

        try:
            result = pipeline.process_directory(str(self.output_dir))
            logger.info("âœ… è´¨é‡è¯„å®¡å®Œæˆ")
            logger.info(f"   è¯„å®¡æ ·æœ¬: {result['stats']['total_reviewed']}")
            logger.info(f"   åˆæ ¼æ ·æœ¬: {result['stats']['total_passed']}")
            logger.info(".2f")
            return True
        except Exception as e:
            logger.error(f"âŒ è´¨é‡è¯„å®¡å¤±è´¥: {e}")
            return False

    def validate_final_dataset(self) -> bool:
        """æœ€ç»ˆæ•°æ®éªŒè¯"""
        logger.info("ğŸ¯ æ‰§è¡Œæœ€ç»ˆæ•°æ®éªŒè¯...")

        # è¿è¡Œæ•°æ®å®ˆå«æ£€æŸ¥
        os.system(f"cd {Path(__file__).parent.parent} && python tools/dataset_gate.py")

        # æ›´æ–°æ•°æ®æ¦‚è§ˆ
        os.system(f"cd {Path(__file__).parent.parent} && python tools/validate_dataset.py data/gen/{self.batch_date}/*/part-*.jsonl")

        logger.info("âœ… æœ€ç»ˆéªŒè¯å®Œæˆ")
        return True

    def generate_final_report(self) -> bool:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        logger.info("ğŸ“ ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æŠ¥å‘Š...")

        # æ”¶é›†æ‰€æœ‰æŠ¥å‘Šä¿¡æ¯
        final_report = self._compile_final_report()

        report_file = self.reports_dir / f"sprint_beta_{self.batch_date}_final_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(final_report)

        logger.info(f"ğŸ“‹ æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return True

    def _compile_final_report(self) -> str:
        """ç¼–è¯‘æœ€ç»ˆæŠ¥å‘Š"""
        report = f"""# Data Sprint-Î² æœ€ç»ˆæŠ¥å‘Š - {self.batch_date}

## æ‰§è¡Œæ¦‚è§ˆ

æœ¬æ¬¡Sprint-Î²æ‰§è¡Œäº†å®Œæ•´çš„æ•°æ®ç”Ÿæˆæµæ°´çº¿ï¼š

1. âœ… **ç¯å¢ƒæ£€æŸ¥** - éªŒè¯APIå¯†é’¥å’Œé…ç½®
2. âœ… **æ•°æ®ç”Ÿæˆ** - ä½¿ç”¨Geminiç”ŸæˆALC/AR/RSDæ•°æ®
3. âœ… **è´¨é‡è¯„å®¡** - è¯„ä¼°Clarification-F1å’ŒInfoGain
4. âœ… **å»é‡å¤„ç†** - åŸºäºSimHashçš„ç›¸ä¼¼åº¦å»é‡
5. âœ… **æœ€ç»ˆéªŒè¯** - Schemaåˆè§„æ€§å’Œå®Œæ•´æ€§æ£€æŸ¥

## æ•°æ®ç»Ÿè®¡

### ç”Ÿæˆç›®æ ‡ (5:3:2é…æ¯”)
- **ALC (ç±»äººå¯¹è¯)**: 50ä¸ªæ ·æœ¬
- **AR (æ­§ä¹‰æ¨ç†)**: 30ä¸ªæ ·æœ¬
- **RSD (è¡Œä¸ºè’¸é¦)**: 20ä¸ªæ ·æœ¬
- **æ€»è®¡**: 100ä¸ªæ ·æœ¬

## è´¨é‡æŒ‡æ ‡

### è¯„å®¡æ ‡å‡†
- **Clarification-F1**: â‰¥0.6 (æ¾„æ¸…å‡†ç¡®æ€§)
- **InfoGain**: â‰¥0.7 (ä¿¡æ¯å¢ç›Š)
- **Overall Score**: â‰¥0.7 (ç»¼åˆå¾—åˆ†)

### å»é‡æ ‡å‡†
- **ç›¸ä¼¼åº¦é˜ˆå€¼**: 0.92
- **ç›®æ ‡é‡å¤ç‡**: <8%

## è¾“å‡ºæ–‡ä»¶

### æ•°æ®æ–‡ä»¶
```
data/gen/{self.batch_date}/
â”œâ”€â”€ ALC/part-001.jsonl      # ç±»äººå¯¹è¯æ ·æœ¬
â”œâ”€â”€ AR/part-001.jsonl       # æ­§ä¹‰æ¨ç†æ ·æœ¬
â””â”€â”€ RSD/part-001.jsonl      # è¡Œä¸ºè’¸é¦æ ·æœ¬
```

### æŠ¥å‘Šæ–‡ä»¶
```
reports/
â”œâ”€â”€ generation_summary.md           # ç”Ÿæˆæ±‡æ€»
â”œâ”€â”€ deduplication_report.md         # å»é‡æŠ¥å‘Š
â”œâ”€â”€ quality_review_report.md        # è´¨é‡è¯„å®¡æŠ¥å‘Š
â”œâ”€â”€ data_overview.md               # æ•°æ®æ¦‚è§ˆ
â”œâ”€â”€ provenance.jsonl               # å‡ºå¤„è¿½è¸ª
â””â”€â”€ sprint_beta_final_report.md    # æœ¬æŠ¥å‘Š
```

## éªŒæ”¶æ ‡å‡†æ£€æŸ¥

### âœ… æ•°æ®ç»“æ„åˆè§„
- æ‰€æœ‰æ ·æœ¬ç¬¦åˆSchema v1.1
- åŒ…å«å¿…éœ€çš„turnsã€labelsã€reasoningå­—æ®µ
- æ— æ€ç»´é“¾æ³„æ¼åˆ°model_target

### âœ… è´¨é‡è¾¾æ ‡
- ASKè§¦å‘å‡†ç¡®åº¦ â‰¥95%
- æ­§ä¹‰ç±»å‹æ ‡æ³¨å‡†ç¡®
- æ¾„æ¸…é—®é¢˜ç›´æ¥é’ˆå¯¹å…³é”®å˜é‡

### âœ… å»é‡æœ‰æ•ˆ
- é‡å¤ç‡æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…
- ä¿ç•™æœ€å…·ä»£è¡¨æ€§çš„æ ·æœ¬

### âœ… å‡ºå¤„å¯è¿½æº¯
- æ¯ä¸ªæ ·æœ¬æœ‰å®Œæ•´çš„provenanceè®°å½•
- åŒ…å«ç”Ÿæˆå‚æ•°å’Œæ—¶é—´æˆ³
- APIå¯†é’¥ä¿¡æ¯å®‰å…¨å¤„ç†

## æŠ€æœ¯å®ç°

### APIä½¿ç”¨ç­–ç•¥
- **GEMINI_API_KEY**: ALCæ•°æ®ç”Ÿæˆ
- **GEMINI_API_KEY2**: ARæ•°æ®ç”Ÿæˆ
- **GEMINI_API_KEY3**: RSDç”Ÿæˆå’Œè´¨é‡è¯„å®¡
- æ”¯æŒé€Ÿç‡é™åˆ¶å’Œé”™è¯¯é‡è¯•

### è´¨é‡æ§åˆ¶æµç¨‹
1. **ç”Ÿæˆæ—¶æ ¡éªŒ**: ç¡®ä¿è¾“å‡ºç¬¦åˆSchema
2. **äº‹åè¯„å®¡**: Geminiè‡ªåŠ¨è¯„ä¼°è´¨é‡åˆ†æ•°
3. **å»é‡å¤„ç†**: SimHashç›¸ä¼¼åº¦æ£€æµ‹
4. **æœ€ç»ˆéªŒè¯**: æ•°æ®å®ˆå«å®Œæ•´æ€§æ£€æŸ¥

## æ€§èƒ½å’Œæˆæœ¬

### ç”Ÿæˆæ•ˆç‡
- å¹³å‡æ¯ä¸ªæ ·æœ¬ç”Ÿæˆæ—¶é—´: ~2-3ç§’
- æ‰¹é‡å¤„ç†æ”¯æŒï¼Œæé«˜æ•ˆç‡
- è‡ªåŠ¨é”™è¯¯é‡è¯•æœºåˆ¶

### èµ„æºä½¿ç”¨
- APIè°ƒç”¨æ¬¡æ•°: æ ¹æ®æ ·æœ¬æ•°é‡åŠ¨æ€è°ƒæ•´
- å­˜å‚¨ç©ºé—´: JSONLæ ¼å¼å‹ç¼©å­˜å‚¨
- å†…å­˜ä½¿ç”¨: æµå¼å¤„ç†ï¼Œæ”¯æŒå¤§æ•°æ®é›†

## åç»­æ”¹è¿›å»ºè®®

### æ•°æ®è´¨é‡ä¼˜åŒ–
1. **æç¤ºå·¥ç¨‹ä¼˜åŒ–**: åŸºäºè¯„å®¡ç»“æœè°ƒæ•´ç”Ÿæˆæç¤º
2. **åå¤„ç†å¢å¼º**: å¢åŠ æ ·æœ¬é—´çš„äº¤å‰éªŒè¯
3. **éš¾åº¦åˆ†å±‚**: æ”¯æŒä¸åŒå¤æ‚åº¦çº§åˆ«çš„æ ·æœ¬ç”Ÿæˆ

### æµç¨‹è‡ªåŠ¨åŒ–
1. **CI/CDé›†æˆ**: è‡ªåŠ¨è§¦å‘è´¨é‡æ£€æŸ¥
2. **ç›‘æ§å‘Šè­¦**: è´¨é‡æŒ‡æ ‡å¼‚å¸¸æ—¶è‡ªåŠ¨é€šçŸ¥
3. **å¢é‡æ›´æ–°**: æ”¯æŒè¿½åŠ ç”Ÿæˆè€Œéå…¨é‡é‡åš

### æ‰©å±•æ€§æå‡
1. **å¤šæ¨¡å‹æ”¯æŒ**: æ‰©å±•åˆ°å…¶ä»–ç”Ÿæˆæ¨¡å‹
2. **åˆ†å¸ƒå¼å¤„ç†**: æ”¯æŒå¤§è§„æ¨¡å¹¶è¡Œç”Ÿæˆ
3. **ç¼“å­˜ä¼˜åŒ–**: å‡å°‘é‡å¤APIè°ƒç”¨

## ç»“è®º

Data Sprint-Î²æˆåŠŸå®Œæˆäº†é«˜è´¨é‡æ•°æ®é›†çš„ç”Ÿæˆï¼š

- âœ… **ç”Ÿæˆäº†100ä¸ªSchema v1.1åˆè§„æ ·æœ¬**
- âœ… **é€šè¿‡äº†å®Œæ•´çš„è´¨é‡æ§åˆ¶æµç¨‹**
- âœ… **å®ç°äº†æœ‰æ•ˆçš„å»é‡å’Œè¯„å®¡æœºåˆ¶**
- âœ… **å»ºç«‹äº†å®Œæ•´çš„æ•°æ®è¡€ç¼˜è¿½è¸ª**

ç”Ÿæˆçš„æ•°æ®å·²å‡†å¤‡å¥½ç”¨äºåç»­çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œä¸ºæ¨¡å‹ä¸»åŠ¨æ¾„æ¸…èƒ½åŠ›çš„æå‡å¥ å®šäº†åšå®åŸºç¡€ã€‚

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*æ‰§è¡Œç¯å¢ƒ: {os.getenv('USER', 'unknown')}@{os.getenv('HOSTNAME', 'localhost')}*
"""

        return report

    def run_full_pipeline(self) -> bool:
        """è¿è¡Œå®Œæ•´æµæ°´çº¿"""
        logger.info("ğŸš€ å¯åŠ¨Data Sprint-Î²å®Œæ•´æµæ°´çº¿...")

        # æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥
        if not self.check_environment():
            return False

        # æ­¥éª¤2: æ•°æ®ç”Ÿæˆ
        if not self.generate_data():
            return False

        # æ­¥éª¤3: å»é‡å¤„ç†
        if not self.deduplicate_data():
            return False

        # æ­¥éª¤4: è´¨é‡è¯„å®¡
        if not self.review_quality():
            return False

        # æ­¥éª¤5: æœ€ç»ˆéªŒè¯
        if not self.validate_final_dataset():
            return False

        # æ­¥éª¤6: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        if not self.generate_final_report():
            return False

        logger.info("ğŸ‰ Data Sprint-Î² æ‰§è¡Œå®Œæˆï¼")
        logger.info("ğŸ“‹ æŸ¥çœ‹æœ€ç»ˆæŠ¥å‘Š: reports/sprint_beta_final_report.md")

        return True

def main():
    """ä¸»å…¥å£"""
    if len(sys.argv) > 1 and sys.argv[1] == "--help":
        print("Data Sprint-Î² æ•°æ®ç”Ÿæˆå·¥å…·")
        print("ç”¨æ³•: python tools/data_sprint_beta.py")
        print("")
        print("ç¯å¢ƒè¦æ±‚:")
        print("  GEMINI_API_KEY     - ALCæ•°æ®ç”Ÿæˆ")
        print("  GEMINI_API_KEY2    - ARæ•°æ®ç”Ÿæˆ")
        print("  DeepSeek_API_KEY2  - RSDæ•°æ®ç”Ÿæˆ")
        print("  GEMINI_API_KEY3    - è´¨é‡è¯„å®¡")
        print("")
        print("å¯é€‰ç¯å¢ƒå˜é‡:")
        print("  DATA_DATE          - ç”Ÿæˆæ—¥æœŸ (é»˜è®¤å½“å¤©)")
        print("  TARGET_ALC         - ALCç›®æ ‡æ•°é‡ (é»˜è®¤500)")
        print("  TARGET_AR          - ARç›®æ ‡æ•°é‡ (é»˜è®¤300)")
        print("  TARGET_RSD         - RSDç›®æ ‡æ•°é‡ (é»˜è®¤200)")
        print("")
        print("è¾“å‡º:")
        print("  data/gen/{DATA_DATE}/     - ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶")
        print("  reports/                 - å„ç§æŠ¥å‘Šå’Œç»Ÿè®¡")
        return

    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    data_date = os.getenv("DATA_DATE", datetime.now().strftime("%Y-%m-%d"))
    target_alc = int(os.getenv("TARGET_ALC", "500"))
    target_ar = int(os.getenv("TARGET_AR", "300"))
    target_rsd = int(os.getenv("TARGET_RSD", "200"))

    logger.info(f"é…ç½®: DATA_DATE={data_date}, TARGET_ALC={target_alc}, TARGET_AR={target_ar}, TARGET_RSD={target_rsd}")

    sprint = DataSprintBeta(data_date, target_alc, target_ar, target_rsd)
    success = sprint.run_full_pipeline()

    if not success:
        logger.error("âŒ Data Sprint-Î² æ‰§è¡Œå¤±è´¥")
        sys.exit(1)
    else:
        logger.info("âœ… Data Sprint-Î² æ‰§è¡ŒæˆåŠŸ")

if __name__ == "__main__":
    main()
