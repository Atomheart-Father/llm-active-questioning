#!/usr/bin/env python3
"""
ä»Hugging Faceæ•°æ®é›†é‡å»ºå½±å­é›†ï¼Œç¡®ä¿çœŸå®æ•°æ®æºä¸æº¯æºä¿¡æ¯
"""

import argparse
import json
import random
import sys
from pathlib import Path
from datasets import load_dataset

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

def load_hf_dataset(dataset_name, config=None, split="train"):
    """åŠ è½½HFæ•°æ®é›†å¹¶è¿”å›æº¯æºä¿¡æ¯"""
    try:
        if config:
            dataset = load_dataset(dataset_name, config, split=split)
        else:
            dataset = load_dataset(dataset_name, split=split)
        
        return dataset, {
            "hf_dataset": dataset_name,
            "hf_config": config,
            "hf_split": split,
            "hf_fingerprint": dataset._fingerprint,
            "hf_num_rows": len(dataset)
        }
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥: {dataset_name} - {e}")
        sys.exit(1)

def extract_samples_hotpotqa(dataset, metadata, n_samples, seed):
    """ä»HotpotQAæå–æ ·æœ¬"""
    random.seed(seed + 1)
    indices = random.sample(range(len(dataset)), min(n_samples, len(dataset)))
    
    samples = []
    for i, idx in enumerate(indices):
        item = dataset[idx]
        sample = {
            "id": f"hotpotqa_{seed:08d}_{i:03d}",
            "task": "hotpotqa",
            "question": item["question"],
            "answer": item["answer"],
            "source": "hf",
            **metadata
        }
        samples.append(sample)
    
    return samples

def extract_samples_strategyqa(dataset, metadata, n_samples, seed):
    """ä»StrategyQAæå–æ ·æœ¬"""
    random.seed(seed + 2)
    indices = random.sample(range(len(dataset)), min(n_samples, len(dataset)))
    
    samples = []
    for i, idx in enumerate(indices):
        item = dataset[idx]
        # BigBenchæ ¼å¼ï¼šinputsæ˜¯é—®é¢˜ï¼Œtargetsæ˜¯ç­”æ¡ˆ
        question = item.get("inputs", "")
        targets = item.get("targets", [""])
        answer = "yes" if targets and ("yes" in str(targets[0]).lower() or "true" in str(targets[0]).lower()) else "no"
        
        sample = {
            "id": f"strategyqa_{seed:08d}_{i:03d}",
            "task": "strategyqa", 
            "question": question,
            "answer": answer,
            "source": "hf",
            **metadata
        }
        samples.append(sample)
    
    return samples

def extract_samples_gsm8k(dataset, metadata, n_samples, seed):
    """ä»GSM8Kæå–æ ·æœ¬"""
    random.seed(seed + 3)
    indices = random.sample(range(len(dataset)), min(n_samples, len(dataset)))
    
    samples = []
    for i, idx in enumerate(indices):
        item = dataset[idx]
        # å»é™¤æœ«å°¾è§£é‡Šï¼Œåªä¿ç•™æ•°å­—ç­”æ¡ˆ
        answer = item["answer"]
        if "####" in answer:
            answer = answer.split("####")[-1].strip()
        
        sample = {
            "id": f"gsm8k_{seed:08d}_{i:03d}",
            "task": "gsm8k",
            "question": item["question"],
            "answer": answer,
            "source": "hf",
            **metadata
        }
        samples.append(sample)
    
    return samples

def main():
    parser = argparse.ArgumentParser(description="ä»HFé‡å»ºå½±å­é›†")
    parser.add_argument("--n", type=int, default=245, help="æ€»æ ·æœ¬æ•°")
    parser.add_argument("--seed", type=int, default=20250821, help="éšæœºç§å­")
    parser.add_argument("--out", required=True, help="è¾“å‡ºJSONLæ–‡ä»¶")
    parser.add_argument("--manifest", required=True, help="æ¸…å•JSONæ–‡ä»¶")
    
    args = parser.parse_args()
    
    # åˆ†å±‚æŠ½æ ·ï¼šå°½é‡82/82/81
    n_per_task = args.n // 3
    task_counts = {
        "hotpotqa": n_per_task,
        "strategyqa": n_per_task,
        "gsm8k": args.n - 2 * n_per_task  # ä½™æ•°ç»™GSM8K
    }
    
    print(f"ğŸ”„ é‡å»ºå½±å­é›†: æ€»æ•°={args.n}, åˆ†å±‚={task_counts}")
    
    all_samples = []
    
    # HotpotQA
    print("ğŸ“¥ åŠ è½½HotpotQA...")
    dataset, metadata = load_hf_dataset("hotpot_qa", config="distractor", split="validation")
    samples = extract_samples_hotpotqa(dataset, metadata, task_counts["hotpotqa"], args.seed)
    all_samples.extend(samples)
    print(f"  âœ… HotpotQA: {len(samples)}æ ·æœ¬")
    
    # StrategyQA
    print("ğŸ“¥ åŠ è½½StrategyQA...")
    dataset, metadata = load_hf_dataset("tasksource/bigbench", config="strategyqa", split="train")
    samples = extract_samples_strategyqa(dataset, metadata, task_counts["strategyqa"], args.seed)
    all_samples.extend(samples)
    print(f"  âœ… StrategyQA: {len(samples)}æ ·æœ¬")
    
    # GSM8K
    print("ğŸ“¥ åŠ è½½GSM8K...")
    dataset, metadata = load_hf_dataset("gsm8k", config="main", split="train")
    samples = extract_samples_gsm8k(dataset, metadata, task_counts["gsm8k"], args.seed)
    all_samples.extend(samples)
    print(f"  âœ… GSM8K: {len(samples)}æ ·æœ¬")
    
    # æ‰“ä¹±é¡ºåº
    random.seed(args.seed)
    random.shuffle(all_samples)
    
    # å¯¼å‡ºJSONL
    Path(args.out).parent.mkdir(parents=True, exist_ok=True)
    with open(args.out, "w", encoding="utf-8") as f:
        for sample in all_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + "\n")
    
    # ç”Ÿæˆæ¸…å•
    by_task = {}
    for sample in all_samples:
        task = sample["task"]
        by_task[task] = by_task.get(task, 0) + 1
    
    manifest = {
        "total_samples": len(all_samples),
        "by_task": by_task,
        "seed": args.seed,
        "source": "hf",
        "samples": all_samples
    }
    
    Path(args.manifest).parent.mkdir(parents=True, exist_ok=True)
    with open(args.manifest, "w", encoding="utf-8") as f:
        json.dump(manifest, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š å®Œæˆé‡å»º: {len(all_samples)}æ ·æœ¬")
    print(f"ğŸ“‹ ä»»åŠ¡åˆ†å¸ƒ: {by_task}")
    print(f"ğŸ’¾ å¯¼å‡º: {args.out}")
    print(f"ğŸ“„ æ¸…å•: {args.manifest}")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
