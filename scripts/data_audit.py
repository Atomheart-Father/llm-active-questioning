#!/usr/bin/env python3
"""
æ•°æ®æºä½“æ£€è„šæœ¬ - åªè¯»æ£€æŸ¥ï¼Œå¿«é€Ÿæš´éœ²æ•°æ®æºå¤±æ•ˆ/fallbacké—®é¢˜
"""

import os
import json
import glob
import re
from pathlib import Path
from urllib.parse import urlparse

def scan_config_files():
    """æ‰«æé…ç½®æ–‡ä»¶ï¼Œæ”¶é›†æ•°æ®æºä¿¡æ¯"""
    sources = []
    
    # æ‰«æ configs/**/*.json
    config_files = glob.glob("configs/**/*.json", recursive=True)
    for config_file in config_files:
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # é€’å½’æŸ¥æ‰¾æ•°æ®æºé…ç½®
            def extract_sources(obj, path=""):
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        current_path = f"{path}.{key}" if path else key
                        if key in ["data", "dataset", "source"] and isinstance(value, dict):
                            if "name" in value or "url" in value or "path" in value:
                                sources.append({
                                    "config_file": config_file,
                                    "config_path": current_path,
                                    "name": value.get("name", "unnamed"),
                                    "url": value.get("url", ""),
                                    "path": value.get("path", ""),
                                    "type": "config"
                                })
                        elif isinstance(value, (dict, list)):
                            extract_sources(value, current_path)
                elif isinstance(obj, list):
                    for i, item in enumerate(obj):
                        extract_sources(item, f"{path}[{i}]")
            
            extract_sources(config)
            
        except Exception as e:
            print(f"âš ï¸ è§£æé…ç½®æ–‡ä»¶å¤±è´¥ {config_file}: {e}")
    
    return sources

def scan_data_directory():
    """æ‰«ædataç›®å½•ï¼Œæ”¶é›†æ•°æ®æ–‡ä»¶ä¿¡æ¯"""
    sources = []
    data_dir = Path("data")
    
    if not data_dir.exists():
        return sources
    
    # æ‰«æå¸¸è§æ•°æ®æ–‡ä»¶
    data_files = []
    for pattern in ["*.jsonl", "*.json", "*.csv", "*.txt"]:
        data_files.extend(data_dir.glob(pattern))
    
    for data_file in data_files:
        try:
            # å°è¯•è¯»å–ç¬¬ä¸€è¡Œåˆ¤æ–­æ ¼å¼
            with open(data_file, 'r', encoding='utf-8') as f:
                first_line = f.readline().strip()
                if first_line:
                    try:
                        sample = json.loads(first_line)
                        if isinstance(sample, dict):
                            sources.append({
                                "config_file": "data/",
                                "config_path": "data_file",
                                "name": data_file.name,
                                "url": sample.get("url", ""),
                                "path": str(data_file),
                                "type": "data_file"
                            })
                    except json.JSONDecodeError:
                        # éJSONæ ¼å¼ï¼Œè®°å½•åŸºæœ¬ä¿¡æ¯
                        sources.append({
                            "config_file": "data/",
                            "config_path": "data_file",
                            "name": data_file.name,
                            "url": "",
                            "path": str(data_file),
                            "type": "data_file"
                        })
        except Exception as e:
            print(f"âš ï¸ è¯»å–æ•°æ®æ–‡ä»¶å¤±è´¥ {data_file}: {e}")
    
    return sources

def check_local_paths(sources):
    """æ£€æŸ¥æœ¬åœ°è·¯å¾„æ˜¯å¦å­˜åœ¨"""
    issues = []
    
    for source in sources:
        path = source.get("path", "")
        if path and not path.startswith(("http://", "https://")):
            if not os.path.exists(path):
                issues.append(f"âŒ æœ¬åœ°è·¯å¾„ä¸å­˜åœ¨: {path} (æ¥è‡ª {source['config_file']})")
                source["local_exists"] = False
            else:
                source["local_exists"] = True
        else:
            source["local_exists"] = None  # URLç±»å‹
    
    return issues

def validate_urls(sources):
    """éªŒè¯URLæ ¼å¼"""
    issues = []
    
    for source in sources:
        url = source.get("url", "")
        if url:
            try:
                parsed = urlparse(url)
                if not parsed.scheme or not parsed.netloc:
                    issues.append(f"âŒ æ— æ•ˆURLæ ¼å¼: {url} (æ¥è‡ª {source['config_file']})")
                    source["url_valid"] = False
                else:
                    source["url_valid"] = True
            except Exception:
                issues.append(f"âŒ URLè§£æå¤±è´¥: {url} (æ¥è‡ª {source['config_file']})")
                source["url_valid"] = False
        else:
            source["url_valid"] = None
    
    return issues

def check_fallback_usage():
    """æ£€æŸ¥fallbackä½¿ç”¨æƒ…å†µ"""
    fallback_stats = {}
    
    # æŸ¥æ‰¾æœ€æ–°çš„shadow_evalæ–‡ä»¶
    shadow_files = glob.glob("data/shadow_eval_*.jsonl")
    if not shadow_files:
        return fallback_stats
    
    latest_file = max(shadow_files, key=os.path.getctime)
    print(f"ğŸ” æ£€æŸ¥fallbackä½¿ç”¨: {latest_file}")
    
    try:
        total_lines = 0
        fallback_lines = 0
        synthetic_lines = 0
        gen_lines = 0
        
        with open(latest_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                
                total_lines += 1
                
                # æ£€æŸ¥å„ç§fallbackæ ‡è®°
                if '"fallback":true' in line or '"fallback": true' in line:
                    fallback_lines += 1
                if '"source":"synthetic"' in line:
                    synthetic_lines += 1
                if '"source":"gen"' in line:
                    gen_lines += 1
        
        fallback_stats = {
            "file": latest_file,
            "total_lines": total_lines,
            "fallback_lines": fallback_lines,
            "synthetic_lines": synthetic_lines,
            "gen_lines": gen_lines,
            "fallback_pct": (fallback_lines / total_lines * 100) if total_lines > 0 else 0,
            "synthetic_pct": (synthetic_lines / total_lines * 100) if total_lines > 0 else 0,
            "gen_pct": (gen_lines / total_lines * 100) if total_lines > 0 else 0
        }
        
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥fallbackå¤±è´¥: {e}")
    
    return fallback_stats

def main():
    """ä¸»ä½“æ£€æµç¨‹"""
    print("ğŸ” æ•°æ®æºä½“æ£€å¼€å§‹")
    print("=" * 50)
    
    # 1. æ‰«æé…ç½®å’Œæ•°æ®æ–‡ä»¶
    print("ğŸ“‹ æ‰«ææ•°æ®æº...")
    config_sources = scan_config_files()
    data_sources = scan_data_directory()
    all_sources = config_sources + data_sources
    
    print(f"  å‘ç° {len(all_sources)} ä¸ªæ•°æ®æº")
    
    # 2. æ£€æŸ¥æœ¬åœ°è·¯å¾„
    print("\nğŸ“ æ£€æŸ¥æœ¬åœ°è·¯å¾„...")
    path_issues = check_local_paths(all_sources)
    for issue in path_issues:
        print(issue)
    
    # 3. éªŒè¯URL
    print("\nğŸŒ éªŒè¯URLæ ¼å¼...")
    url_issues = validate_urls(all_sources)
    for issue in url_issues:
        print(issue)
    
    # 4. æ£€æŸ¥fallbackä½¿ç”¨
    print("\nâš ï¸ æ£€æŸ¥fallbackä½¿ç”¨...")
    fallback_stats = check_fallback_usage()
    
    if fallback_stats:
        print(f"  æ–‡ä»¶: {fallback_stats['file']}")
        print(f"  æ€»è¡Œæ•°: {fallback_stats['total_lines']}")
        print(f"  fallbackæ ‡è®°: {fallback_stats['fallback_lines']} ({fallback_stats['fallback_pct']:.1f}%)")
        print(f"  syntheticæ ‡è®°: {fallback_stats['synthetic_lines']} ({fallback_stats['synthetic_pct']:.1f}%)")
        print(f"  genæ ‡è®°: {fallback_stats['gen_lines']} ({fallback_stats['gen_pct']:.1f}%)")
    
    # 5. æ±‡æ€»æŠ¥å‘Š
    print("\nğŸ“Š æ±‡æ€»æŠ¥å‘Š")
    print("=" * 50)
    
    local_missing = len([s for s in all_sources if s.get("local_exists") == False])
    url_invalid = len([s for s in all_sources if s.get("url_valid") == False])
    has_fallback = fallback_stats.get("fallback_pct", 0) > 0 if fallback_stats else False
    
    print(f"æœ¬åœ°è·¯å¾„ç¼ºå¤±: {local_missing}")
    print(f"URLæ ¼å¼æ— æ•ˆ: {url_invalid}")
    print(f"å­˜åœ¨fallback: {'æ˜¯' if has_fallback else 'å¦'}")
    
    # 6. é€€å‡ºç åˆ¤æ–­
    if local_missing > 0 or url_invalid > 0 or has_fallback:
        print("\nâŒ ä½“æ£€å‘ç°é—®é¢˜ï¼Œé€€å‡ºç : 1")
        return 1
    else:
        print("\nâœ… ä½“æ£€é€šè¿‡ï¼Œé€€å‡ºç : 0")
        return 0

if __name__ == "__main__":
    exit(main())
