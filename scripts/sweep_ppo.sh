#!/bin/bash
# Phase 3.2 è¶…å‚æ•°æ‰«æè„šæœ¬
# ç”¨äºRC1æ¨¡å‹çš„ç³»ç»Ÿæ€§è¶…å‚æ•°è°ƒä¼˜

set -e

echo "ğŸ” PPOè¶…å‚æ•°æ‰«æ - Phase 3.2"
echo "=================================="

# æ£€æŸ¥ç¯å¢ƒ
if [ -z "$BASE_MODEL" ]; then
    echo "âŒ é”™è¯¯: è¯·è®¾ç½® BASE_MODEL ç¯å¢ƒå˜é‡"
    exit 1
fi

# åˆ›å»ºæ‰«æç»“æœç›®å½•
SWEEP_DIR="reports/rc1/sweeps"
mkdir -p "$SWEEP_DIR"

# åŸºç¡€é…ç½®æ–‡ä»¶
BASE_CONFIG="configs/ppo_scale.yaml"
if [ ! -f "$BASE_CONFIG" ]; then
    echo "âŒ é”™è¯¯: åŸºç¡€é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: $BASE_CONFIG"
    exit 1
fi

# æ‰«æå‚æ•°å®šä¹‰
declare -a LEARNING_RATES=("5e-6" "1e-5" "2e-5")
declare -a ALPHA_VALUES=("0.05" "0.07" "0.10")
declare -a KL_COEFS=("0.01" "0.02" "0.03")
declare -a SEEDS=("20250820" "20250821" "20250822")

echo "ğŸ“‹ æ‰«æè®¡åˆ’:"
echo "   å­¦ä¹ ç‡: ${LEARNING_RATES[*]}"
echo "   Î±å€¼: ${ALPHA_VALUES[*]}"
echo "   KLç³»æ•°: ${KL_COEFS[*]}"
echo "   ç§å­: ${SEEDS[*]}"
echo "   æ€»ç»„åˆæ•°: $((${#LEARNING_RATES[@]} * ${#ALPHA_VALUES[@]} * ${#KL_COEFS[@]}))"

# è®°å½•å¼€å§‹æ—¶é—´
START_TIME=$(date +%s)
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

# æ‰«ææ—¥å¿—
SWEEP_LOG="$SWEEP_DIR/sweep_$TIMESTAMP.log"
echo "ğŸ“ æ‰«ææ—¥å¿—: $SWEEP_LOG"

# å‡½æ•°ï¼šè¿è¡Œå•ä¸ªæ‰«æå®éªŒ
run_sweep_experiment() {
    local lr=$1
    local alpha=$2
    local kl_coef=$3
    local exp_id="${lr}_${alpha}_${kl_coef}"
    
    echo "ğŸš€ è¿è¡Œå®éªŒ: lr=$lr, Î±=$alpha, kl=$kl_coef" | tee -a "$SWEEP_LOG"
    
    # åˆ›å»ºå®éªŒä¸“ç”¨é…ç½®
    local exp_config="$SWEEP_DIR/config_$exp_id.yaml"
    cp "$BASE_CONFIG" "$exp_config"
    
    # ä¿®æ”¹é…ç½®å‚æ•°ï¼ˆä½¿ç”¨ä¸´æ—¶Pythonè„šæœ¬ï¼‰
    python3 << EOF
import yaml
with open('$exp_config', 'r') as f:
    config = yaml.safe_load(f)

config['lr'] = float('$lr')
config['overclar']['alpha'] = float('$alpha') 
config['init_kl_coef'] = float('$kl_coef')

# ç¼©å‡æ‰«æå®éªŒè§„æ¨¡
config['steps'] = 10000  # é™åˆ°10kæ­¥
config['train_samples'] = 20000  # é™åˆ°20kæ ·æœ¬
config['eval_shadow_n'] = 100  # é™åˆ°100æ ·æœ¬è¯„ä¼°

with open('$exp_config', 'w') as f:
    yaml.dump(config, f, default_flow_style=False)
EOF
    
    # è¿è¡Œå®éªŒ
    local exp_output="$SWEEP_DIR/result_$exp_id.json"
    if python -m train.ppo_runner --config "$exp_config" > "$SWEEP_DIR/log_$exp_id.txt" 2>&1; then
        echo "âœ… å®éªŒå®Œæˆ: $exp_id" | tee -a "$SWEEP_LOG"
        
        # æå–å…³é”®æŒ‡æ ‡
        if [ -f "reports/rc1/rc1_final_report.json" ]; then
            python3 << EOF
import json
try:
    with open('reports/rc1/rc1_final_report.json', 'r') as f:
        result = json.load(f)
    
    # æå–å…³é”®æŒ‡æ ‡
    summary = {
        'experiment_id': '$exp_id',
        'hyperparams': {'lr': $lr, 'alpha': $alpha, 'kl_coef': $kl_coef},
        'timestamp': '$(date -Iseconds)'
    }
    
    if 'aggregate' in result:
        agg = result['aggregate']
        summary['metrics'] = {
            'success_improvement_median': agg.get('success_deltas_pp', {}).get('hotpotqa', {}).get('median', 0),
            'overclar_reduction_median': agg.get('overclar_reduction_pct', {}).get('median', 0),
            'shadow_spearman_median': agg.get('shadow_metrics', {}).get('spearman', {}).get('median', 0)
        }
    
    if 'acceptance_check' in result:
        summary['passed'] = result['acceptance_check']['all_passed']
    
    with open('$exp_output', 'w') as f:
        json.dump(summary, f, indent=2)
        
except Exception as e:
    print(f"æå–æŒ‡æ ‡å¤±è´¥: {e}")
EOF
        fi
    else
        echo "âŒ å®éªŒå¤±è´¥: $exp_id" | tee -a "$SWEEP_LOG"
        echo "{'experiment_id': '$exp_id', 'error': 'training_failed'}" > "$exp_output"
    fi
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    rm -f "$exp_config"
}

# ä¸»æ‰«æå¾ªç¯
experiment_count=0
total_experiments=$((${#LEARNING_RATES[@]} * ${#ALPHA_VALUES[@]} * ${#KL_COEFS[@]}))

echo "ğŸ å¼€å§‹è¶…å‚æ•°æ‰«æ..." | tee -a "$SWEEP_LOG"

for lr in "${LEARNING_RATES[@]}"; do
    for alpha in "${ALPHA_VALUES[@]}"; do
        for kl_coef in "${KL_COEFS[@]}"; do
            experiment_count=$((experiment_count + 1))
            echo "ğŸ“Š è¿›åº¦: $experiment_count/$total_experiments"
            
            run_sweep_experiment "$lr" "$alpha" "$kl_coef"
            
            # ç®€çŸ­ä¼‘æ¯é¿å…èµ„æºå†²çª
            sleep 5
        done
    done
done

# ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
echo "ğŸ“Š ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š..." | tee -a "$SWEEP_LOG"

SUMMARY_REPORT="$SWEEP_DIR/sweep_summary_$TIMESTAMP.json"

python3 << EOF
import json
import glob
from pathlib import Path

sweep_dir = Path('$SWEEP_DIR')
result_files = list(sweep_dir.glob('result_*.json'))

experiments = []
for file in result_files:
    try:
        with open(file, 'r') as f:
            exp_data = json.load(f)
        experiments.append(exp_data)
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file}: {e}")

# æŒ‰æˆåŠŸç‡æ”¹å–„æ’åº
experiments.sort(key=lambda x: x.get('metrics', {}).get('success_improvement_median', 0), reverse=True)

# ç»Ÿè®¡ä¿¡æ¯
passed_count = sum(1 for exp in experiments if exp.get('passed', False))
total_count = len(experiments)

summary = {
    'sweep_metadata': {
        'timestamp': '$TIMESTAMP',
        'total_experiments': total_count,
        'passed_experiments': passed_count,
        'success_rate': passed_count / total_count if total_count > 0 else 0
    },
    'best_experiments': experiments[:5],  # Top 5
    'all_experiments': experiments
}

with open('$SUMMARY_REPORT', 'w') as f:
    json.dump(summary, f, indent=2, ensure_ascii=False)

print(f"æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: $SUMMARY_REPORT")
print(f"æˆåŠŸå®éªŒ: {passed_count}/{total_count} ({passed_count/total_count*100:.1f}%)")

if experiments:
    best = experiments[0]
    print(f"æœ€ä½³é…ç½®: {best.get('hyperparams', {})}")
    if 'metrics' in best:
        metrics = best['metrics']
        print(f"  æˆåŠŸç‡æ”¹å–„: {metrics.get('success_improvement_median', 0):.2f}pp")
        print(f"  è¿‡åº¦æ¾„æ¸…é™ä½: {metrics.get('overclar_reduction_median', 0):.1f}%")
        print(f"  å½±å­Spearman: {metrics.get('shadow_spearman_median', 0):.3f}")
EOF

# è®¡ç®—æ€»ç”¨æ—¶
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))
HOURS=$((DURATION / 3600))
MINUTES=$(((DURATION % 3600) / 60))

echo "â±ï¸  æ‰«æå®Œæˆï¼" | tee -a "$SWEEP_LOG"
echo "   æ€»ç”¨æ—¶: ${HOURS}h ${MINUTES}m" | tee -a "$SWEEP_LOG"
echo "   ç»“æœç›®å½•: $SWEEP_DIR" | tee -a "$SWEEP_LOG"
echo "   æ±‡æ€»æŠ¥å‘Š: $SUMMARY_REPORT" | tee -a "$SWEEP_LOG"

echo "ğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®:"
echo "   1. æŸ¥çœ‹ $SUMMARY_REPORT ç¡®å®šæœ€ä½³è¶…å‚æ•°"
echo "   2. ä½¿ç”¨æœ€ä½³é…ç½®è¿è¡Œå®Œæ•´è®­ç»ƒ: python -m train.ppo_runner --config configs/ppo_scale.yaml"
echo "   3. è¿è¡Œå¯é€‰åˆ†æ”¯: DPOä¼˜åŒ– æˆ– GGUFéƒ¨ç½²"
