# Active QA v1 - è®­ç»ƒå°±ç»ªåŒ…

**ç‰ˆæœ¬**: v1.0
**ç”Ÿæˆæ—¶é—´**: 2025-09-03
**æ€»æ ·æœ¬æ•°**: 1400 (è®­ç»ƒ: 1120, éªŒè¯: 140, æµ‹è¯•: 140)

## ğŸ“¦ åŒ…å†…å®¹

æœ¬è®­ç»ƒå°±ç»ªåŒ…åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š

### æ•°æ®é›†æ–‡ä»¶
- `train.jsonl` - è®­ç»ƒæ•°æ®é›† (1120 æ ·æœ¬)
- `dev.jsonl` - éªŒè¯æ•°æ®é›† (140 æ ·æœ¬)
- `test.jsonl` - æµ‹è¯•æ•°æ®é›† (140 æ ·æœ¬)

### é…ç½®å’Œå…ƒæ•°æ®
- `schema.json` - æ•°æ®æ ¼å¼è§„èŒƒ
- `metrics.json` - è´¨é‡ç»Ÿè®¡å’Œå…ƒæ•°æ®
- `provenance.csv` - æ•°æ®æ¥æºè¿½è¸ª

## ğŸ“Š æ•°æ®é›†ç»Ÿè®¡

### æ€»ä½“ç»Ÿè®¡
- **æ€»æ ·æœ¬æ•°**: 1400
- **å»é‡å**: ä»1456ä¸ªåŸå§‹æ ·æœ¬å»é‡å¾—åˆ°
- **å¯¹é½å‡†ç¡®ç‡**: 100% (0ä¸ªå¯¹é½é”™è¯¯)
- **å­—æ®µå®Œå¤‡ç‡**: 100%

### ä»»åŠ¡ç±»å‹åˆ†å¸ƒ
- **ambiguous**: 1100 æ ·æœ¬ (78.6%)
- **multihop**: 200 æ ·æœ¬ (14.3%)
- **longform**: 100 æ ·æœ¬ (7.1%)

### æ•°æ®æ¥æº
- **AmbigQA**: 1156 æ ·æœ¬ (cc-by-sa-3.0)
- **HotpotQA**: 200 æ ·æœ¬ (cc-by-sa-4.0)
- **ASQA**: 100 æ ·æœ¬ (apache-2.0)
- **GSM8K**: 200 æ ·æœ¬ (mit)

## ğŸ”§ æ•°æ®æ ¼å¼

æ¯ä¸ªæ ·æœ¬çš„JSONæ ¼å¼å¦‚ä¸‹ï¼š

```json
{
  "uid": "unique_identifier",
  "user_query": "ç”¨æˆ·é—®é¢˜æ–‡æœ¬",
  "needs_clarification": true,
  "clarification_questions": ["æ¾„æ¸…é—®å¥1", "æ¾„æ¸…é—®å¥2"],
  "provided_context": "ä¸Šä¸‹æ–‡ä¿¡æ¯",
  "assistant_response": "è‹¥é—®é¢˜1åˆ™ç­”æ¡ˆï¼šxxxï¼›è‹¥é—®é¢˜2åˆ™ç­”æ¡ˆï¼šyyy",
  "task_type": "ambiguous|multihop|longform|math",
  "source": "ambigqa|hotpotqa|asqa|gsm8k",
  "licensing": "cc-by-sa-3.0|cc-by-sa-4.0|apache-2.0|mit",
  "gen_meta": {
    "synthesis_method": "stage2_xxx_v1",
    "raw_sample_id": "åŸå§‹æ ·æœ¬ID",
    "synthesis_timestamp": "ç”Ÿæˆæ—¶é—´æˆ³",
    // ... å…¶ä»–å…ƒæ•°æ®
  }
}
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬åŠ è½½
```python
import json

# åŠ è½½è®­ç»ƒæ•°æ®
train_data = []
with open('train.jsonl', 'r', encoding='utf-8') as f:
    for line in f:
        if line.strip():
            train_data.append(json.loads(line.strip()))

print(f"åŠ è½½äº† {len(train_data)} ä¸ªè®­ç»ƒæ ·æœ¬")
```

### æŒ‰ä»»åŠ¡ç±»å‹è¿‡æ»¤
```python
# æŒ‰ä»»åŠ¡ç±»å‹åˆ†ç»„
from collections import defaultdict

by_task_type = defaultdict(list)
for sample in train_data:
    task_type = sample['task_type']
    by_task_type[task_type].append(sample)

print("ä»»åŠ¡ç±»å‹åˆ†å¸ƒ:")
for task_type, samples in by_task_type.items():
    print(f"  {task_type}: {len(samples)} æ ·æœ¬")
```

## ğŸ¯ è´¨é‡ä¿è¯

- âœ… **é›¶æ¨¡æ‹Ÿ**: æ‰€æœ‰æ•°æ®å‡åŸºäºçœŸå®æ•°æ®é›†åˆæˆï¼Œæ— æ¨¡æ‹Ÿå†…å®¹
- âœ… **å®Œç¾å¯¹é½**: æ‰€æœ‰æ¾„æ¸…é—®å¥ä¸ç­”æ¡ˆä¸€ä¸€å¯¹åº”
- âœ… **è®¸å¯åˆè§„**: ä¸¥æ ¼æŒ‰ç…§åŸå§‹æ•°æ®æºè®¸å¯æ ‡æ³¨
- âœ… **å»é‡å¤„ç†**: åŸºäºæ–‡æœ¬ç›¸ä¼¼åº¦å»é‡ï¼Œç§»é™¤é‡å¤æ ·æœ¬
- âœ… **åˆ†å±‚åˆ‡åˆ†**: æŒ‰ä»»åŠ¡ç±»å‹æ¯”ä¾‹åˆ‡åˆ†ï¼Œç¡®ä¿åˆ†å¸ƒå‡è¡¡

## ğŸ“ˆ è®­ç»ƒå»ºè®®

1. **æ‰¹é‡å¤§å°**: å»ºè®®ä»16-32å¼€å§‹ï¼Œæ ¹æ®GPUå†…å­˜è°ƒæ•´
2. **å­¦ä¹ ç‡**: ä»1e-5åˆ°5e-5å¼€å§‹ï¼Œæ ¹æ®æ¨¡å‹å¤§å°è°ƒæ•´
3. **éªŒè¯ç­–ç•¥**: æ¯ä¸ªepochååœ¨devé›†ä¸Šè¯„ä¼°
4. **æ—©åœæœºåˆ¶**: åŸºäºdevé›†æ€§èƒ½è®¾ç½®patience=3-5

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [æ•°æ®å¡](../docs/dataset_card_active_qa_v1.md) - è¯¦ç»†çš„æ•°æ®é›†ä»‹ç»
- [åˆæˆç­–ç•¥](../../docs/stage2_plan_and_decisions.md) - åˆæˆæ–¹æ³•å’ŒæŠ€æœ¯ç»†èŠ‚
- [è´¨é‡æŠ¥å‘Š](../../data/processed/active_qa_v1/metrics.json) - å®Œæ•´è´¨é‡ç»Ÿè®¡

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»æ•°æ®å›¢é˜Ÿæˆ–æŸ¥é˜…ç›¸å…³æ–‡æ¡£ã€‚

---
**ç”Ÿæˆè€…**: Cursor AI Assistant
**æœ€åæ›´æ–°**: 2025-09-03
