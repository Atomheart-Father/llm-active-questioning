#!/usr/bin/env python3
"""è¯¦ç»†è°ƒè¯•Data Sprint-Î²å¡ä½é—®é¢˜çš„è„šæœ¬"""

import os
import sys
import time
import logging
import traceback

# è®¾ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('debug_sprint_beta.log')
    ]
)

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

def debug_data_generation():
    """è°ƒè¯•æ•°æ®ç”Ÿæˆè¿‡ç¨‹"""
    try:
        print("ğŸš€ å¼€å§‹è¯¦ç»†è°ƒè¯•æ•°æ®ç”Ÿæˆ...")
        logger = logging.getLogger(__name__)

        # æ­¥éª¤1: å¯¼å…¥æ¨¡å—
        logger.info("æ­¥éª¤1: å¯¼å…¥æ¨¡å—")
        from tools.data_generator import DataGenerator, GenerationConfig

        # æ­¥éª¤2: åˆ›å»ºé…ç½®
        logger.info("æ­¥éª¤2: åˆ›å»ºé…ç½®")
        config = GenerationConfig(
            batch_date="2025-09-03",
            alc_count=5,  # å…ˆç”¨å°æ•°é‡æµ‹è¯•
            ar_count=3,
            rsd_count=2
        )

        # æ­¥éª¤3: åˆå§‹åŒ–ç”Ÿæˆå™¨
        logger.info("æ­¥éª¤3: åˆå§‹åŒ–ç”Ÿæˆå™¨")
        generator = DataGenerator(config)

        # æ­¥éª¤4: æµ‹è¯•å•ä¸ªæ ·æœ¬ç”Ÿæˆ
        logger.info("æ­¥éª¤4: æµ‹è¯•ALCæ ·æœ¬ç”Ÿæˆ")
        alc_samples = generator.generate_alc_data()
        logger.info(f"ALCç”Ÿæˆå®Œæˆ: {len(alc_samples)} ä¸ªæ ·æœ¬")

        # æ­¥éª¤5: æµ‹è¯•ARæ ·æœ¬ç”Ÿæˆ
        logger.info("æ­¥éª¤5: æµ‹è¯•ARæ ·æœ¬ç”Ÿæˆ")
        ar_samples = generator.generate_ar_data()
        logger.info(f"ARç”Ÿæˆå®Œæˆ: {len(ar_samples)} ä¸ªæ ·æœ¬")

        # æ­¥éª¤6: æµ‹è¯•RSDæ ·æœ¬ç”Ÿæˆ
        logger.info("æ­¥éª¤6: æµ‹è¯•RSDæ ·æœ¬ç”Ÿæˆ")
        rsd_samples = generator.generate_rsd_data()
        logger.info(f"RSDç”Ÿæˆå®Œæˆ: {len(rsd_samples)} ä¸ªæ ·æœ¬")

        # æ­¥éª¤7: ä¿å­˜æ ·æœ¬
        logger.info("æ­¥éª¤7: ä¿å­˜æ ·æœ¬")
        if alc_samples:
            generator.save_samples(alc_samples, "ALC/part-001.jsonl")
        if ar_samples:
            generator.save_samples(ar_samples, "AR/part-001.jsonl")
        if rsd_samples:
            generator.save_samples(rsd_samples, "RSD/part-001.jsonl")

        # æ­¥éª¤8: ä¿å­˜provenance
        logger.info("æ­¥éª¤8: ä¿å­˜provenance")
        generator.save_provenance()

        total = len(alc_samples) + len(ar_samples) + len(rsd_samples)
        logger.info(f"âœ… æ•°æ®ç”Ÿæˆå®Œæˆ: æ€»è®¡ {total} ä¸ªæ ·æœ¬")

        return True

    except Exception as e:
        logger.error(f"âŒ æ•°æ®ç”Ÿæˆè°ƒè¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def debug_full_pipeline():
    """è°ƒè¯•å®Œæ•´æµæ°´çº¿"""
    try:
        print("\nğŸš€ å¼€å§‹è°ƒè¯•å®Œæ•´æµæ°´çº¿...")
        logger = logging.getLogger(__name__)

        # æ­¥éª¤1: å¯¼å…¥DataSprintBeta
        logger.info("æµæ°´çº¿æ­¥éª¤1: å¯¼å…¥DataSprintBeta")
        from tools.data_sprint_beta import DataSprintBeta

        # æ­¥éª¤2: åˆå§‹åŒ–
        logger.info("æµæ°´çº¿æ­¥éª¤2: åˆå§‹åŒ–DataSprintBeta")
        sprint = DataSprintBeta(
            data_date="2025-09-03",
            target_alc=5,
            target_ar=3,
            target_rsd=2
        )

        # æ­¥éª¤3: ç¯å¢ƒæ£€æŸ¥
        logger.info("æµæ°´çº¿æ­¥éª¤3: ç¯å¢ƒæ£€æŸ¥")
        if not sprint.check_environment():
            logger.error("ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
            return False

        # æ­¥éª¤4: æ•°æ®ç”Ÿæˆ
        logger.info("æµæ°´çº¿æ­¥éª¤4: æ•°æ®ç”Ÿæˆ")
        start_time = time.time()
        if not sprint.generate_data():
            logger.error("æ•°æ®ç”Ÿæˆå¤±è´¥")
            return False
        generation_time = time.time() - start_time
        logger.info(".2f")
        # æ­¥éª¤5: å»é‡å¤„ç†
        logger.info("æµæ°´çº¿æ­¥éª¤5: å»é‡å¤„ç†")
        start_time = time.time()
        if not sprint.deduplicate_data():
            logger.error("å»é‡å¤„ç†å¤±è´¥")
            return False
        dedup_time = time.time() - start_time
        logger.info(".2f")
        # æ­¥éª¤6: è´¨é‡è¯„å®¡
        logger.info("æµæ°´çº¿æ­¥éª¤6: è´¨é‡è¯„å®¡")
        start_time = time.time()
        if not sprint.review_quality():
            logger.error("è´¨é‡è¯„å®¡å¤±è´¥")
            return False
        review_time = time.time() - start_time
        logger.info(".2f")
        # æ­¥éª¤7: æœ€ç»ˆéªŒè¯
        logger.info("æµæ°´çº¿æ­¥éª¤7: æœ€ç»ˆéªŒè¯")
        if not sprint.validate_final_dataset():
            logger.error("æœ€ç»ˆéªŒè¯å¤±è´¥")
            return False

        # æ­¥éª¤8: ç”ŸæˆæŠ¥å‘Š
        logger.info("æµæ°´çº¿æ­¥éª¤8: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
        if not sprint.generate_final_report():
            logger.error("ç”ŸæˆæŠ¥å‘Šå¤±è´¥")
            return False

        logger.info("âœ… å®Œæ•´æµæ°´çº¿è°ƒè¯•æˆåŠŸ")
        return True

    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"âŒ æµæ°´çº¿è°ƒè¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è¯¦ç»†è°ƒè¯•Data Sprint-Î²å¡ä½é—®é¢˜...")
    print("=" * 60)

    # è®¾ç½®æ›´è¯¦ç»†çš„æ—¥å¿—
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹è°ƒè¯•ä¼šè¯")

    # æµ‹è¯•1: æ•°æ®ç”Ÿæˆè¿‡ç¨‹
    print("\nğŸ“Š æµ‹è¯•1: æ•°æ®ç”Ÿæˆè¿‡ç¨‹")
    if not debug_data_generation():
        print("âŒ æ•°æ®ç”Ÿæˆæµ‹è¯•å¤±è´¥")
        return False

    # æµ‹è¯•2: å®Œæ•´æµæ°´çº¿
    print("\nğŸ“Š æµ‹è¯•2: å®Œæ•´æµæ°´çº¿")
    if not debug_full_pipeline():
        print("âŒ æµæ°´çº¿æµ‹è¯•å¤±è´¥")
        return False

    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰è°ƒè¯•æµ‹è¯•é€šè¿‡ï¼")
    print("ğŸ“‹ æ£€æŸ¥ debug_sprint_beta.log è·å–è¯¦ç»†æ—¥å¿—")
    print("ğŸ’¡ å¦‚æœç”Ÿäº§ç¯å¢ƒä»æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶å®šä½å…·ä½“å¡ä½ä½ç½®")

    logger.info("è°ƒè¯•ä¼šè¯ç»“æŸ")
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
