#!/bin/bash
set -euxo pipefail
export PYTHONHASHSEED=0
export RUN_SEED=20250901
mkdir -p artifacts

echo "ğŸš€ RC1 SOP v0.3 - é…é¢å‹å¥½ + Top-10å†²çº¿ç‰ˆ"

# è®¾ç½®ç¯å¢ƒå˜é‡
export GEMINI_API_KEY="AIzaSyBLECdu94qJWPFOZ--9dIKpeWaWjSGJ_z0"
export SCORER_PROVIDER=gemini
export RATE_LIMIT_RPM=9
export RATE_LIMIT_CONCURRENCY=1
export PYTHONPATH=/Users/bozhongxiao/Desktop/å…‹ç½—ç±³ç‹å›½å›½ç«‹ç”µå°/ä»£ç é¡¹ç›®/project:$PYTHONPATH

# 0) ç¯å¢ƒæŒ‡çº¹
echo "ğŸ“‹ æ­¥éª¤0: ç¯å¢ƒæŒ‡çº¹"
git checkout main && git pull
git rev-parse HEAD | tee artifacts/HEAD.sha
pip freeze > artifacts/requirements.lock.txt

# 0.1) æ£€æŸ¥å›ºå®šè¯„æµ‹æ¸…å•
echo "ğŸ“‹ æ­¥éª¤0.1: æ£€æŸ¥è¯„æµ‹æ¸…å•"
if [ ! -f artifacts/shadow_manifest.jsonl ]; then
  echo "ç”Ÿæˆæ–°çš„è¯„æµ‹æ¸…å•..."
  python tools/sample_shadow.py --n 245 --stratified --seed "${RUN_SEED}" \
    --out artifacts/shadow_manifest.jsonl
else
  echo "âœ… å¤ç”¨ç°æœ‰è¯„æµ‹æ¸…å•"
  wc -l artifacts/shadow_manifest.jsonl
fi

# 1) è¯„åˆ†é€šé“ï¼šGemini Only + é…é¢å‹å¥½
echo "ğŸ”¬ æ­¥éª¤1: è¯„åˆ†é€šé“çœŸè¿æ¥è¯æ˜"
python scripts/prove_gemini_real.py

# éªŒè¯ï¼šè‡³å°‘1æ¡æ­£ä¾‹+1æ¡è´Ÿä¾‹ï¼›Routerå¿…é¡»Gemini Only
python - <<'PY'
import json,sys
ok=neg=0
for ln in open('artifacts/score_canary.jsonl','r',encoding='utf-8'):
    r=json.loads(ln)
    ok+=int(r.get('status')=='success')
    neg+=int(r.get('test_type')=='negative_case')
print(f"canary_ok={ok}, canary_neg={neg}")
assert ok>=1 and neg>=1, "ç¼ºå°‘æ­£/è´Ÿä¾‹ï¼šæ£€æŸ¥ score_canary.jsonl"
cfg=json.load(open('artifacts/router_dump.json'))
assert cfg.get('gemini_api_key_set')==True, "gemini_api_key æœªè®¾ç½®"
allowed=cfg.get('routing_rules',{}).get('allowed_providers',[])
assert cfg.get('scorer_provider')=="gemini" and allowed==["gemini"], f"Router é Gemini Only: {allowed}"
print("âœ… Canary & RouteréªŒè¯é€šè¿‡")
PY

# 2) å½±å­è¯„æµ‹ï¼ˆé…é¢å‹å¥½æ‰¹æ¬¡æ‰§è¡Œï¼‰
echo "ğŸ¯ æ­¥éª¤2: å½±å­è¯„æµ‹åˆ†æ‰¹æ‰§è¡Œ"
# å°†245æ¡æŒ‰3ä¸ªæ‰¹æ¬¡è·‘ï¼ˆ85/æ‰¹ï¼‰ï¼Œæ‰¹é—´sleep 60s
split -l 85 artifacts/shadow_manifest.jsonl artifacts/batch_
for f in artifacts/batch_*; do
  mv "$f" "$f.jsonl"
  echo "å¤„ç†æ‰¹æ¬¡: $f.jsonl"
  python scripts/shadow_run.py \
    --in "$f.jsonl" \
    --append \
    --metrics-out artifacts/shadow_run_metrics.json \
    --manifest-out artifacts/shadow_manifest.enriched.jsonl || true
  echo "æ‰¹æ¬¡å®Œæˆï¼Œç­‰å¾…60ç§’..."
  sleep 60
done

# 3) è¯Šæ–­é¢æ¿
echo "ğŸ” æ­¥éª¤3: è¯Šæ–­é¢æ¿åˆ†æ"
python scripts/analyze_reward_dimensions.py \
  --in artifacts/shadow_manifest.enriched.jsonl \
  --schema enriched \
  --out-json artifacts/reward_diag_v3.json \
  --out-csv artifacts/reward_diag_v3.csv

# 4) Top-10å®šå‘ä¼˜åŒ–ï¼ˆç¦»çº¿æƒé‡æœç´¢ï¼‰
echo "ğŸ¯ æ­¥éª¤4: Top-10å®šå‘ä¼˜åŒ–"
python - <<'PY'
import json, numpy as np, random
rng = np.random.RandomState(20250901)
dims = ["logic_rigor","question_quality","reasoning_completeness","natural_interaction"]
X, G = [], []
for ln in open("artifacts/shadow_manifest.enriched.jsonl","r",encoding="utf-8"):
    r=json.loads(ln)
    s=r.get("subscores") or r.get("scores") or {}
    if all(k in s for k in dims) and "gold_rank" in r:
        X.append([float(s[k]) for k in dims])
        G.append(int(r["gold_rank"]))
X=np.array(X); G=np.array(G)
print(f"åŠ è½½äº† {len(X)} ä¸ªæœ‰æ•ˆæ ·æœ¬ç”¨äºä¼˜åŒ–")
if len(X) == 0:
    print("âš ï¸ æ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡æƒé‡ä¼˜åŒ–")
    exit(0)
def topk(scores, gold, k=10):
    import numpy as np
    return float(np.mean((gold<=k).astype(np.float32)))
def spearman(scores, gold):
    from scipy.stats import spearmanr
    return float(spearmanr(-scores, gold).correlation)
best=(None,None,None,None)
def dirichlet(alpha, n):
    x=rng.gamma(alpha,1,size=(n,len(dims)))
    x=x/x.sum(axis=1,keepdims=True)
    return x
for w in dirichlet(1.5, 60):  # 60æ¬¡è¯•æ¢
    s=X@w
    t10=topk(s,G,10)
    sp=spearman(s,G)
    score = t10 + 0.2*sp
    if (best[0] is None) or (score>best[0]):
        best=(score,w.tolist(),t10,sp)
json.dump({"weights":dict(zip(dims,best[1])),"top10":best[2],"spearman":best[3]},
          open("artifacts/weight_grid_topk_v3.json","w"), indent=2, ensure_ascii=False)
print(f"âœ… æœ€ä½³æƒé‡: Top10={best[2]:.4f}, Spearman={best[3]:.4f}")
PY

# 4.1 åº”ç”¨æ–°æƒé‡
echo "âš–ï¸ æ­¥éª¤4.1: åº”ç”¨æ–°æƒé‡"
python - <<'PY'
import json
g=json.load(open("artifacts/weight_grid_topk_v3.json"))
w=g["weights"]
s=sum(w.values())
w={k:v/s for k,v in w.items()}
try:
    cfg=json.load(open("configs/weights.json"))
except:
    cfg={"weights": {}}
cfg["weights"] = w
# ç¡®ä¿äº”é”®é½å…¨
for k in ["logic_rigor","question_quality","reasoning_completeness","natural_interaction","rules"]:
    if k not in cfg["weights"]:
        cfg["weights"][k] = 0.0
json.dump(cfg, open("configs/weights.json","w"), indent=2, ensure_ascii=False)
print("âœ… æ–°æƒé‡å·²åº”ç”¨:", cfg["weights"])
PY

# 4.2 å¤è·‘ShadowRunï¼ˆä»æŒ‰3æ‰¹ï¼‰
echo "ğŸ”„ æ­¥éª¤4.2: å¤è·‘ShadowRunéªŒè¯æ–°æƒé‡"
rm -f artifacts/shadow_run_metrics_v3.json artifacts/shadow_manifest.enriched_v3.jsonl
for f in artifacts/batch_*.jsonl; do
  python scripts/shadow_run.py \
    --in "$f" \
    --append \
    --metrics-out artifacts/shadow_run_metrics_v3.json \
    --manifest-out artifacts/shadow_manifest.enriched_v3.jsonl || true
  echo "æ‰¹æ¬¡å®Œæˆï¼Œç­‰å¾…60ç§’..."
  sleep 60
done

# 5) é¢„æ£€å¯¹é½
echo "ğŸŸ¡ æ­¥éª¤5: é¢„æ£€å¯¹é½"
python scripts/pre_run_check.py \
  --data-root shadow_data \
  --metrics artifacts/shadow_run_metrics_v3.json \
  --out artifacts/pre_run_check.dev_v3.json || true

python scripts/pre_run_check.py \
  --data-root shadow_data \
  --metrics artifacts/shadow_run_metrics_v3.json \
  --strict-metrics \
  --out artifacts/pre_run_check.ci_v3.json || true

# 6) æ‰“åŒ…è¯æ®ï¼ˆv3ï¼‰
echo "ğŸ“¦ æ­¥éª¤6: æ‰“åŒ…è¯æ®v3"
tar -czf artifacts/rc1_evidence_$(date +%Y%m%d_%H%M)_v3.tar.gz \
  artifacts/HEAD.sha \
  artifacts/requirements.lock.txt \
  artifacts/router_dump.json \
  artifacts/score_canary.jsonl \
  artifacts/shadow_manifest.jsonl \
  artifacts/shadow_manifest.enriched_v3.jsonl \
  artifacts/shadow_run_metrics_v3.json \
  artifacts/reward_diag_v3.json artifacts/reward_diag_v3.csv \
  artifacts/pre_run_check.dev_v3.json artifacts/pre_run_check.ci_v3.json \
  artifacts/weight_grid_topk_v3.json

echo "ğŸ‰ RC1 SOP v0.3 å®Œæˆï¼"
echo "ğŸ“‹ éªŒæ”¶æ¸…å•ï¼š"
echo "  âœ… score_canary.jsonl: çœŸè¿æ¥æ­£/è´Ÿä¾‹"
echo "  âœ… router_dump.json: Gemini Onlyé…ç½®"
echo "  âœ… shadow_run_metrics_v3.json: æ–°æƒé‡è¯„æµ‹ç»“æœ"
echo "  âœ… reward_diag_v3.*: è¯Šæ–­é¢æ¿"
echo "  âœ… weight_grid_topk_v3.json: Top-10ä¼˜åŒ–ç»“æœ"
echo "  âœ… rc1_evidence_*_v3.tar.gz: å®Œæ•´è¯æ®åŒ…"
echo ""
echo "ğŸ¯ æ£€æŸ¥Top-10æŒ‡æ ‡ï¼š"
python - <<'PY'
try:
    m=json.load(open('artifacts/shadow_run_metrics_v3.json'))
    top10=m.get("overlap_metrics", {}).get("top10_overlap", 0)
    sp=m.get("correlations", {}).get("full_dataset", {}).get("spearman", 0)
    print(f"Top-10é‡å ç‡: {top10:.4f}")
    print(f"Spearmanç›¸å…³æ€§: {sp:.4f}")
    if top10 >= 0.60:
        print("ğŸ‰ Top-10ç›®æ ‡è¾¾æˆ!")
    else:
        print(f"âš ï¸ Top-10å·®è·: {0.60 - top10:.4f}")
except Exception as e:
    print(f"âš ï¸ æ— æ³•è¯»å–æŒ‡æ ‡: {e}")
PY

