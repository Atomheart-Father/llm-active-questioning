#!/usr/bin/env python3
"""
ç¬¬äºŒé˜¶æ®µç²¾ç»†åŒ–æµ‹è¯•ï¼šè§£å†³è¿‡åº¦æé—®é—®é¢˜
ä¸»è¦æ”¹è¿›ï¼š
1. å¢åŠ "æ— éœ€æé—®"çš„ç¤ºä¾‹
2. è®¾ç½®æé—®æƒ©ç½šæœºåˆ¶  
3. æ›´å¹³è¡¡çš„Few-shotå­¦ä¹ 
4. å¼•å…¥è¿‡åº¦æé—®ç‡è¯„ä¼°
"""

import sys
import torch
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForCausalLM
import json
import re
from typing import Dict, List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.utils.config import get_config
from src.utils.logging import get_logger


class Stage2RefinedTester:
    """ç¬¬äºŒé˜¶æ®µç²¾ç»†åŒ–æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.config = get_config()
        self.logger = get_logger("stage2_refined")
        self.tokenizer = None
        self.model = None
        
        # è®¾ç½®è®¾å¤‡ï¼ˆä¼˜å…ˆä½¿ç”¨MPSï¼‰
        self.device = self._setup_device()
        
        # ç²¾ç»†åŒ–æµ‹è¯•æ•°æ®
        self.test_cases = self._create_balanced_test_cases()
        self.user_responses = self._create_user_response_mapping()
        
        self.logger.info("ç¬¬äºŒé˜¶æ®µç²¾ç»†åŒ–æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_device(self) -> torch.device:
        """è®¾ç½®æœ€ä¼˜è®¾å¤‡"""
        if torch.backends.mps.is_available():
            device = torch.device("mps")
            self.logger.info("ä½¿ç”¨Apple Silicon MPSåŠ é€Ÿ")
        elif torch.cuda.is_available():
            device = torch.device("cuda")
            self.logger.info("ä½¿ç”¨CUDA GPU")
        else:
            device = torch.device("cpu")
            self.logger.info("ä½¿ç”¨CPU")
        
        return device
    
    def _create_balanced_test_cases(self) -> List[Dict]:
        """åˆ›å»ºå¹³è¡¡çš„æµ‹è¯•æ¡ˆä¾‹ï¼ˆæ›´å¤šæ§åˆ¶æ¡ˆä¾‹ï¼‰"""
        # éœ€è¦æé—®çš„æ¡ˆä¾‹ï¼ˆå‡å°‘æ•°é‡ï¼‰
        ambiguous_cases = [
            {
                "id": 1,
                "type": "ä»£è¯æ­§ä¹‰",
                "question": "ä»–ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ",
                "should_ask": True,
                "difficulty": "easy",
                "expected_question_topic": "å…·ä½“æŒ‡ä»£äººç‰©"
            },
            {
                "id": 2,
                "type": "ç¼ºå°‘å…³é”®ä¿¡æ¯",
                "question": "é¢„è®¢ä¸€å¼ ç¥¨",
                "should_ask": True,
                "difficulty": "easy",
                "expected_question_topic": "ç¥¨çš„ç±»å‹å’Œå…·ä½“ä¿¡æ¯"
            },
            {
                "id": 3,
                "type": "ä¸Šä¸‹æ–‡ä¾èµ–",
                "question": "é‚£ä¸ªæ–‡ä»¶åœ¨å“ªé‡Œï¼Ÿ",
                "should_ask": True,
                "difficulty": "medium",
                "expected_question_topic": "å…·ä½“æ–‡ä»¶åç§°"
            }
        ]
        
        # æ— éœ€æé—®çš„æ¡ˆä¾‹ï¼ˆå¢åŠ æ•°é‡å’Œå¤šæ ·æ€§ï¼‰
        complete_cases = [
            {
                "id": 4,
                "type": "äº‹å®æŸ¥è¯¢",
                "question": "ä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ",
                "should_ask": False,
                "difficulty": "easy",
                "expected_answer": "åŒ—äº¬"
            },
            {
                "id": 5,
                "type": "æ•°å­¦è®¡ç®—",
                "question": "25ä¹˜ä»¥4ç­‰äºå¤šå°‘ï¼Ÿ",
                "should_ask": False,
                "difficulty": "easy", 
                "expected_answer": "100"
            },
            {
                "id": 6,
                "type": "å®šä¹‰è§£é‡Š",
                "question": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
                "should_ask": False,
                "difficulty": "medium",
                "expected_answer": "å…³äºAIçš„è§£é‡Š"
            },
            {
                "id": 7,
                "type": "æ—¥æœŸæ—¶é—´",
                "question": "ä»Šå¤©æ˜¯æ˜ŸæœŸå‡ ï¼Ÿ",
                "should_ask": False,
                "difficulty": "easy",
                "expected_answer": "éœ€è¦å½“å‰æ—¥æœŸä¿¡æ¯"
            },
            {
                "id": 8,
                "type": "è¯­è¨€ç¿»è¯‘",
                "question": "è¯·æŠŠ'Hello'ç¿»è¯‘æˆä¸­æ–‡",
                "should_ask": False,
                "difficulty": "easy",
                "expected_answer": "ä½ å¥½"
            },
            {
                "id": 9,
                "type": "å¸¸è¯†é—®ç­”",
                "question": "ä¸€å¹´æœ‰å¤šå°‘ä¸ªæœˆï¼Ÿ",
                "should_ask": False,
                "difficulty": "easy",
                "expected_answer": "12ä¸ªæœˆ"
            },
            {
                "id": 10,
                "type": "å…·ä½“æŒ‡ä»¤",
                "question": "è¯·å¸®æˆ‘å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",
                "should_ask": False,
                "difficulty": "medium",
                "expected_answer": "åˆ›ä½œæ˜¥å¤©ä¸»é¢˜çš„è¯—æ­Œ"
            }
        ]
        
        return ambiguous_cases + complete_cases
    
    def _create_user_response_mapping(self) -> Dict[int, str]:
        """åˆ›å»ºç”¨æˆ·æ¾„æ¸…å›ç­”æ˜ å°„"""
        return {
            1: "æˆ‘æ˜¯æŒ‡çˆ±å› æ–¯å¦ã€‚",
            2: "æˆ‘æƒ³è®¢ä»åŒ—äº¬åˆ°ä¸Šæµ·æ˜å¤©ä¸Šåˆçš„é«˜é“ç¥¨ã€‚",
            3: "æˆ‘è¯´çš„æ˜¯æ˜¨å¤©å‘ç»™ä½ çš„é¡¹ç›®æŠ¥å‘Šæ–‡ä»¶ã€‚"
        }
    
    def load_model(self) -> bool:
        """åŠ è½½æ¨¡å‹"""
        try:
            model_name = self.config.get("model.name", "Qwen/Qwen3-4B-Thinking-2507")
            self.logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")
            
            # åŠ è½½åˆ†è¯å™¨
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                trust_remote_code=True,
                padding_side="left"
            )
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # åŠ è½½æ¨¡å‹
            if self.device.type == "mps":
                self.model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    torch_dtype=torch.float16,
                    trust_remote_code=True
                ).to(self.device)
            else:
                self.model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    device_map="auto" if torch.cuda.is_available() else None,
                    trust_remote_code=True,
                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
                )
            
            self.logger.info(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
            return True
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def create_balanced_few_shot_prompt(self, question: str, mode: str = "with_question") -> str:
        """
        åˆ›å»ºå¹³è¡¡çš„Few-shotæç¤ºè¯ï¼ˆåŒ…å«æ­£åç¤ºä¾‹ï¼‰
        """
        if mode == "with_question":
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½AIåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹åŸåˆ™å¤„ç†ç”¨æˆ·é—®é¢˜ï¼š

1. å¦‚æœé—®é¢˜ä¿¡æ¯å®Œæ•´ä¸”æ˜ç¡®ï¼Œç›´æ¥ç»™å‡ºå‡†ç¡®å›ç­”
2. å¦‚æœé—®é¢˜æ¨¡ç³Šä¸æ¸…æˆ–ç¼ºå°‘å…³é”®ä¿¡æ¯ï¼Œä¸»åŠ¨æé—®æ¾„æ¸…
3. é¿å…ä¸å¿…è¦çš„æé—®ï¼Œåªåœ¨ç¡®å®éœ€è¦æ¾„æ¸…æ—¶æ‰æé—®

ç¤ºä¾‹1ï¼ˆéœ€è¦æ¾„æ¸…ï¼‰ï¼š
ç”¨æˆ·ï¼šä»–ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ
åŠ©æ‰‹ï¼šè¯·é—®æ‚¨æŒ‡çš„æ˜¯å“ªä½äººç‰©å‘¢ï¼Ÿ

ç¤ºä¾‹2ï¼ˆä¿¡æ¯å®Œæ•´ï¼Œç›´æ¥å›ç­”ï¼‰ï¼š
ç”¨æˆ·ï¼šçˆ±å› æ–¯å¦ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ
åŠ©æ‰‹ï¼šçˆ±å› æ–¯å¦äº1879å¹´3æœˆ14æ—¥å‡ºç”Ÿã€‚

ç¤ºä¾‹3ï¼ˆéœ€è¦æ¾„æ¸…ï¼‰ï¼š
ç”¨æˆ·ï¼šé¢„è®¢ä¸€å¼ ç¥¨
åŠ©æ‰‹ï¼šè¯·é—®æ‚¨éœ€è¦é¢„è®¢ä»€ä¹ˆç±»å‹çš„ç¥¨ï¼Ÿæ¯”å¦‚ç«è½¦ç¥¨ã€é£æœºç¥¨ï¼Œä»¥åŠå…·ä½“çš„å‡ºå‘åœ°å’Œç›®çš„åœ°ï¼Ÿ

ç¤ºä¾‹4ï¼ˆä¿¡æ¯å®Œæ•´ï¼Œç›´æ¥å›ç­”ï¼‰ï¼š
ç”¨æˆ·ï¼šä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ
åŠ©æ‰‹ï¼šä¸­å›½çš„é¦–éƒ½æ˜¯åŒ—äº¬ã€‚

è¯·æŒ‰ç…§è¿™ä¸ªæ¨¡å¼å¤„ç†ç”¨æˆ·é—®é¢˜ã€‚"""

        else:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å°½åŠ›ç»™å‡ºå›ç­”ã€‚"""
        
        prompt = f"""<|im_start|>system
{system_prompt}<|im_end|>
<|im_start|>user
{question}<|im_end|>
<|im_start|>assistant
"""
        return prompt
    
    def generate_response(self, prompt: str) -> str:
        """ç”Ÿæˆæ¨¡å‹å›ç­”"""
        if not self.model or not self.tokenizer:
            return "æ¨¡å‹æœªåŠ è½½"
        
        try:
            # åˆ†è¯
            inputs = self.tokenizer(
                prompt,
                return_tensors="pt",
                truncation=True,
                max_length=1200  # ç¨å¾®å¢åŠ ä»¥å®¹çº³æ›´å¤šç¤ºä¾‹
            ).to(self.device)
            
            # ç”Ÿæˆå‚æ•°
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=150,
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.9,
                    pad_token_id=self.tokenizer.pad_token_id,
                    eos_token_id=self.tokenizer.eos_token_id
                )
            
            # è§£ç å›ç­”
            input_length = inputs["input_ids"].shape[1]
            response_tokens = outputs[0][input_length:]
            response = self.tokenizer.decode(response_tokens, skip_special_tokens=True)
            
            return response.strip()
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå›ç­”å¤±è´¥: {e}")
            return f"ç”Ÿæˆå¤±è´¥: {e}"
    
    def detect_question(self, response: str) -> Tuple[bool, str]:
        """æ£€æµ‹å›ç­”ä¸­æ˜¯å¦åŒ…å«æé—®"""
        # æ£€æŸ¥é—®å·
        if 'ï¼Ÿ' in response or '?' in response:
            sentences = re.split(r'[ã€‚ï¼!.]', response)
            for sentence in sentences:
                if 'ï¼Ÿ' in sentence or '?' in sentence:
                    return True, sentence.strip()
        
        # æ£€æŸ¥æé—®å…³é”®è¯
        question_patterns = [
            r'è¯·é—®.*?[ï¼Ÿ?]',
            r'èƒ½å¦.*?[ï¼Ÿ?]',
            r'æ‚¨.*?[ï¼Ÿ?]',
            r'ä»€ä¹ˆ.*?[ï¼Ÿ?]',
            r'å“ª.*?[ï¼Ÿ?]',
            r'å¦‚ä½•.*?[ï¼Ÿ?]',
            r'æ˜¯å¦.*?[ï¼Ÿ?]',
            r'å¯ä»¥.*?[ï¼Ÿ?]'
        ]
        
        for pattern in question_patterns:
            match = re.search(pattern, response)
            if match:
                return True, match.group(0)
        
        return False, ""
    
    def calculate_question_appropriateness(self, test_case: Dict, has_question: bool) -> Tuple[bool, float]:
        """
        è®¡ç®—æé—®çš„åˆé€‚æ€§
        
        Returns:
            (è¡Œä¸ºæ˜¯å¦æ­£ç¡®, æƒ©ç½šåˆ†æ•°)
        """
        should_ask = test_case.get("should_ask", False)
        
        if should_ask and has_question:
            # åº”è¯¥æé—®ä¸”ç¡®å®æé—®äº†
            return True, 0.0
        elif not should_ask and not has_question:
            # ä¸åº”è¯¥æé—®ä¸”ç¡®å®æ²¡æé—®
            return True, 0.0
        elif not should_ask and has_question:
            # ä¸åº”è¯¥æé—®ä½†æé—®äº†ï¼ˆè¿‡åº¦æé—®ï¼‰
            return False, -0.3  # æƒ©ç½šè¿‡åº¦æé—®
        else:
            # åº”è¯¥æé—®ä½†æ²¡æé—®
            return False, -0.5  # é‡åº¦æƒ©ç½šé—æ¼æé—®
    
    def run_single_test(self, test_case: Dict, mode: str) -> Dict:
        """è¿è¡Œå•ä¸ªæµ‹è¯•æ¡ˆä¾‹"""
        case_id = test_case["id"]
        question = test_case["question"]
        should_ask = test_case.get("should_ask", False)
        
        # åˆ›å»ºå¹³è¡¡çš„Few-shotæç¤ºè¯
        prompt = self.create_balanced_few_shot_prompt(question, mode)
        
        # ç”Ÿæˆå›ç­”
        response = self.generate_response(prompt)
        
        # æ£€æµ‹æé—®
        has_question, extracted_question = self.detect_question(response)
        
        # è®¡ç®—åˆé€‚æ€§
        correct_behavior, penalty = self.calculate_question_appropriateness(test_case, has_question)
        
        result = {
            "case_id": case_id,
            "mode": mode,
            "original_question": question,
            "should_ask": should_ask,
            "first_response": response,
            "has_question": has_question,
            "extracted_question": extracted_question,
            "correct_behavior": correct_behavior,
            "penalty_score": penalty,
            "final_answer": "",
            "success": False,
            "conversation_turns": 1
        }
        
        if should_ask and has_question:
            # éœ€è¦æé—®ä¸”ç¡®å®æé—®äº†ï¼Œè¿›è¡Œå¤šè½®å¯¹è¯
            user_clarification = self.user_responses.get(case_id, "è¯·æ‚¨å…·ä½“è¯´æ˜ã€‚")
            
            # ç¬¬äºŒè½®å¯¹è¯
            second_prompt = f"""{prompt.rstrip()}{response}<|im_end|>
<|im_start|>user
{user_clarification}<|im_end|>
<|im_start|>assistant
"""
            
            final_response = self.generate_response(second_prompt)
            result["final_answer"] = final_response
            result["user_clarification"] = user_clarification
            result["conversation_turns"] = 2
            result["success"] = len(final_response) > 10 and "ä¸ç¡®å®š" not in final_response
            
        elif not should_ask:
            # ä¸åº”è¯¥æé—®çš„æ¡ˆä¾‹
            result["final_answer"] = response
            result["success"] = not has_question and len(response) > 5
        
        return result
    
    def run_balanced_experiment(self) -> Dict:
        """è¿è¡Œå¹³è¡¡å®éªŒ"""
        self.logger.info("å¼€å§‹è¿è¡Œç¬¬äºŒé˜¶æ®µå¹³è¡¡å®éªŒ...")
        
        results = {
            "with_question_results": [],
            "direct_answer_results": [],
            "summary": {}
        }
        
        # æµ‹è¯•ç²¾ç»†åŒ–çš„ä¸»åŠ¨æé—®æ¨¡å¼
        self.logger.info("æµ‹è¯•ç²¾ç»†åŒ–çš„ä¸»åŠ¨æé—®æ¨¡å¼...")
        for test_case in self.test_cases:
            result = self.run_single_test(test_case, "with_question")
            results["with_question_results"].append(result)
            
            behavior = "âœ“" if result["correct_behavior"] else "âœ—"
            action = "æé—®" if result["has_question"] else "ç›´ç­”"
            should = "åº”è¯¥æé—®" if result["should_ask"] else "æ— éœ€æé—®"
            
            self.logger.info(f"æ¡ˆä¾‹ {test_case['id']}: {action} ({should}) - {behavior}")
        
        # æµ‹è¯•ç›´æ¥å›ç­”æ¨¡å¼ï¼ˆå¯¹ç…§ç»„ï¼‰
        self.logger.info("æµ‹è¯•ç›´æ¥å›ç­”æ¨¡å¼...")
        for test_case in self.test_cases:
            result = self.run_single_test(test_case, "direct_answer")
            results["direct_answer_results"].append(result)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        results["summary"] = self._calculate_balanced_summary(results)
        
        return results
    
    def _calculate_balanced_summary(self, results: Dict) -> Dict:
        """è®¡ç®—å¹³è¡¡å®éªŒæ€»ç»“"""
        with_q = results["with_question_results"]
        direct = results["direct_answer_results"]
        
        # æŒ‰ç±»å‹åˆ†ç»„
        should_ask_cases = [r for r in with_q if r["should_ask"]]
        should_not_ask_cases = [r for r in with_q if not r["should_ask"]]
        
        # è®¡ç®—è¿‡åº¦æé—®ç‡
        over_questioning_rate = sum(1 for r in should_not_ask_cases if r["has_question"]) / len(should_not_ask_cases) if should_not_ask_cases else 0
        
        # è®¡ç®—å¹³å‡æƒ©ç½šåˆ†æ•°
        avg_penalty = sum(r["penalty_score"] for r in with_q) / len(with_q)
        
        summary = {
            "æ€»æµ‹è¯•æ¡ˆä¾‹æ•°": len(self.test_cases),
            "åº”è¯¥æé—®æ¡ˆä¾‹æ•°": len(should_ask_cases),
            "æ— éœ€æé—®æ¡ˆä¾‹æ•°": len(should_not_ask_cases),
            
            "ç²¾ç»†åŒ–ä¸»åŠ¨æé—®æ¨¡å¼": {
                "æ€»ä½“è¡Œä¸ºæ­£ç¡®ç‡": sum(1 for r in with_q if r["correct_behavior"]) / len(with_q),
                "æ€»ä½“æˆåŠŸç‡": sum(1 for r in with_q if r["success"]) / len(with_q),
                
                # åº”è¯¥æé—®çš„æ¡ˆä¾‹
                "åº”æé—®-å®é™…æé—®ç‡": sum(1 for r in should_ask_cases if r["has_question"]) / len(should_ask_cases) if should_ask_cases else 0,
                "åº”æé—®-æœ€ç»ˆæˆåŠŸç‡": sum(1 for r in should_ask_cases if r["success"]) / len(should_ask_cases) if should_ask_cases else 0,
                
                # ä¸åº”è¯¥æé—®çš„æ¡ˆä¾‹
                "æ— éœ€æé—®-æ­£ç¡®ç›´ç­”ç‡": sum(1 for r in should_not_ask_cases if not r["has_question"]) / len(should_not_ask_cases) if should_not_ask_cases else 0,
                "è¿‡åº¦æé—®ç‡": over_questioning_rate,
                
                "å¹³å‡æƒ©ç½šåˆ†æ•°": avg_penalty,
                "å¹³å‡å¯¹è¯è½®æ¬¡": sum(r["conversation_turns"] for r in with_q) / len(with_q)
            },
            
            "ç›´æ¥å›ç­”æ¨¡å¼": {
                "æˆåŠŸç‡": sum(1 for r in direct if r["success"]) / len(direct),
                "å¹³å‡å¯¹è¯è½®æ¬¡": 1.0
            }
        }
        
        # è®¡ç®—æ”¹è¿›æƒ…å†µ
        summary["è¡Œä¸ºæ­£ç¡®ç‡æ”¹è¿›"] = summary["ç²¾ç»†åŒ–ä¸»åŠ¨æé—®æ¨¡å¼"]["æ€»ä½“è¡Œä¸ºæ­£ç¡®ç‡"] - 0.625  # ä¸ç¬¬ä¸€é˜¶æ®µå¯¹æ¯”
        summary["è¿‡åº¦æé—®ç‡æ”¹è¿›"] = 1.0 - over_questioning_rate  # è¿‡åº¦æé—®ç‡çš„æ”¹è¿›
        
        return summary
    
    def print_balanced_report(self, results: Dict):
        """æ‰“å°å¹³è¡¡å®éªŒæŠ¥å‘Š"""
        summary = results["summary"]
        
        print("\n" + "="*70)
        print("ç¬¬äºŒé˜¶æ®µç²¾ç»†åŒ–å®éªŒç»“æœæŠ¥å‘Š")
        print("="*70)
        
        print(f"ğŸ“Š å®éªŒè§„æ¨¡: {summary['æ€»æµ‹è¯•æ¡ˆä¾‹æ•°']} ä¸ªæ¡ˆä¾‹")
        print(f"   â”œâ”€ åº”è¯¥æé—®: {summary['åº”è¯¥æé—®æ¡ˆä¾‹æ•°']} ä¸ª")
        print(f"   â””â”€ æ— éœ€æé—®: {summary['æ— éœ€æé—®æ¡ˆä¾‹æ•°']} ä¸ª")
        print()
        
        mode_stats = summary["ç²¾ç»†åŒ–ä¸»åŠ¨æé—®æ¨¡å¼"]
        print("ğŸ¯ ç²¾ç»†åŒ–ä¸»åŠ¨æé—®æ¨¡å¼:")
        print(f"   â”œâ”€ æ€»ä½“è¡Œä¸ºæ­£ç¡®ç‡: {mode_stats['æ€»ä½“è¡Œä¸ºæ­£ç¡®ç‡']:.1%}")
        print(f"   â”œâ”€ æ€»ä½“æˆåŠŸç‡: {mode_stats['æ€»ä½“æˆåŠŸç‡']:.1%}")
        print(f"   â”œâ”€ åº”æé—®-å®é™…æé—®ç‡: {mode_stats['åº”æé—®-å®é™…æé—®ç‡']:.1%}")
        print(f"   â”œâ”€ åº”æé—®-æœ€ç»ˆæˆåŠŸç‡: {mode_stats['åº”æé—®-æœ€ç»ˆæˆåŠŸç‡']:.1%}")
        print(f"   â”œâ”€ æ— éœ€æé—®-æ­£ç¡®ç›´ç­”ç‡: {mode_stats['æ— éœ€æé—®-æ­£ç¡®ç›´ç­”ç‡']:.1%}")
        print(f"   â”œâ”€ è¿‡åº¦æé—®ç‡: {mode_stats['è¿‡åº¦æé—®ç‡']:.1%}")
        print(f"   â”œâ”€ å¹³å‡æƒ©ç½šåˆ†æ•°: {mode_stats['å¹³å‡æƒ©ç½šåˆ†æ•°']:.2f}")
        print(f"   â””â”€ å¹³å‡å¯¹è¯è½®æ¬¡: {mode_stats['å¹³å‡å¯¹è¯è½®æ¬¡']:.1f}")
        print()
        
        print("ğŸ“ ç›´æ¥å›ç­”æ¨¡å¼:")
        print(f"   â”œâ”€ æˆåŠŸç‡: {summary['ç›´æ¥å›ç­”æ¨¡å¼']['æˆåŠŸç‡']:.1%}")
        print(f"   â””â”€ å¹³å‡å¯¹è¯è½®æ¬¡: {summary['ç›´æ¥å›ç­”æ¨¡å¼']['å¹³å‡å¯¹è¯è½®æ¬¡']:.1f}")
        print()
        
        print("ğŸ“ˆ æ”¹è¿›æƒ…å†µ:")
        behavior_improvement = summary.get("è¡Œä¸ºæ­£ç¡®ç‡æ”¹è¿›", 0)
        over_question_improvement = summary.get("è¿‡åº¦æé—®ç‡æ”¹è¿›", 0)
        
        if behavior_improvement > 0:
            print(f"   âœ… è¡Œä¸ºæ­£ç¡®ç‡æå‡: +{behavior_improvement:.1%}")
        else:
            print(f"   ğŸ“Š è¡Œä¸ºæ­£ç¡®ç‡å˜åŒ–: {behavior_improvement:.1%}")
            
        print(f"   âœ… è¿‡åº¦æé—®æ§åˆ¶: {over_question_improvement:.1%}")
        
        # æ€»ä½“è¯„ä¼°
        if mode_stats['æ€»ä½“è¡Œä¸ºæ­£ç¡®ç‡'] > 0.8:
            print("\nğŸ‰ ä¼˜ç§€ï¼æ¨¡å‹è¡Œä¸ºæ§åˆ¶è‰¯å¥½")
        elif mode_stats['æ€»ä½“è¡Œä¸ºæ­£ç¡®ç‡'] > 0.7:
            print("\nâœ… è‰¯å¥½ï¼æ¨¡å‹è¡Œä¸ºåŸºæœ¬æ­£ç¡®")
        else:
            print("\nâš ï¸ éœ€è¦ç»§ç»­ä¼˜åŒ–æ¨¡å‹è¡Œä¸º")
            
        if mode_stats['è¿‡åº¦æé—®ç‡'] < 0.2:
            print("ğŸ¯ è¿‡åº¦æé—®é—®é¢˜å·²å¾—åˆ°æœ‰æ•ˆæ§åˆ¶")
        else:
            print("ğŸ“‹ è¿‡åº¦æé—®ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        print("="*70)
    
    def save_results(self, results: Dict, output_file: str = "stage2_refined_results.json"):
        """ä¿å­˜å®éªŒç»“æœ"""
        output_path = Path(output_file)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"ç¬¬äºŒé˜¶æ®µå®éªŒç»“æœå·²ä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ç¬¬äºŒé˜¶æ®µç²¾ç»†åŒ–å®éªŒ")
    print("ç›®æ ‡ï¼šè§£å†³è¿‡åº¦æé—®é—®é¢˜ï¼Œæå‡è¡Œä¸ºåˆ¤æ–­å‡†ç¡®æ€§")
    print("="*70)
    
    # åˆå§‹åŒ–æµ‹è¯•å™¨
    tester = Stage2RefinedTester()
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ”„ æ­£åœ¨åŠ è½½ä¼˜åŒ–æ¨¡å‹...")
    if not tester.load_model():
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # è¿è¡Œå¹³è¡¡å®éªŒ
    print("\nğŸ§ª å¼€å§‹è¿è¡Œå¹³è¡¡å¯¹æ¯”å®éªŒ...")
    print("æ”¹è¿›é¡¹: å¹³è¡¡Few-shot + æé—®æƒ©ç½š + æ›´å¤šæ§åˆ¶æ¡ˆä¾‹")
    
    results = tester.run_balanced_experiment()
    
    # ä¿å­˜å’ŒæŠ¥å‘Šç»“æœ
    tester.save_results(results)
    tester.print_balanced_report(results)
    
    print("\nğŸ¯ ç¬¬äºŒé˜¶æ®µç²¾ç»†åŒ–å®éªŒå®Œæˆï¼")
    print("ğŸ“‹ å‡†å¤‡è¿›å…¥å¤šè½®äº¤äº’å’Œä»»åŠ¡æ‰©å±•é˜¶æ®µ")


if __name__ == "__main__":
    main()
