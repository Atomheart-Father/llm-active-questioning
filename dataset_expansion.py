#!/usr/bin/env python3
"""
æ•°æ®é›†æ‰©å±•æ¨¡å—
åŸºäºHotpotQAã€StrategyQAã€AmbigQAç­‰æ•°æ®é›†åˆ›å»ºå¤šè½®å¯¹è¯è®­ç»ƒæ•°æ®
"""

import sys
import json
import random
from pathlib import Path
from typing import Dict, List, Any, Optional
from datasets import load_dataset

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.utils.config import get_config
from src.utils.logging import get_logger
from gemini_integration import GeminiDataGenerator


class DatasetExpander:
    """æ•°æ®é›†æ‰©å±•å™¨"""
    
    def __init__(self):
        self.config = get_config()
        self.logger = get_logger("dataset_expander")
        self.gemini_generator = GeminiDataGenerator()
        
        # æ•°æ®é›†é…ç½®
        self.dataset_configs = {
            "hotpot_qa": {
                "name": "hotpot_qa",
                "config": "fullwiki",
                "sample_size": 50,
                "description": "å¤šè·³æ¨ç†é—®ç­”æ•°æ®é›†"
            },
            "ambig_qa": {
                "name": "ambig_qa",
                "config": "light",
                "sample_size": 30,
                "description": "æ­§ä¹‰é—®ç­”æ•°æ®é›†"
            },
            "gsm8k": {
                "name": "gsm8k",
                "config": "main",
                "sample_size": 40,
                "description": "æ•°å­¦æ¨ç†é—®é¢˜æ•°æ®é›†"
            }
        }
        
        self.logger.info("æ•°æ®é›†æ‰©å±•å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def load_sample_data(self, dataset_name: str, sample_size: int = None) -> List[Dict[str, Any]]:
        """
        åŠ è½½å¹¶é‡‡æ ·æ•°æ®é›†
        
        Args:
            dataset_name: æ•°æ®é›†åç§°
            sample_size: é‡‡æ ·å¤§å°
            
        Returns:
            é‡‡æ ·çš„æ•°æ®åˆ—è¡¨
        """
        config = self.dataset_configs.get(dataset_name)
        if not config:
            self.logger.error(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")
            return []
        
        sample_size = sample_size or config["sample_size"]
        
        try:
            self.logger.info(f"åŠ è½½æ•°æ®é›†: {config['name']} ({config['description']})")
            
            if dataset_name == "hotpot_qa":
                dataset = load_dataset(config["name"], config["config"], split="train")
                # è¿‡æ»¤å¤æ‚åº¦é€‚ä¸­çš„é—®é¢˜
                filtered_data = [item for item in dataset if len(item.get("question", "")) < 150]
                samples = random.sample(filtered_data, min(sample_size, len(filtered_data)))
                
                processed_samples = []
                for item in samples:
                    processed_samples.append({
                        "question": item["question"],
                        "answer": item["answer"],
                        "type": "multi_hop",
                        "supporting_facts": item.get("supporting_facts", []),
                        "dataset": "hotpot_qa"
                    })
                
            elif dataset_name == "ambig_qa":
                dataset = load_dataset(config["name"], config["config"], split="train")
                samples = random.sample(list(dataset), min(sample_size, len(dataset)))
                
                processed_samples = []
                for item in samples:
                    # AmbigQAå¯èƒ½æœ‰å¤šä¸ªå¯èƒ½çš„ç­”æ¡ˆ
                    annotations = item.get("annotations", [])
                    if annotations:
                        processed_samples.append({
                            "question": item["question"],
                            "answer": annotations[0].get("long_answer", ""),
                            "type": "ambiguous",
                            "multiple_answers": [ann.get("long_answer", "") for ann in annotations],
                            "dataset": "ambig_qa"
                        })
            
            elif dataset_name == "gsm8k":
                dataset = load_dataset(config["name"], config["config"], split="train")
                samples = random.sample(list(dataset), min(sample_size, len(dataset)))
                
                processed_samples = []
                for item in samples:
                    processed_samples.append({
                        "question": item["question"],
                        "answer": item["answer"],
                        "type": "math_reasoning",
                        "dataset": "gsm8k"
                    })
            
            else:
                self.logger.warning(f"æ•°æ®é›† {dataset_name} å¤„ç†é€»è¾‘æœªå®ç°")
                return []
            
            self.logger.info(f"æˆåŠŸåŠ è½½{len(processed_samples)}ä¸ª{config['description']}æ ·æœ¬")
            return processed_samples
            
        except Exception as e:
            self.logger.error(f"åŠ è½½æ•°æ®é›†å¤±è´¥ {dataset_name}: {e}")
            return []
    
    def create_mock_datasets(self) -> Dict[str, List[Dict[str, Any]]]:
        """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†ï¼ˆå½“æ— æ³•åŠ è½½çœŸå®æ•°æ®é›†æ—¶ä½¿ç”¨ï¼‰"""
        self.logger.info("åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†...")
        
        mock_data = {
            "hotpot_qa": [
                {
                    "question": "è°æ˜¯å†™ã€Šå“ˆåˆ©æ³¢ç‰¹ã€‹çš„ä½œè€…çš„ä¸ˆå¤«ï¼Ÿ",
                    "answer": "å°¼å°”Â·é»˜é‡Œï¼ˆNeil Murrayï¼‰",
                    "type": "multi_hop",
                    "reasoning_steps": ["æ‰¾åˆ°ã€Šå“ˆåˆ©æ³¢ç‰¹ã€‹ä½œè€…", "æ‰¾åˆ°ä½œè€…çš„ä¸ˆå¤«"],
                    "dataset": "hotpot_qa_mock"
                },
                {
                    "question": "ä¸–ç•Œæœ€é«˜å³°æ‰€åœ¨å›½å®¶çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "answer": "åŠ å¾·æ»¡éƒ½",
                    "type": "multi_hop", 
                    "reasoning_steps": ["ç¡®å®šä¸–ç•Œæœ€é«˜å³°", "ç¡®å®šæ‰€åœ¨å›½å®¶", "æ‰¾åˆ°é¦–éƒ½"],
                    "dataset": "hotpot_qa_mock"
                },
                {
                    "question": "ç¬¬ä¸€ä¸ªç™»ä¸Šæœˆçƒçš„äººå‡ºç”Ÿåœ¨å“ªä¸ªå·ï¼Ÿ",
                    "answer": "ä¿„äº¥ä¿„å·",
                    "type": "multi_hop",
                    "reasoning_steps": ["ç¡®å®šç¬¬ä¸€ä¸ªç™»æœˆçš„äºº", "æŸ¥æ‰¾å‡ºç”Ÿåœ°"],
                    "dataset": "hotpot_qa_mock"
                }
            ],
            "ambig_qa": [
                {
                    "question": "ä»–ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ",
                    "answer": "éœ€è¦æ˜ç¡®æŒ‡ä»£å¯¹è±¡",
                    "type": "ambiguous",
                    "clarification_needed": "è¯·é—®æ‚¨æŒ‡çš„æ˜¯å“ªä½äººç‰©ï¼Ÿ",
                    "dataset": "ambig_qa_mock"
                },
                {
                    "question": "é‚£å®¶é¤å…å¥½åƒå—ï¼Ÿ",
                    "answer": "éœ€è¦æ˜ç¡®å…·ä½“é¤å…",
                    "type": "ambiguous",
                    "clarification_needed": "è¯·é—®æ‚¨æŒ‡çš„æ˜¯å“ªå®¶é¤å…ï¼Ÿ",
                    "dataset": "ambig_qa_mock"
                },
                {
                    "question": "è¿™ä¸ªä»·æ ¼åˆç†å—ï¼Ÿ",
                    "answer": "éœ€è¦æ˜ç¡®å•†å“å’Œä»·æ ¼ä¿¡æ¯",
                    "type": "ambiguous",
                    "clarification_needed": "è¯·é—®æ‚¨æŒ‡çš„æ˜¯ä»€ä¹ˆå•†å“å’Œä»·æ ¼ï¼Ÿ",
                    "dataset": "ambig_qa_mock"
                }
            ],
            "gsm8k": [
                {
                    "question": "ä¸€ä¸ªç­çº§æœ‰25ä¸ªå­¦ç”Ÿï¼Œå¦‚æœæ¯ä¸ªå­¦ç”Ÿéœ€è¦3æœ¬ä¹¦ï¼Œæ€»å…±éœ€è¦å¤šå°‘æœ¬ä¹¦ï¼Ÿ",
                    "answer": "75æœ¬ä¹¦",
                    "type": "math_reasoning",
                    "calculation": "25 Ã— 3 = 75",
                    "dataset": "gsm8k_mock"
                },
                {
                    "question": "å¼ ä¸‰æœ‰120å…ƒï¼Œä¹°äº†3æ”¯ç¬”ï¼Œæ¯æ”¯ç¬”15å…ƒï¼Œè¿˜å‰©å¤šå°‘é’±ï¼Ÿ",
                    "answer": "75å…ƒ",
                    "type": "math_reasoning", 
                    "calculation": "120 - (3 Ã— 15) = 120 - 45 = 75",
                    "dataset": "gsm8k_mock"
                },
                {
                    "question": "ä¸€è¾†è½¦æ¯å°æ—¶è¡Œé©¶60å…¬é‡Œï¼Œè¡Œé©¶äº†2.5å°æ—¶ï¼Œæ€»å…±è¡Œé©¶äº†å¤šå°‘å…¬é‡Œï¼Ÿ",
                    "answer": "150å…¬é‡Œ",
                    "type": "math_reasoning",
                    "calculation": "60 Ã— 2.5 = 150",
                    "dataset": "gsm8k_mock"
                }
            ]
        }
        
        self.logger.info(f"åˆ›å»ºäº†{sum(len(v) for v in mock_data.values())}ä¸ªæ¨¡æ‹Ÿæ ·æœ¬")
        return mock_data
    
    def convert_to_multi_turn_dialogues(self, samples: List[Dict[str, Any]], 
                                       dataset_type: str) -> List[Dict[str, Any]]:
        """
        å°†æ ·æœ¬è½¬æ¢ä¸ºå¤šè½®å¯¹è¯æ ¼å¼
        
        Args:
            samples: åŸå§‹æ ·æœ¬
            dataset_type: æ•°æ®é›†ç±»å‹
            
        Returns:
            å¤šè½®å¯¹è¯æ•°æ®
        """
        self.logger.info(f"è½¬æ¢{len(samples)}ä¸ª{dataset_type}æ ·æœ¬ä¸ºå¤šè½®å¯¹è¯æ ¼å¼...")
        
        multi_turn_dialogues = []
        
        for i, sample in enumerate(samples):
            try:
                if dataset_type == "ambiguous":
                    # æ­§ä¹‰é—®é¢˜ï¼šéœ€è¦æ¾„æ¸…
                    dialogue = self._create_clarification_dialogue(sample)
                elif dataset_type == "multi_hop":
                    # å¤šè·³æ¨ç†ï¼šåˆ†æ­¥éª¤æé—®
                    dialogue = self._create_step_wise_dialogue(sample)
                elif dataset_type == "math_reasoning":
                    # æ•°å­¦æ¨ç†ï¼šå¯èƒ½éœ€è¦æ¾„æ¸…æ¡ä»¶
                    dialogue = self._create_math_dialogue(sample)
                else:
                    # é»˜è®¤å¤„ç†
                    dialogue = self._create_simple_dialogue(sample)
                
                if dialogue:
                    dialogue["sample_id"] = i
                    dialogue["original_dataset"] = sample.get("dataset", dataset_type)
                    multi_turn_dialogues.append(dialogue)
                    
                self.logger.info(f"è½¬æ¢å®Œæˆ {i+1}/{len(samples)}")
                
            except Exception as e:
                self.logger.error(f"è½¬æ¢æ ·æœ¬å¤±è´¥ {i}: {e}")
                continue
        
        self.logger.info(f"æˆåŠŸè½¬æ¢{len(multi_turn_dialogues)}ä¸ªå¤šè½®å¯¹è¯")
        return multi_turn_dialogues
    
    def _create_clarification_dialogue(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºæ¾„æ¸…å¯¹è¯"""
        question = sample["question"]
        
        # ä½¿ç”¨Geminiç”Ÿæˆæ¾„æ¸…å¯¹è¯
        try:
            dialogue_data = self.gemini_generator.generate_clarifying_dialogue(question)
            if dialogue_data:
                return {
                    "dialogue_type": "clarification",
                    "original_question": question,
                    "is_ambiguous": dialogue_data.get("is_ambiguous", True),
                    "turns": [
                        {"role": "user", "content": question},
                        {"role": "assistant", "content": dialogue_data.get("clarifying_question", "è¯·æ‚¨æä¾›æ›´å¤šä¿¡æ¯ã€‚")},
                        {"role": "user", "content": dialogue_data.get("user_clarification", "ç”¨æˆ·æä¾›æ¾„æ¸…ä¿¡æ¯")},
                        {"role": "assistant", "content": dialogue_data.get("final_answer", sample.get("answer", ""))}
                    ],
                    "expected_outcome": "successful_clarification"
                }
        except Exception as e:
            self.logger.warning(f"Geminiç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")
        
        # å¤‡ç”¨ç®€åŒ–ç‰ˆæœ¬
        return {
            "dialogue_type": "clarification",
            "original_question": question,
            "is_ambiguous": True,
            "turns": [
                {"role": "user", "content": question},
                {"role": "assistant", "content": "è¯·æ‚¨æä¾›æ›´å¤šå…·ä½“ä¿¡æ¯ï¼Œè¿™æ ·æˆ‘èƒ½æ›´å¥½åœ°å¸®åŠ©æ‚¨ã€‚"},
                {"role": "user", "content": "æˆ‘éœ€è¦å…·ä½“ä¿¡æ¯"},
                {"role": "assistant", "content": sample.get("answer", "æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œæˆ‘çš„å›ç­”æ˜¯...")}
            ],
            "expected_outcome": "successful_clarification"
        }
    
    def _create_step_wise_dialogue(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºåˆ†æ­¥æ¨ç†å¯¹è¯"""
        question = sample["question"]
        
        # ä½¿ç”¨Geminiç”Ÿæˆå¤šè·³æ¨ç†å¯¹è¯
        try:
            dialogue_data = self.gemini_generator.generate_multi_hop_dialogue(question)
            if dialogue_data:
                turns = [{"role": "user", "content": question}]
                
                steps = dialogue_data.get("reasoning_steps", [])
                for step in steps:
                    turns.append({"role": "assistant", "content": step.get("ai_question", "è®©æˆ‘åˆ†æä¸€ä¸‹...")})
                    turns.append({"role": "user", "content": step.get("user_answer", "ç”¨æˆ·æä¾›ä¿¡æ¯")})
                
                turns.append({"role": "assistant", "content": dialogue_data.get("final_answer", sample.get("answer", ""))})
                
                return {
                    "dialogue_type": "multi_step_reasoning",
                    "original_question": question,
                    "reasoning_complexity": "multi_hop",
                    "turns": turns,
                    "expected_outcome": "successful_reasoning"
                }
        except Exception as e:
            self.logger.warning(f"Geminiç”Ÿæˆå¤šè·³å¯¹è¯å¤±è´¥: {e}")
        
        # å¤‡ç”¨ç‰ˆæœ¬
        return {
            "dialogue_type": "multi_step_reasoning", 
            "original_question": question,
            "reasoning_complexity": "multi_hop",
            "turns": [
                {"role": "user", "content": question},
                {"role": "assistant", "content": "è¿™ä¸ªé—®é¢˜éœ€è¦åˆ†æ­¥åˆ†æï¼Œè®©æˆ‘å…ˆç¡®è®¤ç¬¬ä¸€æ­¥ä¿¡æ¯ã€‚"},
                {"role": "user", "content": "è¯·ç»§ç»­åˆ†æ"},
                {"role": "assistant", "content": sample.get("answer", "åŸºäºåˆ†æï¼Œç­”æ¡ˆæ˜¯...")}
            ],
            "expected_outcome": "successful_reasoning"
        }
    
    def _create_math_dialogue(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºæ•°å­¦æ¨ç†å¯¹è¯"""
        question = sample["question"]
        answer = sample.get("answer", "")
        
        return {
            "dialogue_type": "math_reasoning",
            "original_question": question,
            "complexity": "calculation",
            "turns": [
                {"role": "user", "content": question},
                {"role": "assistant", "content": f"è®©æˆ‘æ¥è®¡ç®—è¿™ä¸ªé—®é¢˜ã€‚{answer}"}
            ],
            "expected_outcome": "correct_calculation"
        }
    
    def _create_simple_dialogue(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºç®€å•å¯¹è¯"""
        return {
            "dialogue_type": "simple_qa",
            "original_question": sample["question"],
            "turns": [
                {"role": "user", "content": sample["question"]},
                {"role": "assistant", "content": sample.get("answer", "æˆ‘æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚")}
            ],
            "expected_outcome": "direct_answer"
        }
    
    def build_comprehensive_training_dataset(self, use_real_data: bool = True) -> Dict[str, Any]:
        """
        æ„å»ºç»¼åˆè®­ç»ƒæ•°æ®é›†
        
        Args:
            use_real_data: æ˜¯å¦ä½¿ç”¨çœŸå®æ•°æ®é›†
            
        Returns:
            ç»¼åˆè®­ç»ƒæ•°æ®é›†
        """
        self.logger.info("å¼€å§‹æ„å»ºç»¼åˆè®­ç»ƒæ•°æ®é›†...")
        
        all_dialogues = []
        dataset_stats = {}
        
        if use_real_data:
            # å°è¯•åŠ è½½çœŸå®æ•°æ®é›†
            for dataset_name in self.dataset_configs.keys():
                try:
                    samples = self.load_sample_data(dataset_name)
                    if samples:
                        dataset_type = samples[0].get("type", "unknown")
                        dialogues = self.convert_to_multi_turn_dialogues(samples, dataset_type)
                        all_dialogues.extend(dialogues)
                        dataset_stats[dataset_name] = len(dialogues)
                except Exception as e:
                    self.logger.warning(f"åŠ è½½çœŸå®æ•°æ®é›†{dataset_name}å¤±è´¥: {e}")
        
        # å¦‚æœçœŸå®æ•°æ®é›†åŠ è½½å¤±è´¥æˆ–ä¸ä½¿ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        if not all_dialogues:
            self.logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®é›†...")
            mock_datasets = self.create_mock_datasets()
            
            for dataset_name, samples in mock_datasets.items():
                dataset_type = samples[0].get("type", "unknown")
                dialogues = self.convert_to_multi_turn_dialogues(samples, dataset_type)
                all_dialogues.extend(dialogues)
                dataset_stats[dataset_name] = len(dialogues)
        
        # éšæœºæ‰“ä¹±æ•°æ®
        random.shuffle(all_dialogues)
        
        training_dataset = {
            "version": "1.0",
            "total_dialogues": len(all_dialogues),
            "dataset_distribution": dataset_stats,
            "dialogue_types": {
                "clarification": len([d for d in all_dialogues if d["dialogue_type"] == "clarification"]),
                "multi_step_reasoning": len([d for d in all_dialogues if d["dialogue_type"] == "multi_step_reasoning"]),
                "math_reasoning": len([d for d in all_dialogues if d["dialogue_type"] == "math_reasoning"]),
                "simple_qa": len([d for d in all_dialogues if d["dialogue_type"] == "simple_qa"])
            },
            "dialogues": all_dialogues
        }
        
        self.logger.info(f"æ„å»ºå®Œæˆï¼æ€»è®¡{len(all_dialogues)}ä¸ªå¤šè½®å¯¹è¯")
        self.logger.info(f"æ•°æ®åˆ†å¸ƒ: {dataset_stats}")
        
        return training_dataset
    
    def save_training_dataset(self, dataset: Dict[str, Any], output_file: str = "multi_turn_training_data.json"):
        """ä¿å­˜è®­ç»ƒæ•°æ®é›†"""
        output_path = Path(output_file)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"è®­ç»ƒæ•°æ®é›†å·²ä¿å­˜åˆ°: {output_path}")
        
        # ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š
        self._generate_dataset_report(dataset, output_path.with_suffix('.report.txt'))
    
    def _generate_dataset_report(self, dataset: Dict[str, Any], report_file: Path):
        """ç”Ÿæˆæ•°æ®é›†æŠ¥å‘Š"""
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("å¤šè½®å¯¹è¯è®­ç»ƒæ•°æ®é›†æŠ¥å‘Š\n")
            f.write("=" * 40 + "\n\n")
            
            f.write(f"æ•°æ®é›†ç‰ˆæœ¬: {dataset['version']}\n")
            f.write(f"æ€»å¯¹è¯æ•°: {dataset['total_dialogues']}\n\n")
            
            f.write("æ•°æ®æ¥æºåˆ†å¸ƒ:\n")
            for source, count in dataset['dataset_distribution'].items():
                f.write(f"  {source}: {count} ä¸ªå¯¹è¯\n")
            
            f.write("\nå¯¹è¯ç±»å‹åˆ†å¸ƒ:\n")
            for dialogue_type, count in dataset['dialogue_types'].items():
                f.write(f"  {dialogue_type}: {count} ä¸ªå¯¹è¯\n")
            
            f.write("\nç¤ºä¾‹å¯¹è¯:\n")
            if dataset['dialogues']:
                example = dataset['dialogues'][0]
                f.write(f"ç±»å‹: {example['dialogue_type']}\n")
                f.write(f"åŸå§‹é—®é¢˜: {example['original_question']}\n")
                f.write("å¯¹è¯è½®æ¬¡:\n")
                for i, turn in enumerate(example['turns']):
                    f.write(f"  {i+1}. {turn['role']}: {turn['content'][:100]}...\n")
        
        self.logger.info(f"æ•°æ®é›†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


def main():
    """ä¸»å‡½æ•°ï¼šæ„å»ºå¤šè½®å¯¹è¯è®­ç»ƒæ•°æ®é›†"""
    print("å¤šè½®å¯¹è¯è®­ç»ƒæ•°æ®é›†æ„å»ºå™¨")
    print("=" * 50)
    
    # åˆå§‹åŒ–æ•°æ®é›†æ‰©å±•å™¨
    expander = DatasetExpander()
    
    # æ„å»ºç»¼åˆè®­ç»ƒæ•°æ®é›†
    print("ğŸ”„ å¼€å§‹æ„å»ºç»¼åˆè®­ç»ƒæ•°æ®é›†...")
    training_dataset = expander.build_comprehensive_training_dataset(use_real_data=False)  # å…ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
    
    # ä¿å­˜æ•°æ®é›†
    expander.save_training_dataset(training_dataset)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ•°æ®é›†æ„å»ºå®Œæˆ!")
    print(f"   æ€»å¯¹è¯æ•°: {training_dataset['total_dialogues']}")
    print(f"   æ•°æ®æ¥æº: {list(training_dataset['dataset_distribution'].keys())}")
    print(f"   å¯¹è¯ç±»å‹: {list(training_dataset['dialogue_types'].keys())}")
    
    # æ˜¾ç¤ºç¤ºä¾‹
    if training_dataset['dialogues']:
        example = training_dataset['dialogues'][0]
        print(f"\nğŸ’¬ ç¤ºä¾‹å¯¹è¯ ({example['dialogue_type']}):")
        print(f"   é—®é¢˜: {example['original_question']}")
        print(f"   è½®æ¬¡: {len(example['turns'])} è½®")
    
    print(f"\nğŸ¯ å¤šè½®å¯¹è¯è®­ç»ƒæ•°æ®é›†æ„å»ºå®Œæˆï¼")
    print(f"ğŸ“‹ å¯ç”¨äºå¼ºåŒ–å­¦ä¹ è®­ç»ƒå’Œæ¨¡å‹å¾®è°ƒ")


if __name__ == "__main__":
    main()
