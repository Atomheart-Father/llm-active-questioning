#!/bin/bash
set -euxo pipefail
export PYTHONHASHSEED=0
export RUN_SEED=20250901
mkdir -p artifacts

echo "ğŸš€ RC1 SOP v0.2 - è¡¥é½çœŸè¿æ¥è¯æ® + Top-10ä¼˜åŒ–"

# 0) ç¯å¢ƒæŒ‡çº¹
echo "ğŸ“‹ æ­¥éª¤0: ç¯å¢ƒæŒ‡çº¹"
git checkout main && git pull
git rev-parse HEAD | tee artifacts/HEAD.sha
pip freeze > artifacts/requirements.lock.txt

# 1) è¯„åˆ†é€šé“çœŸè¿æ¥è¯æ˜
echo "ğŸ”¬ æ­¥éª¤1: è¯„åˆ†é€šé“çœŸè¿æ¥è¯æ˜"
export SCORER_PROVIDER=gemini

# æ£€æŸ¥API keyï¼ˆå¦‚æœæ²¡æœ‰ï¼Œè¯·æ‰‹åŠ¨è®¾ç½®ï¼‰
if [ -z "$GEMINI_API_KEY" ]; then
    echo "âš ï¸  GEMINI_API_KEY æœªè®¾ç½®ï¼Œè¯·è®¾ç½®åé‡æ–°è¿è¡Œï¼š"
    echo "   export GEMINI_API_KEY=your_api_key_here"
    echo "   ./run_rc1_sop_v02.sh"
    exit 1
fi

PYTHONPATH=/Users/bozhongxiao/Desktop/å…‹ç½—ç±³ç‹å›½å›½ç«‹ç”µå°/ä»£ç é¡¹ç›®/project:$PYTHONPATH python scripts/prove_gemini_real.py

# éªŒè¯canaryç»“æœ
python - <<'PY'
import json,sys
ok=neg=0
for ln in open('artifacts/score_canary.jsonl','r',encoding='utf-8'):
    r=json.loads(ln); ok+=int(r.get('ok') is True); neg+=int(r.get('ok') is False)
print("canary_ok=",ok,"canary_neg=",neg)
assert ok>=1 and neg>=1, "ç¼ºå°‘æ­£/è´Ÿä¾‹ï¼šæ£€æŸ¥ GEMINI_API_KEY / æ–­ç½‘å¯¹ç…§"
print("âœ… CanaryéªŒè¯é€šè¿‡")
PY

# RouteréªŒè¯
python - <<'PY'
import json
j=json.load(open('artifacts/router_dump.json'))
assert j.get('gemini_api_key_set')==True, "gemini_api_key æœªè®¾ç½®"
prov=j.get('scorer_provider')
allowed=j.get('routing_rules',{}).get('allowed_providers',[])
assert prov=="gemini" and allowed==["gemini"], f"Router é Gemini Only: {prov}, {allowed}"
print("âœ… RouteréªŒè¯é€šè¿‡: Gemini Only")
PY

# 2) æ£€æŸ¥æ˜¯å¦å­˜åœ¨enrichedæ–‡ä»¶
echo "ğŸ“Š æ­¥éª¤2: æ£€æŸ¥è¯„æµ‹æ•°æ®"
if [ ! -f artifacts/shadow_manifest.enriched.jsonl ]; then
  echo "ç”Ÿæˆæ–°çš„è¯„æµ‹æ•°æ®..."
  cp data/shadow_eval_245.jsonl artifacts/shadow_manifest.jsonl
  PYTHONPATH=/Users/bozhongxiao/Desktop/å…‹ç½—ç±³ç‹å›½å›½ç«‹ç”µå°/ä»£ç é¡¹ç›®/project:$PYTHONPATH python -m src.evaluation.shadow_run \
    --manifest artifacts/shadow_manifest.jsonl \
    --output artifacts/shadow_run_metrics.json \
    --materialize artifacts/shadow_manifest.enriched.jsonl
else
  echo "âœ… å¤ç”¨ç°æœ‰è¯„æµ‹æ•°æ®"
fi

# 3) è¯Šæ–­é¢æ¿
echo "ğŸ” æ­¥éª¤3: è¯Šæ–­é¢æ¿åˆ†æ"
PYTHONPATH=/Users/bozhongxiao/Desktop/å…‹ç½—ç±³ç‹å›½å›½ç«‹ç”µå°/ä»£ç é¡¹ç›®/project:$PYTHONPATH python scripts/analyze_reward_dimensions.py \
  --manifest artifacts/shadow_manifest.enriched.jsonl \
  --out-json artifacts/reward_diag.json \
  --out-csv artifacts/reward_diag.csv

# 4) é¢„æ£€å¯¹é½
echo "ğŸŸ¡ æ­¥éª¤4: é¢„æ£€å¯¹é½ï¼ˆå¼€å‘æ¨¡å¼ï¼‰"
PYTHONPATH=/Users/bozhongxiao/Desktop/å…‹ç½—ç±³ç‹å›½å›½ç«‹ç”µå°/ä»£ç é¡¹ç›®/project:$PYTHONPATH python scripts/pre_run_check.py \
  --data-root shadow_data \
  --out artifacts/pre_run_check.dev.json || true

echo "ğŸ”´ æ­¥éª¤4: é¢„æ£€å¯¹é½ï¼ˆCIæ¨¡å¼ï¼‰"
PYTHONPATH=/Users/bozhongxiao/Desktop/å…‹ç½—ç±³ç‹å›½å›½ç«‹ç”µå°/ä»£ç é¡¹ç›®/project:$PYTHONPATH python scripts/pre_run_check.py \
  --data-root shadow_data \
  --strict-metrics \
  --out artifacts/pre_run_check.ci.json || true

# 5) Top-10å®šå‘ä¼˜åŒ–
echo "ğŸ¯ æ­¥éª¤5: Top-10å®šå‘ä¼˜åŒ–"
python - <<'PY'
import json,random,math,statistics,sys
import itertools as it
import numpy as np

def read_enriched(path):
    import json
    rows = []
    for ln in open(path,'r',encoding='utf-8'):
        if ln.strip():
            rows.append(json.loads(ln))
    return rows

def collect(rows):
    dims=["logic_rigor","question_quality","reasoning_completeness","natural_interaction"]
    X=[]; G=[]
    for r in rows:
        # å°è¯•ä¸åŒçš„å¯èƒ½å­—æ®µå
        scores = r.get("evaluation", {}).get("component_scores") or r.get("scores") or r.get("subscores") or {}
        gold_rank = r.get("gold_rank") or r.get("rank") or r.get("evaluation", {}).get("gold_rank")

        if all(k in scores for k in dims) and gold_rank is not None:
            X.append([float(scores[k]) for k in dims])
            G.append(int(gold_rank))
    return np.array(X), np.array(G), dims

def topk_overlap(scores, gold_rank, k=10):
    return float(np.mean((gold_rank<=k).astype(np.float32)))

def spearman(scores, gold_rank):
    from scipy.stats import spearmanr
    return float(spearmanr(-scores, gold_rank).correlation)

rows=read_enriched("artifacts/shadow_manifest.enriched.jsonl")
X,G,dims=collect(rows)

if len(X) == 0:
    print("âš ï¸  æ— æ³•æ”¶é›†ç»´åº¦æ•°æ®ï¼Œè·³è¿‡æƒé‡ä¼˜åŒ–")
    sys.exit(0)

print(f"ä¼˜åŒ–æ•°æ®: {len(X)} æ ·æœ¬, {len(dims)} ç»´åº¦")

best=None
rng=np.random.RandomState(20250901)

def dirichlet(alpha, n=1):
    x=rng.gamma(alpha,1,size=(n,4))
    x=x/x.sum(axis=1,keepdims=True)
    return x

trials=40
for w in dirichlet(1.5, trials):
    s=(X@w)
    t10=topk_overlap(s,G,k=10)
    sp=spearman(s,G)
    score= t10 + 0.2*sp
    if (best is None) or (score>best[0]):
        best=(score, w.tolist(), float(t10), float(sp))

print(".4f")

res={"weights": dict(zip(dims, best[1])), "top10": best[2], "spearman": best[3]}
json.dump(res, open("artifacts/weight_grid_topk.json","w"), indent=2, ensure_ascii=False)
print("âœ… æƒé‡ä¼˜åŒ–å®Œæˆ")
PY

# åº”ç”¨æ–°æƒé‡
echo "âš–ï¸ æ­¥éª¤6: åº”ç”¨æ–°æƒé‡"
python - <<'PY'
import json
g=json.load(open("artifacts/weight_grid_topk.json"))
w=g["weights"]
s=sum(w.values())
w={k:v/s for k,v in w.items()}
print("æ–°æƒé‡:", w)

# æ›´æ–°weights.json
try:
    j=json.load(open("configs/weights.json"))
except:
    j={"weights": {}}

j["weights"] = w
# ç¡®ä¿äº”é”®é½å…¨
for k in ["logic_rigor","question_quality","reasoning_completeness","natural_interaction","rules"]:
    if k not in j["weights"]:
        j["weights"][k] = 0.0

json.dump(j, open("configs/weights.json","w"), indent=2, ensure_ascii=False)
print("âœ… æƒé‡å·²æ›´æ–°")
PY

# ç”¨æ–°æƒé‡å¤è·‘ShadowRun
echo "ğŸ¯ æ­¥éª¤7: ç”¨æ–°æƒé‡é‡æ–°è¯„æµ‹"
PYTHONPATH=/Users/bozhongxiao/Desktop/å…‹ç½—ç±³ç‹å›½å›½ç«‹ç”µå°/ä»£ç é¡¹ç›®/project:$PYTHONPATH python -m src.evaluation.shadow_run \
  --manifest artifacts/shadow_manifest.jsonl \
  --output artifacts/shadow_run_metrics.json \
  --materialize artifacts/shadow_manifest.enriched.jsonl

# éªŒè¯æ”¹è¿›æ•ˆæœ
echo "ğŸ“Š æ­¥éª¤8: éªŒè¯æ”¹è¿›æ•ˆæœ"
python - <<'PY'
import json
m=json.load(open('artifacts/shadow_run_metrics.json'))
sp=m.get("correlations", {}).get("full_dataset", {}).get("spearman", 0)
top10=m.get("overlap_metrics", {}).get("top10_overlap", 0)
print(".4f")
PY

# 8) æ‰“åŒ…å®Œæ•´è¯æ®
echo "ğŸ“¦ æ­¥éª¤9: æ‰“åŒ…å®Œæ•´è¯æ®"
tar -czf artifacts/rc1_evidence_$(date +%Y%m%d_%H%M)_v2.tar.gz \
  artifacts/HEAD.sha \
  artifacts/requirements.lock.txt \
  artifacts/router_dump.json \
  artifacts/score_canary.jsonl \
  artifacts/shadow_manifest.jsonl \
  artifacts/shadow_manifest.enriched.jsonl \
  artifacts/shadow_run_metrics.json \
  artifacts/reward_diag.json artifacts/reward_diag.csv \
  artifacts/pre_run_check.dev.json artifacts/pre_run_check.ci.json \
  artifacts/weight_grid_topk.json

echo "ğŸ‰ RC1 SOP v0.2 å®Œæˆï¼"
echo "ğŸ“‹ éªŒæ”¶æ¸…å•ï¼š"
echo "  âœ… score_canary.jsonl: çœŸè¿æ¥æ­£/è´Ÿä¾‹"
echo "  âœ… router_dump.json: Gemini Onlyé…ç½®"
echo "  âœ… reward_diag.*: è¯Šæ–­é¢æ¿"
echo "  âœ… pre_run_check.*: å¯¹é½æœ€æ–°æŒ‡æ ‡"
echo "  âœ… weight_grid_topk.json: Top-10ä¼˜åŒ–ç»“æœ"
echo "  âœ… rc1_evidence_..._v2.tar.gz: å®Œæ•´è¯æ®åŒ…"
