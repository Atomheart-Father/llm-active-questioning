#!/usr/bin/env python3
"""
ç¬¬ä¸‰é˜¶æ®µç¬¬ä¸€é˜¶æ®µæ•°æ®ç”Ÿæˆå™¨
å¤šç»´åº¦è´¨é‡éªŒè¯çš„é«˜è´¨é‡å¤šè½®æ¨ç†å¯¹è¯ç”Ÿæˆ
"""

import sys
import json
import time
import asyncio
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.utils.config import get_config
from src.utils.logging import get_logger
from src.data_preparation.advanced_prompt_templates import AdvancedPromptTemplates, ReasoningType
from src.evaluation.quality_scorer import QualityScorer, QuestionType
from gemini_integration import GeminiDataGenerator


class Phase1DataGenerator:
    """ç¬¬ä¸€é˜¶æ®µæ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.config = get_config()
        self.logger = get_logger("phase1_generator")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.prompt_generator = AdvancedPromptTemplates()
        self.gemini_generator = GeminiDataGenerator()
        self.quality_scorer = QualityScorer()
        
        # ç”Ÿæˆç»Ÿè®¡
        self.generation_stats = {
            "total_attempted": 0,
            "total_successful": 0,
            "by_type": {
                "math_reasoning": {"attempted": 0, "successful": 0, "failed": 0},
                "multi_hop": {"attempted": 0, "successful": 0, "failed": 0},
                "ambiguity_clarification": {"attempted": 0, "successful": 0, "failed": 0}
            },
            "quality_distribution": {"A": 0, "B": 0, "C": 0},
            "start_time": None,
            "end_time": None
        }
        
        self.logger.info("ç¬¬ä¸€é˜¶æ®µæ•°æ®ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def create_phase1_questions(self) -> List[Dict[str, Any]]:
        """åˆ›å»ºç¬¬ä¸€é˜¶æ®µéªŒè¯é—®é¢˜é›†ï¼ˆæ¯ç±»å‹15ä¸ªï¼Œå…±45ä¸ªï¼‰"""
        
        # æ•°å­¦æ¨ç†é—®é¢˜
        math_questions = [
            {"question": "ä¸€ä¸ªæ­£æ–¹å½¢çš„å‘¨é•¿æ˜¯20å˜ç±³ï¼Œæ±‚é¢ç§¯", "type": ReasoningType.MATH_REASONING, "context": "å‡ ä½•è®¡ç®—"},
            {"question": "å°æ˜ä¹°äº†3æ”¯ç¬”å’Œ2æœ¬ä¹¦ï¼Œæ€»å…±èŠ±äº†25å…ƒï¼Œæ¯æ”¯ç¬”3å…ƒï¼Œæ¯æœ¬ä¹¦å¤šå°‘å…ƒï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "åº”ç”¨é¢˜"},
            {"question": "ä¸€è¾†è½¦ä»¥60å…¬é‡Œ/å°æ—¶çš„é€Ÿåº¦è¡Œé©¶ï¼Œéœ€è¦å¤šé•¿æ—¶é—´åˆ°è¾¾ç›®çš„åœ°ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "é€Ÿåº¦æ—¶é—´é—®é¢˜"},
            {"question": "è®¡ç®—å¤åˆ©ï¼šæœ¬é‡‘1000å…ƒï¼Œå¹´åˆ©ç‡5%ï¼Œ3å¹´åæœ¬æ¯åˆè®¡å¤šå°‘ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "é‡‘èè®¡ç®—"},
            {"question": "ä¸€ä¸ªåœ†çš„åŠå¾„æ˜¯å¤šå°‘æ—¶é¢ç§¯ç­‰äº50å¹³æ–¹å˜ç±³ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "åå‘è®¡ç®—"},
            {"question": "å¼ ä¸‰çš„å¹´é¾„æ˜¯æå››çš„2å€ï¼Œä¸¤äººå¹´é¾„ä¹‹å’Œæ˜¯45å²ï¼Œå„è‡ªå¤šå°‘å²ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "å¹´é¾„é—®é¢˜"},
            {"question": "ä¸€æ‰¹è´§ç‰©ï¼Œç¬¬ä¸€å¤©è¿èµ°å…¨éƒ¨çš„1/3ï¼Œç¬¬äºŒå¤©è¿èµ°ä½™ä¸‹çš„1/2ï¼Œè¿˜å‰©60å¨ï¼ŒåŸæ¥æœ‰å¤šå°‘å¨ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "åˆ†æ•°åº”ç”¨"},
            {"question": "æŸå•†å“æ‰“8æŠ˜åä»·æ ¼æ˜¯160å…ƒï¼ŒåŸä»·æ˜¯å¤šå°‘ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "æŠ˜æ‰£è®¡ç®—"},
            {"question": "ä¸€ä¸ªæ°´æ± ï¼Œè¿›æ°´ç®¡æ¯å°æ—¶è¿›æ°´20ç«‹æ–¹ç±³ï¼Œæ’æ°´ç®¡æ¯å°æ—¶æ’æ°´12ç«‹æ–¹ç±³ï¼Œå¤šé•¿æ—¶é—´èƒ½æ³¨æ»¡100ç«‹æ–¹ç±³çš„æ°´æ± ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "å·¥ç¨‹é—®é¢˜"},
            {"question": "ç”²ä¹™ä¸¤åœ°ç›¸è·240å…¬é‡Œï¼Œä¸¤è½¦åŒæ—¶ä»ä¸¤åœ°ç›¸å¯¹å¼€å‡ºï¼Œç”²è½¦é€Ÿåº¦80å…¬é‡Œ/å°æ—¶ï¼Œä¹™è½¦é€Ÿåº¦å¤šå°‘æ—¶èƒ½åœ¨1.5å°æ—¶åç›¸é‡ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "ç›¸é‡é—®é¢˜"},
            {"question": "ä¸€ä¸ªç­‰è…°ä¸‰è§’å½¢çš„åº•è¾¹é•¿8å˜ç±³ï¼Œè…°é•¿å¤šå°‘æ—¶å‘¨é•¿ä¸º20å˜ç±³ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "å‡ ä½•é—®é¢˜"},
            {"question": "æŠ•èµ„è‚¡ç¥¨ï¼Œç¬¬ä¸€å¹´äºæŸ20%ï¼Œç¬¬äºŒå¹´ç›ˆåˆ©å¤šå°‘æ‰èƒ½å›åˆ°æœ¬é‡‘ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "æŠ•èµ„è®¡ç®—"},
            {"question": "ä¸€ä¸ªæ•°åŠ ä¸Šå®ƒçš„20%ç­‰äº36ï¼Œè¿™ä¸ªæ•°æ˜¯å¤šå°‘ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "ç™¾åˆ†æ•°é—®é¢˜"},
            {"question": "åˆ¶ä½œä¸€ä¸ªé•¿æ–¹ä½“ç›’å­ï¼Œé•¿å®½é«˜ä¹‹æ¯”æ˜¯3:2:1ï¼Œä½“ç§¯æ˜¯48ç«‹æ–¹å˜ç±³ï¼Œå„è¾¹é•¿æ˜¯å¤šå°‘ï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "ç«‹ä½“å‡ ä½•"},
            {"question": "æŸå·¥å‚åŸè®¡åˆ’20å¤©å®Œæˆä¸€æ‰¹äº§å“ï¼Œå®é™…æ¯å¤©å¤šç”Ÿäº§25%ï¼Œå®é™…éœ€è¦å¤šå°‘å¤©å®Œæˆï¼Ÿ", "type": ReasoningType.MATH_REASONING, "context": "å·¥ä½œæ•ˆç‡"}
        ]
        
        # å¤šè·³æ¨ç†é—®é¢˜
        multi_hop_questions = [
            {"question": "ä¸–ç•Œä¸Šæœ€å¤§çš„æ²™æ¼ ä½äºå“ªä¸ªå¤§æ´²çš„å“ªä¸ªå›½å®¶ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "åœ°ç†çŸ¥è¯†"},
            {"question": "å‘æ˜ç”µè¯çš„äººæ˜¯å“ªä¸ªå›½å®¶çš„ï¼Œä»–è¿˜å‘æ˜äº†ä»€ä¹ˆé‡è¦è®¾å¤‡ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "ç§‘æŠ€å†å²"},
            {"question": "è·å¾—è¯ºè´å°”æ–‡å­¦å¥–æœ€å¤šçš„å›½å®¶çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "æ–‡å­¦åœ°ç†"},
            {"question": "å¤ªé˜³ç³»ä¸­è·ç¦»åœ°çƒæœ€è¿‘çš„è¡Œæ˜Ÿçš„è¡¨é¢æ¸©åº¦å¤§çº¦æ˜¯å¤šå°‘ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "å¤©æ–‡ç§‘å­¦"},
            {"question": "ä¸­å›½å¤ä»£å››å¤§å‘æ˜ä¸­æœ€æ™šå‘æ˜çš„é‚£ä¸ªå¯¹å“ªä¸ªæœä»£çš„å‘å±•å½±å“æœ€å¤§ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "å†å²ç§‘æŠ€"},
            {"question": "å†™å‡ºã€Šç™¾å¹´å­¤ç‹¬ã€‹çš„ä½œè€…æ¥è‡ªå“ªä¸ªå¤§æ´²çš„å“ªä¸ªå›½å®¶ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "æ–‡å­¦åœ°ç†"},
            {"question": "ä¸¾åŠè¿‡å¤å­£å¥¥è¿ä¼šæ¬¡æ•°æœ€å¤šçš„åŸå¸‚ä½äºå“ªä¸ªå›½å®¶çš„å“ªä¸ªå·ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "ä½“è‚²åœ°ç†"},
            {"question": "ä¸–ç•Œä¸Šç¬¬ä¸€å°è®¡ç®—æœºæ˜¯åœ¨å“ªä¸ªå¤§å­¦è¯ç”Ÿçš„ï¼Œè¿™æ‰€å¤§å­¦ä½äºå“ªä¸ªå·ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "ç§‘æŠ€æ•™è‚²"},
            {"question": "èå£«æ¯”äºšå‡ºç”Ÿçš„åŸå¸‚ç°åœ¨å±äºè‹±å›½çš„å“ªä¸ªéƒ¡ï¼Œè¿™ä¸ªéƒ¡çš„é¢ç§¯å¤§çº¦æ˜¯å¤šå°‘ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "æ–‡å­¦åœ°ç†"},
            {"question": "æå‡ºè¿›åŒ–è®ºçš„ç§‘å­¦å®¶ä¹˜åçš„é‚£è‰˜è‘—åèˆ¹åªçš„åå­—æ˜¯ä»€ä¹ˆï¼Œè¿™æ¬¡èˆªè¡ŒæŒç»­äº†å¤šé•¿æ—¶é—´ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "ç§‘å­¦å†å²"},
            {"question": "ä¸–ç•Œä¸Šæœ€é«˜çš„ç€‘å¸ƒä½äºå“ªä¸ªå›½å®¶ï¼Œè¿™ä¸ªå›½å®¶çš„å®˜æ–¹è¯­è¨€æ˜¯ä»€ä¹ˆï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "åœ°ç†è¯­è¨€"},
            {"question": "å‘ç°DNAåŒèºæ—‹ç»“æ„çš„ç§‘å­¦å®¶ä¸­ï¼Œè·å¾—è¯ºè´å°”å¥–çš„æ˜¯å“ªå‡ ä½ï¼Œä»–ä»¬è·å¥–æ—¶é—´æ˜¯å“ªä¸€å¹´ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "ç§‘å­¦æˆå°±"},
            {"question": "åˆ¶ä½œç¬¬ä¸€éƒ¨åŠ¨ç”»é•¿ç‰‡çš„å…¬å¸åˆ›å§‹äººå‡ºç”Ÿåœ¨å“ªä¸ªå›½å®¶çš„å“ªä¸ªå·ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "å¨±ä¹å†å²"},
            {"question": "ä¸–ç•Œä¸Šæœ€æ·±çš„æµ·æ²Ÿä½äºå“ªä¸ªå¤§æ´‹çš„å“ªä¸ªåŒºåŸŸï¼Œå®ƒçš„æœ€æ·±å¤„å¤§çº¦æœ‰å¤šæ·±ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "æµ·æ´‹åœ°ç†"},
            {"question": "å‘æ˜é’éœ‰ç´ çš„ç§‘å­¦å®¶å‡ºç”Ÿåœ¨å“ªä¸ªå›½å®¶ï¼Œé’éœ‰ç´ é¦–æ¬¡å¤§è§„æ¨¡ç”Ÿäº§æ˜¯åœ¨å“ªä¸ªå†å²äº‹ä»¶æœŸé—´ï¼Ÿ", "type": ReasoningType.MULTI_HOP, "context": "åŒ»å­¦å†å²"}
        ]
        
        # æ­§ä¹‰æ¾„æ¸…é—®é¢˜
        ambiguity_questions = [
            {"question": "ä»–ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "ä»£è¯æŒ‡ä»£æ¨¡ç³Š"},
            {"question": "é‚£å®¶é¤å…æ€ä¹ˆæ ·ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "æŒ‡ä»£å¯¹è±¡ä¸æ˜"},
            {"question": "ä½ èƒ½å¸®æˆ‘å®Œæˆè¿™ä¸ªå—ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "ä»»åŠ¡å†…å®¹æ¨¡ç³Š"},
            {"question": "è¿™ä¸ªä»·æ ¼åˆç†å—ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "å¯¹è±¡å’Œæ ‡å‡†ä¸æ˜"},
            {"question": "ä¸Šæ¬¡è¯´çš„é‚£ä¸ªåœ°æ–¹åœ¨å“ªé‡Œï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "ç¼ºä¹ä¸Šä¸‹æ–‡"},
            {"question": "å®ƒä»€ä¹ˆæ—¶å€™å¼€å§‹çš„ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "äº‹ä»¶ä¸»ä½“ä¸æ˜"},
            {"question": "è¿™æ ·åšå¯¹å—ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "è¡Œä¸ºå’Œæ ‡å‡†æ¨¡ç³Š"},
            {"question": "å¥¹ç°åœ¨åœ¨å“ªé‡Œå·¥ä½œï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "äººç‰©æŒ‡ä»£ä¸æ˜"},
            {"question": "é‚£ä¸ªæ–¹æ¡ˆå¯è¡Œå—ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "æ–¹æ¡ˆå†…å®¹ä¸æ˜"},
            {"question": "ä½ è§‰å¾—æ€ä¹ˆæ ·ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "è¯„ä»·å¯¹è±¡æ¨¡ç³Š"},
            {"question": "ä»€ä¹ˆæ—¶å€™æˆªæ­¢ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "æ´»åŠ¨ä¸»ä½“ä¸æ˜"},
            {"question": "è¿™ä¸ªæ•ˆæœå¥½å—ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "äº§å“å’Œæ ‡å‡†ä¸æ˜"},
            {"question": "ä¸‹æ¬¡æˆ‘ä»¬å»å“ªé‡Œï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "æ´»åŠ¨èƒŒæ™¯ä¸æ˜"},
            {"question": "ä»–ä»¬ä»€ä¹ˆæ—¶å€™å›æ¥ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "äººç¾¤æŒ‡ä»£æ¨¡ç³Š"},
            {"question": "è¿™ä¸ªç»“æœå¯¹å—ï¼Ÿ", "type": ReasoningType.AMBIGUITY_CLARIFICATION, "context": "ç»“æœå†…å®¹å’Œæ ‡å‡†ä¸æ˜"}
        ]
        
        all_questions = math_questions + multi_hop_questions + ambiguity_questions
        
        # ä¸ºæ¯ä¸ªé—®é¢˜æ·»åŠ ID
        for i, question in enumerate(all_questions):
            question["id"] = f"phase1_{question['type'].value}_{i+1:03d}"
        
        self.logger.info(f"åˆ›å»ºäº†{len(all_questions)}ä¸ªç¬¬ä¸€é˜¶æ®µéªŒè¯é—®é¢˜")
        return all_questions
    
    def generate_single_dialogue(self, question_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ç”Ÿæˆå•ä¸ªå¯¹è¯"""
        question_id = question_data["id"]
        question_text = question_data["question"]
        reasoning_type = question_data["type"]
        context = question_data.get("context", "")
        
        try:
            self.logger.info(f"ç”Ÿæˆå¯¹è¯: {question_id}")
            
            # ç”Ÿæˆprompt
            if reasoning_type == ReasoningType.MATH_REASONING:
                prompt = self.prompt_generator.generate_math_reasoning_prompt(question_text, context)
            elif reasoning_type == ReasoningType.MULTI_HOP:
                prompt = self.prompt_generator.generate_multi_hop_prompt(question_text, context)
            elif reasoning_type == ReasoningType.AMBIGUITY_CLARIFICATION:
                prompt = self.prompt_generator.generate_ambiguity_clarification_prompt(question_text, context)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨ç†ç±»å‹: {reasoning_type}")
            
            # è°ƒç”¨Geminiç”Ÿæˆå¯¹è¯
            response = self.gemini_generator._make_request(prompt)
            
            if not response:
                self.logger.error(f"Gemini APIè¿”å›ä¸ºç©º: {question_id}")
                return None
            
            # å°è¯•è§£æJSONå“åº”
            try:
                # æå–JSONéƒ¨åˆ†
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_str = response[json_start:json_end]
                    dialogue_data = json.loads(json_str)
                else:
                    raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
                
            except (json.JSONDecodeError, ValueError) as e:
                self.logger.warning(f"JSONè§£æå¤±è´¥: {question_id}, é”™è¯¯: {e}")
                # åˆ›å»ºç®€åŒ–çš„å¯¹è¯ç»“æ„
                dialogue_data = self._create_fallback_dialogue(question_data, response)
            
            # æ·»åŠ å…ƒæ•°æ®
            dialogue_data.update({
                "id": question_id,
                "source_question": question_data,
                "generation_timestamp": datetime.now().isoformat(),
                "generator_version": "phase1_v1.0"
            })
            
            # ç«‹å³è¿›è¡Œè´¨é‡è¯„åˆ†
            quality_type_map = {
                ReasoningType.MATH_REASONING: QuestionType.MATH_REASONING,
                ReasoningType.MULTI_HOP: QuestionType.MULTI_HOP,
                ReasoningType.AMBIGUITY_CLARIFICATION: QuestionType.AMBIGUITY_CLARIFICATION
            }
            
            quality_result = self.quality_scorer.score_dialogue(
                dialogue_data, 
                quality_type_map[reasoning_type]
            )
            
            dialogue_data["quality_score"] = quality_result
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_stats(reasoning_type.value, True, quality_result["grade"])
            
            self.logger.info(f"æˆåŠŸç”Ÿæˆå¯¹è¯: {question_id}, è´¨é‡ç­‰çº§: {quality_result['grade']}")
            return dialogue_data
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå¯¹è¯å¤±è´¥: {question_id}, é”™è¯¯: {e}")
            self._update_stats(reasoning_type.value, False)
            return None
    
    def _create_fallback_dialogue(self, question_data: Dict[str, Any], raw_response: str) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ç”¨çš„å¯¹è¯ç»“æ„"""
        reasoning_type = question_data["type"]
        original_question = question_data["question"]
        
        # ç®€åŒ–çš„å¯¹è¯ç»“æ„
        dialogue = {
            "dialogue_type": reasoning_type.value,
            "original_question": original_question,
            "reconstructed_question": original_question,  # ä½¿ç”¨åŸé—®é¢˜
            "turns": [
                {"role": "user", "content": original_question},
                {"role": "assistant", "content": raw_response[:500] + "..." if len(raw_response) > 500 else raw_response}
            ],
            "generation_note": "fallback_structure_due_to_json_parse_error"
        }
        
        return dialogue
    
    def _update_stats(self, reasoning_type: str, success: bool, quality_grade: str = None):
        """æ›´æ–°ç”Ÿæˆç»Ÿè®¡"""
        self.generation_stats["total_attempted"] += 1
        self.generation_stats["by_type"][reasoning_type]["attempted"] += 1
        
        if success:
            self.generation_stats["total_successful"] += 1
            self.generation_stats["by_type"][reasoning_type]["successful"] += 1
            
            if quality_grade:
                self.generation_stats["quality_distribution"][quality_grade] += 1
        else:
            self.generation_stats["by_type"][reasoning_type]["failed"] += 1
    
    def generate_phase1_dataset(self, max_concurrent: int = 3) -> Dict[str, Any]:
        """ç”Ÿæˆç¬¬ä¸€é˜¶æ®µæ•°æ®é›†"""
        self.logger.info("å¼€å§‹ç”Ÿæˆç¬¬ä¸€é˜¶æ®µæ•°æ®é›†")
        self.generation_stats["start_time"] = datetime.now().isoformat()
        
        # åˆ›å»ºé—®é¢˜é›†
        questions = self.create_phase1_questions()
        
        # ç”Ÿæˆå¯¹è¯
        dialogues = []
        failed_questions = []
        
        for question_data in questions:
            dialogue = self.generate_single_dialogue(question_data)
            
            if dialogue:
                dialogues.append(dialogue)
            else:
                failed_questions.append(question_data)
            
            # é¿å…APIé™æµï¼Œæ·»åŠ å»¶è¿Ÿ
            time.sleep(2)
        
        self.generation_stats["end_time"] = datetime.now().isoformat()
        
        # åˆ†æç»“æœ
        analysis = self._analyze_generation_results(dialogues, failed_questions)
        
        # æ„å»ºæœ€ç»ˆæ•°æ®é›†
        dataset = {
            "version": "phase1_v1.0",
            "generation_timestamp": self.generation_stats["end_time"],
            "total_dialogues": len(dialogues),
            "target_count": len(questions),
            "success_rate": len(dialogues) / len(questions) if questions else 0,
            "dialogues": dialogues,
            "failed_questions": failed_questions,
            "generation_stats": self.generation_stats,
            "quality_analysis": analysis,
            "next_steps": self._generate_next_steps_recommendations(analysis)
        }
        
        self.logger.info(f"ç¬¬ä¸€é˜¶æ®µæ•°æ®é›†ç”Ÿæˆå®Œæˆ: {len(dialogues)}/{len(questions)} æˆåŠŸ")
        return dataset
    
    def _analyze_generation_results(self, dialogues: List[Dict[str, Any]], 
                                   failed_questions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æç”Ÿæˆç»“æœ"""
        analysis = {
            "overall_quality": {},
            "by_type_analysis": {},
            "common_issues": [],
            "quality_trends": {}
        }
        
        if not dialogues:
            return analysis
        
        # æ•´ä½“è´¨é‡åˆ†æ
        grades = [d["quality_score"]["grade"] for d in dialogues if "quality_score" in d]
        total_scores = [d["quality_score"]["total_score"] for d in dialogues if "quality_score" in d]
        
        if grades:
            analysis["overall_quality"] = {
                "grade_distribution": {grade: grades.count(grade) for grade in ["A", "B", "C"]},
                "average_score": sum(total_scores) / len(total_scores) if total_scores else 0,
                "high_quality_rate": grades.count("A") / len(grades),
                "acceptable_rate": (grades.count("A") + grades.count("B")) / len(grades)
            }
        
        # æŒ‰ç±»å‹åˆ†æ
        for dialogue in dialogues:
            dialogue_type = dialogue.get("dialogue_type", "unknown")
            if dialogue_type not in analysis["by_type_analysis"]:
                analysis["by_type_analysis"][dialogue_type] = {
                    "count": 0,
                    "avg_score": 0,
                    "grade_dist": {"A": 0, "B": 0, "C": 0},
                    "common_strengths": [],
                    "common_weaknesses": []
                }
            
            type_analysis = analysis["by_type_analysis"][dialogue_type]
            type_analysis["count"] += 1
            
            if "quality_score" in dialogue:
                quality_data = dialogue["quality_score"]
                type_analysis["avg_score"] += quality_data["total_score"]
                type_analysis["grade_dist"][quality_data["grade"]] += 1
                
                # æ”¶é›†ä¼˜åŠ¿å’ŒåŠ£åŠ¿
                if "detailed_analysis" in quality_data:
                    detailed = quality_data["detailed_analysis"]
                    type_analysis["common_strengths"].extend(detailed.get("strengths", []))
                    type_analysis["common_weaknesses"].extend(detailed.get("weaknesses", []))
        
        # è®¡ç®—å¹³å‡åˆ†
        for type_name, type_data in analysis["by_type_analysis"].items():
            if type_data["count"] > 0:
                type_data["avg_score"] /= type_data["count"]
        
        return analysis
    
    def _generate_next_steps_recommendations(self, analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¸‹ä¸€æ­¥å»ºè®®"""
        recommendations = []
        
        overall_quality = analysis.get("overall_quality", {})
        high_quality_rate = overall_quality.get("high_quality_rate", 0)
        
        if high_quality_rate < 0.6:
            recommendations.append("æ•´ä½“è´¨é‡åä½ï¼Œå»ºè®®ä¼˜åŒ–promptæ¨¡æ¿ï¼Œå¢åŠ æ›´å¤šç¤ºä¾‹å’Œçº¦æŸ")
        
        if high_quality_rate >= 0.8:
            recommendations.append("è´¨é‡è¡¨ç°è‰¯å¥½ï¼Œå¯ä»¥å¼€å§‹å¤§è§„æ¨¡ç”Ÿæˆ")
        
        # æŒ‰ç±»å‹çš„å»ºè®®
        by_type = analysis.get("by_type_analysis", {})
        for type_name, type_data in by_type.items():
            avg_score = type_data.get("avg_score", 0)
            if avg_score < 70:
                recommendations.append(f"{type_name}ç±»å‹éœ€è¦é‡ç‚¹ä¼˜åŒ–promptè®¾è®¡")
            elif avg_score >= 85:
                recommendations.append(f"{type_name}ç±»å‹è¡¨ç°ä¼˜ç§€ï¼Œå¯ä½œä¸ºæ¨¡æ¿å‚è€ƒ")
        
        if not recommendations:
            recommendations.append("ç»§ç»­æŒ‰å½“å‰ç­–ç•¥è¿›è¡Œå¤§è§„æ¨¡ç”Ÿæˆ")
        
        return recommendations
    
    def save_phase1_results(self, dataset: Dict[str, Any], output_dir: str = "phase1_results"):
        """ä¿å­˜ç¬¬ä¸€é˜¶æ®µç»“æœ"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜å®Œæ•´æ•°æ®é›†
        dataset_file = output_path / f"phase1_dataset_{timestamp}.json"
        with open(dataset_file, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜è´¨é‡æŠ¥å‘Š
        quality_report = {
            "generation_stats": dataset["generation_stats"],
            "quality_analysis": dataset["quality_analysis"],
            "next_steps": dataset["next_steps"],
            "summary": {
                "total_generated": dataset["total_dialogues"],
                "success_rate": f"{dataset['success_rate']:.1%}",
                "high_quality_rate": f"{dataset['quality_analysis']['overall_quality'].get('high_quality_rate', 0):.1%}"
            }
        }
        
        report_file = output_path / f"phase1_quality_report_{timestamp}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(quality_report, f, ensure_ascii=False, indent=2)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        markdown_report = self._generate_markdown_report(dataset)
        md_file = output_path / f"phase1_report_{timestamp}.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(markdown_report)
        
        self.logger.info(f"ç¬¬ä¸€é˜¶æ®µç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return {
            "dataset_file": str(dataset_file),
            "report_file": str(report_file),
            "markdown_file": str(md_file)
        }
    
    def _generate_markdown_report(self, dataset: Dict[str, Any]) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report = f"""# ç¬¬ä¸€é˜¶æ®µæ•°æ®ç”ŸæˆæŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {timestamp}  
**æ•°æ®é›†ç‰ˆæœ¬**: {dataset['version']}

## ğŸ“Š æ€»ä½“ç»Ÿè®¡

- **ç›®æ ‡æ•°é‡**: {dataset['target_count']} ä¸ªå¯¹è¯
- **æˆåŠŸç”Ÿæˆ**: {dataset['total_dialogues']} ä¸ªå¯¹è¯
- **æˆåŠŸç‡**: {dataset['success_rate']:.1%}

## ğŸ¯ è´¨é‡åˆ†æ

### æ•´ä½“è´¨é‡åˆ†å¸ƒ
"""
        
        overall_quality = dataset['quality_analysis'].get('overall_quality', {})
        if 'grade_distribution' in overall_quality:
            grade_dist = overall_quality['grade_distribution']
            report += f"""
- **Açº§ (ä¼˜ç§€)**: {grade_dist.get('A', 0)} ä¸ª ({grade_dist.get('A', 0)/max(dataset['total_dialogues'], 1):.1%})
- **Bçº§ (è‰¯å¥½)**: {grade_dist.get('B', 0)} ä¸ª ({grade_dist.get('B', 0)/max(dataset['total_dialogues'], 1):.1%})
- **Cçº§ (éœ€æ”¹è¿›)**: {grade_dist.get('C', 0)} ä¸ª ({grade_dist.get('C', 0)/max(dataset['total_dialogues'], 1):.1%})

**å¹³å‡åˆ†æ•°**: {overall_quality.get('average_score', 0):.1f}
**é«˜è´¨é‡ç‡**: {overall_quality.get('high_quality_rate', 0):.1%}
"""
        
        # æŒ‰ç±»å‹åˆ†æ
        by_type = dataset['quality_analysis'].get('by_type_analysis', {})
        if by_type:
            report += "\n### åˆ†ç±»å‹åˆ†æ\n\n"
            for type_name, type_data in by_type.items():
                report += f"""#### {type_name}
- **æ•°é‡**: {type_data['count']} ä¸ª
- **å¹³å‡åˆ†**: {type_data['avg_score']:.1f}
- **ç­‰çº§åˆ†å¸ƒ**: A({type_data['grade_dist']['A']}) B({type_data['grade_dist']['B']}) C({type_data['grade_dist']['C']})

"""
        
        # ä¸‹ä¸€æ­¥å»ºè®®
        next_steps = dataset.get('next_steps', [])
        if next_steps:
            report += "## ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®\n\n"
            for i, step in enumerate(next_steps, 1):
                report += f"{i}. {step}\n"
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    print("ç¬¬ä¸‰é˜¶æ®µç¬¬ä¸€é˜¶æ®µæ•°æ®ç”Ÿæˆå™¨")
    print("=" * 50)
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = Phase1DataGenerator()
    
    # ç”Ÿæˆæ•°æ®é›†
    print("ğŸ”„ å¼€å§‹ç”Ÿæˆç¬¬ä¸€é˜¶æ®µéªŒè¯æ•°æ®é›†...")
    dataset = generator.generate_phase1_dataset()
    
    # ä¿å­˜ç»“æœ
    print("ğŸ’¾ ä¿å­˜ç”Ÿæˆç»“æœ...")
    file_paths = generator.save_phase1_results(dataset)
    
    # æ˜¾ç¤ºæ€»ç»“
    print(f"\nâœ… ç¬¬ä¸€é˜¶æ®µæ•°æ®ç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“Š æˆåŠŸç‡: {dataset['success_rate']:.1%}")
    print(f"ğŸ“ˆ é«˜è´¨é‡ç‡: {dataset['quality_analysis']['overall_quality'].get('high_quality_rate', 0):.1%}")
    print(f"ğŸ“ æ–‡ä»¶ä¿å­˜:")
    for file_type, file_path in file_paths.items():
        print(f"   {file_type}: {file_path}")

if __name__ == "__main__":
    main()
